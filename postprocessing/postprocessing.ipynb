{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Best Run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(good link in general) also incorrect false negative?\n",
    "https://neuroglancer-demo.appspot.com/#!gs://flyem-user-links/short/2023-10-02.154327.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "grace annotated 4 new validation regions: https://cell-map.slack.com/archives/C04N9JUFQK1/p1695934591940359, so will use these\n",
    "\n",
    "we will use her initial large \"validation region\" as testing region\n",
    "\n",
    "annotations_20230929_115330.csv is validation region 2\n",
    "\n",
    "annotations_20230929_115745.csv is validation region 3\n",
    "\n",
    "annotations_20230929_115914.csv is validation regions 4 and 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "a = np.array([-0.3, 0.4, 1.0, 244.5, 244.4, 255]).astype(np.uint8)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all annotations: 4429\n",
      "all annotations assuming region 1 is used for test: 3455\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "original_annotations = pd.read_csv(\"../preprocessing/annotations_20230510_114340.csv\")\n",
    "validation_region_1 = pd.read_csv(\"../preprocessing/annotations_20230829_173628.csv\")\n",
    "validation_region_2 = pd.read_csv(\"../preprocessing/annotations_20230929_115330.csv\")\n",
    "validation_region_3 = pd.read_csv(\"../preprocessing/annotations_20230929_115745.csv\")\n",
    "validation_region_4_and_5 = pd.read_csv(\n",
    "    \"../preprocessing/annotations_20230929_115914.csv\"\n",
    ")\n",
    "print(\n",
    "    f\"all annotations: {len(original_annotations) + len(validation_region_1) + len(validation_region_2) + len(validation_region_3)+ len(validation_region_4_and_5)}\"\n",
    ")\n",
    "print(\n",
    "    f\"all annotations assuming region 1 is used for test: {len(original_annotations) + len(validation_region_2) + len(validation_region_3) + len(validation_region_4_and_5)}\"\n",
    ")  # if use validation 1 as test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "190.6893146663395"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv(\"../preprocessing/annotations/jrc_22ak351-leaf-3m/annotations_20230510_114340.csv\")\n",
    "\n",
    "pd_starts = np.array([df[\"start x (nm)\"], df[\"start y (nm)\"], df[\"start z (nm)\"]]).T\n",
    "pd_ends = np.array([df[\"end x (nm)\"], df[\"end y (nm)\"], df[\"end z (nm)\"]]).T\n",
    "\n",
    "np.linalg.norm(pd_starts-pd_ends,axis=1).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## min volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "358.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\n",
    "    \"/nrs/cellmap/ackermand/cellmap/analysisResults/leaf-gall/jrc_22ak351-leaf-3m/plasmodesmata_as_cylinders.csv\"\n",
    ")\n",
    "print(df[\"Volume (nm^3)\"].min() / (8**3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "df = validation_region_4_and_5\n",
    "\n",
    "pd_starts = np.array([df[\"start x (nm)\"], df[\"start y (nm)\"], df[\"start z (nm)\"]]).T\n",
    "pd_ends = np.array([df[\"end x (nm)\"], df[\"end y (nm)\"], df[\"end z (nm)\"]]).T\n",
    "pd_centers = np.array(\n",
    "    list(map(tuple, np.round(((pd_starts + pd_ends) / 2)).astype(int)))\n",
    ")\n",
    "\n",
    "in_box_5 = (\n",
    "    (pd_centers[:, 0] <= 126598)\n",
    "    & (pd_centers[:, 0] >= 118478)\n",
    "    & (pd_centers[:, 1] <= 38009)\n",
    "    & (pd_centers[:, 1] >= 30502)\n",
    "    & (pd_centers[:, 2] <= 50384)\n",
    "    & (pd_centers[:, 2] >= 34005)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    len(original_annotations)\n",
    "    + len(validation_region_4_and_5)\n",
    "    + len(validation_region_1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from dacapo.store.create_store import (\n",
    "    create_config_store,\n",
    ")\n",
    "from dacapo.experiments import Run\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    columns=[\n",
    "        \"run\",\n",
    "        \"iteration\",\n",
    "        \"parameter\",\n",
    "        \"full_path\",\n",
    "        \"rand_voi\",\n",
    "        \"rand_voi_bkgd\",\n",
    "        \"detection_f1\",\n",
    "        \"detection_iou_f1\",\n",
    "        \"detection_avg_iou\",\n",
    "        \"detection_iou_avg_iou\",\n",
    "    ]\n",
    ")\n",
    "\n",
    "base_dir = \"/nrs/cellmap/ackermand/validation_inference/\"\n",
    "for run_name in os.listdir(base_dir):\n",
    "    for iteration in range(5000, 200000 + 1, 5000):\n",
    "        for idx, bias in enumerate([0.1, 0.25, 0.5, 0.75, 0.9]):\n",
    "            parameter = f\"WatershedPostProcessorParameters(id={idx}, bias={bias})\"\n",
    "            dir_name = f\"/nrs/cellmap/ackermand/validation_inference/{run_name}/processed.n5/iteration_{iteration}/{parameter}\"\n",
    "            file_name = f\"{dir_name}/attributes.json\"\n",
    "            try:\n",
    "                with open(file_name) as f:\n",
    "                    data = json.load(f)\n",
    "                detection = data[\"detection\"]\n",
    "                f1 = (\n",
    "                    2\n",
    "                    * detection[\"tp\"]\n",
    "                    / (2 * detection[\"tp\"] + detection[\"fp\"] + detection[\"fn\"])\n",
    "                )\n",
    "                detection_iou = data[\"detection_iou\"]\n",
    "                f1_iou = (\n",
    "                    2\n",
    "                    * detection_iou[\"tp\"]\n",
    "                    / (\n",
    "                        2 * detection_iou[\"tp\"]\n",
    "                        + detection_iou[\"fp\"]\n",
    "                        + detection_iou[\"fn\"]\n",
    "                    )\n",
    "                )\n",
    "                row = [\n",
    "                    run_name,\n",
    "                    iteration,\n",
    "                    parameter,\n",
    "                    dir_name,\n",
    "                    data[\"rand_voi\"],\n",
    "                    data[\"rand_voi_include_background\"],\n",
    "                    f1,\n",
    "                    f1_iou,\n",
    "                    detection[\"avg_iou\"],\n",
    "                    detection_iou[\"avg_iou\"],\n",
    "                ]\n",
    "                df.loc[len(df.index)] = row\n",
    "            except:\n",
    "                pass\n",
    "                # print(run_name,iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "removed_dummy = df[df[\"run\"].str.contains(\"removed_dummy\")]\n",
    "f1_max = max(\n",
    "    removed_dummy[\"detection_f1\"].max(), removed_dummy[\"detection_iou_f1\"].max()\n",
    ")\n",
    "df_maxs = removed_dummy[\n",
    "    (removed_dummy[\"detection_f1\"] == f1_max)\n",
    "    | (removed_dummy[\"detection_iou_f1\"] == f1_max)\n",
    "]\n",
    "print(f1_max, df_maxs[\"full_path\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detection_iou"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check f1 score in new validation region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from funlib.persistence import open_ds\n",
    "from funlib.geometry import Roi\n",
    "\n",
    "roi = Roi((19952, 9736, 153344), (13464, 14064, 15104))\n",
    "best = open_ds(\n",
    "    \"/nrs/cellmap/ackermand/predictions/jrc_22ak351-leaf-3m/jrc_22ak351-leaf-3m.n5\",\n",
    "    \"processed/2023-08-17/plasmodesmata_affs_lsds/0/fragments_relabeled/\",\n",
    ")\n",
    "gt = open_ds(\n",
    "    \"/nrs/cellmap/ackermand/cellmap/leaf-gall/jrc_22ak351-leaf-3m.n5\",\n",
    "    \"larger_validation_crop\",\n",
    ")\n",
    "best = best.to_ndarray(roi)\n",
    "gt = gt.to_ndarray(roi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed | 104.62 ms\n",
      "[{1: [array([2, 8]), array([1, 1])], 2: [array([3, 4, 8]), array([1, 1, 1])], 3: [array([4]), array([1])], 5: [array([5]), array([1])], 9: [array([3]), array([1])]}, {1: [array([5, 7]), array([1, 1])], 2: [array([3, 9]), array([1, 2])], 6: [array([3]), array([1])], 7: [array([5]), array([1])], 9: [array([4]), array([1])]}]\n"
     ]
    }
   ],
   "source": [
    "import dask\n",
    "import dask.array as da\n",
    "import numpy as np\n",
    "import dask.diagnostics\n",
    "\n",
    "# target array to be processed block-by-block\n",
    "# use `da.overlap.overlap` for overlapped blocks\n",
    "gt_da = da.random.randint(low=1, high=10, size=(4, 4), dtype=int, chunks=2)\n",
    "test_da = da.random.randint(low=1, high=10, size=(4, 4), dtype=int, chunks=2)\n",
    "\n",
    "\n",
    "# function that returns a python dictionary\n",
    "def get_overlap_dict(gt, test):\n",
    "    out_dict = {}\n",
    "    gt_ids = np.unique(gt)\n",
    "    for gt_id in gt_ids:\n",
    "        if gt_id > 0:\n",
    "            test_ids, test_counts = np.unique(test[gt == gt_id], return_counts=True)\n",
    "            nonzeros = test_ids > 0\n",
    "            out_dict[gt_id] = [\n",
    "                test_ids[nonzeros],\n",
    "                test_counts[nonzeros],\n",
    "            ]\n",
    "    return out_dict\n",
    "\n",
    "\n",
    "# list comprehension to iterate over the blocks, lazily\n",
    "delayed_result = [\n",
    "    dask.delayed(get_overlap_dict)(gt_block, test_block)\n",
    "    for (gt_block, test_block) in zip(gt_da.blocks, test_da.blocks)\n",
    "]\n",
    "\n",
    "result = dask.delayed(list)(delayed_result)\n",
    "with dask.diagnostics.ProgressBar():\n",
    "    print(result.compute())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Click here to monitor job: http://ackermand-ws2:8787/status\n",
      "[########################################] | 100% Completed | 203.75 s\n"
     ]
    }
   ],
   "source": [
    "import dask.diagnostics\n",
    "import dask.array as da\n",
    "from dask.distributed import Client, LocalCluster\n",
    "import numpy as np\n",
    "from scipy.ndimage import binary_erosion\n",
    "import socket\n",
    "import itertools\n",
    "from funlib.persistence import open_ds\n",
    "from funlib.geometry import Roi\n",
    "import itertools\n",
    "\n",
    "# target array to be processed block-by-block\n",
    "# use `da.overlap.overlap` for overlapped blocks\n",
    "with LocalCluster(n_workers=8, threads_per_worker=1) as cluster:\n",
    "    with Client(cluster) as client:\n",
    "        print(\n",
    "            f'Click here to monitor job: {client.dashboard_link.replace(\"127.0.0.1\", socket.gethostname())}'\n",
    "        )\n",
    "\n",
    "        roi = Roi((19952, 9736, 153344), (13464, 14064, 15104)).snap_to_grid((8, 8, 8))\n",
    "        start_original = np.array(roi.begin / 8).astype(int)\n",
    "        end_original = np.array(roi.end / 8).astype(int)\n",
    "\n",
    "        # need to snap to 256 since we are using that for chunk size and because chunks start at 0,0,0\n",
    "        # in voxels\n",
    "        roi = roi.snap_to_grid((256 * 8, 256 * 8, 256 * 8))\n",
    "\n",
    "        # start_prediction_mask = np.array([22400.0, 12800.0, 0.0], dtype=int) / 128\n",
    "        # prediction_mask_da = da.from_zarr(\n",
    "        #    \"/nrs/cellmap/ackermand/cellmap/leaf-gall/validation_masks.zarr\",\n",
    "        #    \"jrc_22ak351-leaf-3m\",\n",
    "        #    chunks=(16, 16, 16),\n",
    "        # )\n",
    "        # prediction_mask_da = da.pad(\n",
    "        #     prediction_mask_da,\n",
    "        #     [(start_prediction_mask[i] - start[i], 0) for i in range(3)],\n",
    "        #     mode=\"constant\",\n",
    "        #     constant_values=0,\n",
    "        # )\n",
    "\n",
    "        prediction_mask_da = da.from_zarr(\n",
    "            \"/nrs/cellmap/ackermand/cellmap/leaf-gall/validation_masks.zarr\",\n",
    "            \"jrc_22ak351-leaf-3m\",\n",
    "            chunks=(128, 128, 128),\n",
    "        )\n",
    "\n",
    "        start_prediction = np.array(roi.begin / 128).astype(int)\n",
    "        end_prediction = np.array(roi.end / 128).astype(int)\n",
    "        prediction_mask_da = prediction_mask_da[\n",
    "            start_prediction[0] : end_prediction[0],\n",
    "            start_prediction[1] : end_prediction[1],\n",
    "            start_prediction[2] : end_prediction[2],\n",
    "        ]\n",
    "        prediction_mask_da = (\n",
    "            prediction_mask_da.repeat(16, axis=0).repeat(16, axis=1).repeat(16, axis=2)\n",
    "        )\n",
    "        prediction_mask_da = prediction_mask_da.rechunk((256, 256, 256))\n",
    "\n",
    "        start = np.array(roi.begin / 8).astype(int)\n",
    "        end = np.array(roi.end / 8).astype(int)\n",
    "        test_da = da.from_zarr(\n",
    "            \"/nrs/cellmap/ackermand/predictions/jrc_22ak351-leaf-3m/jrc_22ak351-leaf-3m.n5\",\n",
    "            \"processed/2023-08-17/plasmodesmata_affs_lsds/0/fragments_relabeled/\",\n",
    "            chunks=(256, 256, 256),\n",
    "        )\n",
    "\n",
    "        test_da = da.pad(\n",
    "            test_da,\n",
    "            [\n",
    "                (start_original[i] - start[i], end[i] - end_original[i])\n",
    "                for i in range(3)\n",
    "            ],\n",
    "            mode=\"constant\",\n",
    "            constant_values=0,\n",
    "        )\n",
    "        test_da = test_da.rechunk((256, 256, 256))\n",
    "\n",
    "        gt_da = da.from_zarr(\n",
    "            \"/nrs/cellmap/ackermand/cellmap/leaf-gall/jrc_22ak351-leaf-3m.n5\",\n",
    "            \"larger_validation_crop\",\n",
    "            chunks=(256, 256, 256),\n",
    "        )\n",
    "        gt_da = gt_da[\n",
    "            start[0] : end[0],\n",
    "            start[1] : end[1],\n",
    "            start[2] : end[2],\n",
    "        ]\n",
    "\n",
    "        # function that returns a python dictionary\n",
    "        def get_overlap_dict(true_components, test_components, prediction_mask):\n",
    "            out_dict = {}\n",
    "            # taken from funlib.evaluate detection\n",
    "            # change logical_and to logical_or since we want total counts\n",
    "            # prediction_mask = (\n",
    "            #     prediction_mask.repeat(16, axis=0).repeat(16, axis=1).repeat(16, axis=2)\n",
    "            # )\n",
    "            test_components = np.multiply(test_components, prediction_mask)\n",
    "\n",
    "            # NOTE: had to chnage logical_and to logical_or since we are doing this in chunks\n",
    "            # and want to make sure we have all our ids for downstream processing\n",
    "            both_fg_mask = np.logical_or(true_components > 0, test_components > 0)\n",
    "            both_fg_true = true_components[both_fg_mask].ravel()\n",
    "            both_fg_test = test_components[both_fg_mask].ravel()\n",
    "            if both_fg_true.size > 0:\n",
    "                pairs, counts = np.unique(\n",
    "                    np.array([both_fg_true, both_fg_test]), axis=1, return_counts=True\n",
    "                )\n",
    "\n",
    "                for gt_id, test_id, count in zip(pairs[0], pairs[1], counts):\n",
    "                    out_dict[(gt_id, test_id)] = count\n",
    "                return out_dict\n",
    "\n",
    "    # list comprehension to iterate over the blocks, lazily\n",
    "    delayed_result = [\n",
    "        dask.delayed(get_overlap_dict)(\n",
    "            gt_da.blocks[inds],\n",
    "            test_da.blocks[inds],\n",
    "            prediction_mask_da.blocks[\n",
    "                inds\n",
    "            ],  # tuple([int(ind // 16) for ind in inds])],\n",
    "        )\n",
    "        for inds in itertools.product(*map(range, gt_da.blocks.shape))\n",
    "    ]\n",
    "\n",
    "    result = dask.delayed(list)(delayed_result)\n",
    "    with dask.diagnostics.ProgressBar():\n",
    "        res = result.compute()\n",
    "\n",
    "import pickle\n",
    "\n",
    "with open(\"validation_processing_result.pickle\", \"wb\") as handle:\n",
    "    pickle.dump(res, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## attempt daisy implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "364a5b68dd8d467bb665292c5e1ef458",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "block_processing ▶:   0%|          | 0/2366 [00:00<?, ?blocks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Execution Summary\n",
      "-----------------\n",
      "\n",
      "  Task block_processing:\n",
      "\n",
      "    num blocks : 2366\n",
      "    completed ✔: 2366 (skipped 0)\n",
      "    failed    ✗: 0\n",
      "    orphaned  ∅: 0\n",
      "\n",
      "    all blocks processed successfully\n"
     ]
    }
   ],
   "source": [
    "import daisy\n",
    "from funlib.persistence import Array, open_ds\n",
    "from funlib.geometry import Roi, Coordinate\n",
    "import zarr\n",
    "import numpy as np\n",
    "import numcodecs\n",
    "import tempfile\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "\n",
    "# function that returns a python dictionary\n",
    "def get_overlap_dict(\n",
    "    block: daisy.Block,\n",
    "    gt_array: Array,\n",
    "    test_array: Array,\n",
    "    mask_array: Array,\n",
    "    tmpdirname,\n",
    "):\n",
    "    _, block_id = block.block_id\n",
    "    gt_block = gt_array.to_ndarray(block.read_roi, fill_value=0)\n",
    "    test_block = test_array.to_ndarray(block.read_roi, fill_value=0)\n",
    "\n",
    "    mask_roi = block.read_roi.snap_to_grid((128, 128, 128))\n",
    "    mask_block = mask_array.to_ndarray(mask_roi)\n",
    "    mask_block = mask_block.repeat(16, axis=0).repeat(16, axis=1).repeat(16, axis=2)\n",
    "    mask_begin_voxels = (block.read_roi.begin - mask_roi.begin) / 8\n",
    "    mask_end_voxels = mask_begin_voxels + Coordinate(gt_block.shape)\n",
    "    mask_block = mask_block[\n",
    "        mask_begin_voxels[0] : mask_end_voxels[0],\n",
    "        mask_begin_voxels[1] : mask_end_voxels[1],\n",
    "        mask_begin_voxels[2] : mask_end_voxels[2],\n",
    "    ]\n",
    "\n",
    "    test_block = np.multiply(test_block, mask_block)\n",
    "\n",
    "    out_dict = {}\n",
    "    # taken from funlib.evaluate detection\n",
    "    # change logical_and to logical_or since we want total counts\n",
    "    # prediction_mask = (\n",
    "    #     prediction_mask.repeat(16, axis=0).repeat(16, axis=1).repeat(16, axis=2)\n",
    "    # )\n",
    "\n",
    "    # test_components = np.multiply(test_components, prediction_mask)\n",
    "\n",
    "    # NOTE: had to chnage logical_and to logical_or since we are doing this in chunks\n",
    "    # and want to make sure we have all our ids for downstream processing\n",
    "    both_fg_mask = np.logical_or(gt_block > 0, test_block > 0)\n",
    "    both_fg_true = gt_block[both_fg_mask].ravel()\n",
    "    both_fg_test = test_block[both_fg_mask].ravel()\n",
    "    if both_fg_true.size > 0:\n",
    "        pairs, counts = np.unique(\n",
    "            np.array([both_fg_true, both_fg_test]), axis=1, return_counts=True\n",
    "        )\n",
    "\n",
    "        for gt_id, test_id, count in zip(pairs[0], pairs[1], counts):\n",
    "            out_dict[(gt_id, test_id)] = count\n",
    "\n",
    "    with open(f\"{tmpdirname}/block_{block_id}.pkl\", \"wb\") as fp:\n",
    "        pickle.dump(out_dict, fp)\n",
    "\n",
    "\n",
    "def combine_block_dicts(tmpdirname):\n",
    "    gt_test_counts = {}\n",
    "    test_ids = {0}\n",
    "    gt_ids = {0}\n",
    "    for block_filename in os.listdir(tmpdirname):\n",
    "        with open(f\"{tmpdirname}/{block_filename}\", \"rb\") as f:\n",
    "            block_dict = pickle.load(f)\n",
    "            if block_dict:\n",
    "                for (gt_id, test_id), v in block_dict.items():\n",
    "                    gt_ids.add(gt_id)\n",
    "                    test_ids.add(test_id)\n",
    "                    gt_test_counts[(gt_id, test_id)] = (\n",
    "                        gt_test_counts.get((gt_id, test_id), 0) + v\n",
    "                    )\n",
    "\n",
    "    # vs = np.array(list(test_id_counts.values()))\n",
    "\n",
    "    test_id_renumbering = {test_id: i for i, test_id in enumerate(test_ids)}\n",
    "    gt_id_renumbering = {gt_id: i for i, gt_id in enumerate(gt_ids)}\n",
    "    # n_test = len(test_ids) - 1\n",
    "    # n_gt = len(gt_ids) - 1\n",
    "    gt_test_overlaps = np.zeros(\n",
    "        (len(gt_id_renumbering), len(test_id_renumbering)), dtype=np.int64\n",
    "    )\n",
    "    for (gt_id, test_id), v in gt_test_counts.items():\n",
    "        # TODO: Does it matter the order? In Funke lab stuff it is test, gt...\n",
    "        gt_test_overlaps[gt_id_renumbering[gt_id], test_id_renumbering[test_id]] = v\n",
    "\n",
    "    with open(f\"testing.pkl\", \"wb\") as fp:\n",
    "        pickle.dump(\n",
    "            {\n",
    "                \"test_gt_counts\": gt_test_counts,\n",
    "                \"gt_id_renumbering\": gt_id_renumbering,\n",
    "                \"test_id_renumbering\": test_id_renumbering,\n",
    "                \"gt_test_overlaps\": gt_test_overlaps,\n",
    "            },\n",
    "            fp,\n",
    "        )\n",
    "\n",
    "\n",
    "with tempfile.TemporaryDirectory() as tmpdirname:\n",
    "    total_roi = Roi((19952, 9736, 153344), (13464, 14064, 15104)).snap_to_grid(\n",
    "        (8, 8, 8)\n",
    "    )\n",
    "\n",
    "    test_array: Array = open_ds(\n",
    "        filename=\"/nrs/cellmap/ackermand/predictions/jrc_22ak351-leaf-3m/jrc_22ak351-leaf-3m.n5\",\n",
    "        ds_name=\"processed/2023-08-17/plasmodesmata_affs_lsds/0/fragments_relabeled/\",\n",
    "    )\n",
    "    gt_array: Array = open_ds(\n",
    "        filename=\"/nrs/cellmap/ackermand/cellmap/leaf-gall/jrc_22ak351-leaf-3m.n5\",\n",
    "        ds_name=\"larger_validation_crop\",\n",
    "    )\n",
    "    mask_array: Array = open_ds(\n",
    "        filename=\"/nrs/cellmap/ackermand/cellmap/leaf-gall/validation_masks.zarr\",\n",
    "        ds_name=\"jrc_22ak351-leaf-3m\",\n",
    "    )\n",
    "\n",
    "    read_write_roi: Roi = Roi((0, 0, 0), gt_array.chunk_shape * gt_array.voxel_size)\n",
    "\n",
    "    task = daisy.Task(\n",
    "        total_roi=total_roi,\n",
    "        read_roi=read_write_roi,\n",
    "        write_roi=read_write_roi,\n",
    "        process_function=lambda b: get_overlap_dict(\n",
    "            b, gt_array, test_array, mask_array, tmpdirname\n",
    "        ),\n",
    "        num_workers=10,\n",
    "        task_id=\"block_processing\",\n",
    "    )\n",
    "    # add export of scores\n",
    "    daisy.run_blockwise([task])\n",
    "    combine_block_dicts(tmpdirname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 128, 128)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = open_ds(\n",
    "    filename=\"/nrs/cellmap/ackermand/cellmap/leaf-gall/validation_masks.zarr\",\n",
    "    ds_name=\"jrc_22ak351-leaf-3m\",\n",
    ")\n",
    "mask.voxel_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "720 1728 128 0.4368932038834951\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'f1_score_info': {'tp': 720,\n",
       "  'fp': 1728,\n",
       "  'fn': 128,\n",
       "  'f1_score': 0.4368932038834951,\n",
       "  'iou': 0.3079191096062949},\n",
       " 'iou_score_info': {'iou_score': 0.30792880535091716,\n",
       "  'iou_matches': [(2, 1470),\n",
       "   (3, 2210),\n",
       "   (6, 2269),\n",
       "   (8, 1055),\n",
       "   (9, 1820),\n",
       "   (10, 274),\n",
       "   (11, 500),\n",
       "   (12, 521),\n",
       "   (13, 699),\n",
       "   (14, 768),\n",
       "   (15, 324),\n",
       "   (16, 613),\n",
       "   (17, 432),\n",
       "   (18, 400),\n",
       "   (19, 142),\n",
       "   (20, 465),\n",
       "   (22, 105),\n",
       "   (23, 585),\n",
       "   (24, 359),\n",
       "   (26, 1887),\n",
       "   (28, 1921),\n",
       "   (29, 113),\n",
       "   (30, 134),\n",
       "   (31, 147),\n",
       "   (32, 2126),\n",
       "   (33, 635),\n",
       "   (34, 615),\n",
       "   (35, 982),\n",
       "   (36, 1063),\n",
       "   (37, 454),\n",
       "   (38, 1877),\n",
       "   (39, 809),\n",
       "   (40, 1858),\n",
       "   (41, 1380),\n",
       "   (42, 1788),\n",
       "   (43, 146),\n",
       "   (44, 1691),\n",
       "   (45, 551),\n",
       "   (46, 629),\n",
       "   (47, 2377),\n",
       "   (49, 983),\n",
       "   (50, 1955),\n",
       "   (52, 2060),\n",
       "   (54, 45),\n",
       "   (57, 112),\n",
       "   (58, 1891),\n",
       "   (59, 1854),\n",
       "   (60, 469),\n",
       "   (61, 40),\n",
       "   (62, 1865),\n",
       "   (63, 1894),\n",
       "   (64, 1853),\n",
       "   (65, 1752),\n",
       "   (66, 1620),\n",
       "   (67, 1584),\n",
       "   (68, 1989),\n",
       "   (69, 1498),\n",
       "   (71, 1401),\n",
       "   (72, 1533),\n",
       "   (73, 1198),\n",
       "   (74, 1319),\n",
       "   (75, 1999),\n",
       "   (76, 1565),\n",
       "   (77, 1882),\n",
       "   (78, 1830),\n",
       "   (79, 1686),\n",
       "   (80, 1431),\n",
       "   (81, 1371),\n",
       "   (82, 1808),\n",
       "   (83, 2001),\n",
       "   (84, 1859),\n",
       "   (85, 2264),\n",
       "   (86, 2202),\n",
       "   (88, 1990),\n",
       "   (89, 1716),\n",
       "   (90, 1728),\n",
       "   (91, 177),\n",
       "   (92, 2208),\n",
       "   (93, 460),\n",
       "   (94, 2340),\n",
       "   (95, 1509),\n",
       "   (97, 1409),\n",
       "   (98, 1437),\n",
       "   (99, 1568),\n",
       "   (100, 1537),\n",
       "   (101, 1504),\n",
       "   (102, 1849),\n",
       "   (103, 1411),\n",
       "   (104, 1888),\n",
       "   (105, 1005),\n",
       "   (106, 1140),\n",
       "   (107, 1944),\n",
       "   (108, 2427),\n",
       "   (109, 350),\n",
       "   (110, 87),\n",
       "   (111, 117),\n",
       "   (112, 1512),\n",
       "   (113, 2000),\n",
       "   (114, 1146),\n",
       "   (115, 1838),\n",
       "   (116, 1384),\n",
       "   (117, 1322),\n",
       "   (118, 2075),\n",
       "   (119, 2098),\n",
       "   (120, 2128),\n",
       "   (121, 1535),\n",
       "   (122, 1478),\n",
       "   (123, 1510),\n",
       "   (124, 1597),\n",
       "   (125, 1157),\n",
       "   (126, 1602),\n",
       "   (127, 1635),\n",
       "   (128, 794),\n",
       "   (129, 1792),\n",
       "   (130, 952),\n",
       "   (131, 854),\n",
       "   (132, 1903),\n",
       "   (134, 1423),\n",
       "   (135, 116),\n",
       "   (136, 1329),\n",
       "   (137, 132),\n",
       "   (138, 1675),\n",
       "   (139, 1889),\n",
       "   (140, 798),\n",
       "   (141, 1823),\n",
       "   (142, 1179),\n",
       "   (143, 648),\n",
       "   (144, 743),\n",
       "   (145, 1643),\n",
       "   (146, 1682),\n",
       "   (147, 1783),\n",
       "   (148, 471),\n",
       "   (149, 1758),\n",
       "   (150, 150),\n",
       "   (151, 2362),\n",
       "   (153, 1195),\n",
       "   (154, 2018),\n",
       "   (155, 2149),\n",
       "   (156, 133),\n",
       "   (157, 2120),\n",
       "   (158, 2421),\n",
       "   (159, 2054),\n",
       "   (160, 2130),\n",
       "   (161, 1940),\n",
       "   (162, 181),\n",
       "   (163, 2163),\n",
       "   (164, 148),\n",
       "   (166, 1183),\n",
       "   (167, 159),\n",
       "   (168, 2159),\n",
       "   (169, 1008),\n",
       "   (170, 135),\n",
       "   (171, 197),\n",
       "   (172, 266),\n",
       "   (173, 2356),\n",
       "   (175, 2190),\n",
       "   (176, 2287),\n",
       "   (179, 1759),\n",
       "   (180, 998),\n",
       "   (183, 1342),\n",
       "   (184, 2112),\n",
       "   (185, 1918),\n",
       "   (186, 718),\n",
       "   (188, 2222),\n",
       "   (189, 776),\n",
       "   (191, 18),\n",
       "   (192, 1127),\n",
       "   (193, 905),\n",
       "   (196, 1121),\n",
       "   (199, 376),\n",
       "   (200, 300),\n",
       "   (201, 1289),\n",
       "   (202, 1272),\n",
       "   (203, 337),\n",
       "   (204, 2161),\n",
       "   (206, 1637),\n",
       "   (207, 1632),\n",
       "   (208, 482),\n",
       "   (209, 1872),\n",
       "   (211, 1688),\n",
       "   (213, 154),\n",
       "   (214, 2166),\n",
       "   (215, 593),\n",
       "   (216, 263),\n",
       "   (217, 356),\n",
       "   (218, 238),\n",
       "   (219, 2074),\n",
       "   (220, 2097),\n",
       "   (221, 896),\n",
       "   (222, 1020),\n",
       "   (223, 1046),\n",
       "   (224, 1349),\n",
       "   (225, 1210),\n",
       "   (226, 1280),\n",
       "   (227, 994),\n",
       "   (228, 960),\n",
       "   (229, 2324),\n",
       "   (230, 1347),\n",
       "   (231, 1016),\n",
       "   (232, 2193),\n",
       "   (233, 1732),\n",
       "   (234, 739),\n",
       "   (235, 1870),\n",
       "   (236, 353),\n",
       "   (237, 1893),\n",
       "   (238, 2346),\n",
       "   (239, 70),\n",
       "   (240, 1952),\n",
       "   (241, 488),\n",
       "   (242, 836),\n",
       "   (243, 1517),\n",
       "   (244, 2276),\n",
       "   (247, 1772),\n",
       "   (248, 1965),\n",
       "   (249, 1935),\n",
       "   (250, 1880),\n",
       "   (251, 2168),\n",
       "   (252, 2230),\n",
       "   (253, 2237),\n",
       "   (254, 2301),\n",
       "   (255, 109),\n",
       "   (256, 63),\n",
       "   (257, 1361),\n",
       "   (259, 1455),\n",
       "   (262, 653),\n",
       "   (263, 2129),\n",
       "   (264, 2099),\n",
       "   (265, 2262),\n",
       "   (266, 1043),\n",
       "   (267, 10),\n",
       "   (268, 13),\n",
       "   (269, 8),\n",
       "   (270, 2288),\n",
       "   (271, 2322),\n",
       "   (272, 95),\n",
       "   (273, 1422),\n",
       "   (274, 329),\n",
       "   (276, 399),\n",
       "   (277, 323),\n",
       "   (278, 1972),\n",
       "   (279, 1803),\n",
       "   (280, 120),\n",
       "   (281, 2125),\n",
       "   (282, 1919),\n",
       "   (283, 2380),\n",
       "   (284, 241),\n",
       "   (285, 2434),\n",
       "   (286, 956),\n",
       "   (287, 1845),\n",
       "   (288, 332),\n",
       "   (290, 2044),\n",
       "   (291, 1958),\n",
       "   (292, 1927),\n",
       "   (293, 185),\n",
       "   (294, 2100),\n",
       "   (295, 932),\n",
       "   (296, 430),\n",
       "   (297, 490),\n",
       "   (298, 1110),\n",
       "   (299, 1298),\n",
       "   (300, 2167),\n",
       "   (303, 208),\n",
       "   (304, 184),\n",
       "   (305, 401),\n",
       "   (307, 251),\n",
       "   (308, 2033),\n",
       "   (310, 291),\n",
       "   (311, 2021),\n",
       "   (312, 2253),\n",
       "   (313, 2321),\n",
       "   (314, 2220),\n",
       "   (315, 1483),\n",
       "   (316, 160),\n",
       "   (317, 1800),\n",
       "   (318, 420),\n",
       "   (319, 1861),\n",
       "   (320, 749),\n",
       "   (322, 2247),\n",
       "   (323, 1359),\n",
       "   (325, 1420),\n",
       "   (327, 1364),\n",
       "   (329, 2143),\n",
       "   (331, 1188),\n",
       "   (333, 781),\n",
       "   (334, 714),\n",
       "   (335, 378),\n",
       "   (336, 1341),\n",
       "   (338, 1332),\n",
       "   (340, 746),\n",
       "   (341, 152),\n",
       "   (342, 627),\n",
       "   (343, 607),\n",
       "   (344, 393),\n",
       "   (345, 907),\n",
       "   (346, 1373),\n",
       "   (347, 753),\n",
       "   (349, 1447),\n",
       "   (350, 31),\n",
       "   (351, 1851),\n",
       "   (352, 1634),\n",
       "   (354, 769),\n",
       "   (355, 813),\n",
       "   (357, 840),\n",
       "   (358, 871),\n",
       "   (359, 897),\n",
       "   (360, 851),\n",
       "   (361, 939),\n",
       "   (362, 1735),\n",
       "   (363, 1006),\n",
       "   (364, 973),\n",
       "   (367, 1245),\n",
       "   (368, 1479),\n",
       "   (369, 1511),\n",
       "   (371, 1507),\n",
       "   (372, 205),\n",
       "   (373, 2171),\n",
       "   (374, 287),\n",
       "   (375, 236),\n",
       "   (376, 429),\n",
       "   (377, 395),\n",
       "   (378, 489),\n",
       "   (379, 463),\n",
       "   (380, 319),\n",
       "   (381, 1539),\n",
       "   (382, 2012),\n",
       "   (384, 355),\n",
       "   (385, 2265),\n",
       "   (386, 1167),\n",
       "   (388, 338),\n",
       "   (389, 1873),\n",
       "   (392, 1243),\n",
       "   (393, 2085),\n",
       "   (394, 314),\n",
       "   (395, 351),\n",
       "   (398, 342),\n",
       "   (399, 391),\n",
       "   (400, 2135),\n",
       "   (401, 1344),\n",
       "   (402, 192),\n",
       "   (403, 2132),\n",
       "   (404, 128),\n",
       "   (405, 97),\n",
       "   (406, 230),\n",
       "   (407, 257),\n",
       "   (409, 626),\n",
       "   (410, 301),\n",
       "   (413, 1376),\n",
       "   (414, 2325),\n",
       "   (415, 1325),\n",
       "   (416, 1307),\n",
       "   (417, 123),\n",
       "   (418, 1266),\n",
       "   (419, 442),\n",
       "   (420, 1335),\n",
       "   (421, 2344),\n",
       "   (422, 677),\n",
       "   (423, 829),\n",
       "   (424, 1287),\n",
       "   (425, 565),\n",
       "   (426, 58),\n",
       "   (427, 651),\n",
       "   (428, 2345),\n",
       "   (429, 1222),\n",
       "   (430, 440),\n",
       "   (431, 662),\n",
       "   (432, 1045),\n",
       "   (434, 789),\n",
       "   (436, 2338),\n",
       "   (438, 1061),\n",
       "   (439, 383),\n",
       "   (440, 434),\n",
       "   (441, 481),\n",
       "   (443, 2302),\n",
       "   (444, 2270),\n",
       "   (445, 2176),\n",
       "   (447, 562),\n",
       "   (448, 1869),\n",
       "   (449, 1588),\n",
       "   (451, 417),\n",
       "   (452, 2250),\n",
       "   (453, 2184),\n",
       "   (454, 2416),\n",
       "   (455, 1614),\n",
       "   (456, 992),\n",
       "   (457, 2315),\n",
       "   (458, 2248),\n",
       "   (461, 1418),\n",
       "   (463, 678),\n",
       "   (464, 1066),\n",
       "   (465, 711),\n",
       "   (466, 450),\n",
       "   (471, 99),\n",
       "   (472, 637),\n",
       "   (473, 2386),\n",
       "   (474, 2157),\n",
       "   (475, 39),\n",
       "   (476, 904),\n",
       "   (477, 1254),\n",
       "   (478, 683),\n",
       "   (479, 426),\n",
       "   (480, 1294),\n",
       "   (481, 1417),\n",
       "   (483, 1010),\n",
       "   (484, 835),\n",
       "   (485, 1943),\n",
       "   (486, 2119),\n",
       "   (487, 968),\n",
       "   (488, 899),\n",
       "   (491, 2403),\n",
       "   (492, 470),\n",
       "   (494, 955),\n",
       "   (496, 1666),\n",
       "   (497, 1082),\n",
       "   (498, 1209),\n",
       "   (499, 531),\n",
       "   (500, 631),\n",
       "   (501, 1551),\n",
       "   (502, 970),\n",
       "   (504, 322),\n",
       "   (505, 286),\n",
       "   (506, 2219),\n",
       "   (507, 2187),\n",
       "   (509, 1827),\n",
       "   (510, 1711),\n",
       "   (511, 860),\n",
       "   (512, 2124),\n",
       "   (513, 2043),\n",
       "   (514, 1530),\n",
       "   (515, 419),\n",
       "   (516, 700),\n",
       "   (517, 96),\n",
       "   (518, 679),\n",
       "   (519, 598),\n",
       "   (521, 2025),\n",
       "   (522, 827),\n",
       "   (523, 1410),\n",
       "   (524, 1439),\n",
       "   (525, 2214),\n",
       "   (526, 1003),\n",
       "   (527, 557),\n",
       "   (528, 2016),\n",
       "   (530, 364),\n",
       "   (531, 515),\n",
       "   (534, 825),\n",
       "   (535, 600),\n",
       "   (536, 811),\n",
       "   (537, 2435),\n",
       "   (538, 2395),\n",
       "   (539, 884),\n",
       "   (541, 1017),\n",
       "   (542, 2257),\n",
       "   (543, 2290),\n",
       "   (544, 1405),\n",
       "   (547, 333),\n",
       "   (548, 934),\n",
       "   (549, 444),\n",
       "   (551, 140),\n",
       "   (552, 272),\n",
       "   (553, 1862),\n",
       "   (555, 372),\n",
       "   (556, 1397),\n",
       "   (558, 1419),\n",
       "   (559, 1453),\n",
       "   (560, 1521),\n",
       "   (563, 855),\n",
       "   (564, 828),\n",
       "   (568, 1182),\n",
       "   (569, 1295),\n",
       "   (570, 392),\n",
       "   (572, 414),\n",
       "   (574, 1785),\n",
       "   (575, 1561),\n",
       "   (576, 1795),\n",
       "   (577, 2221),\n",
       "   (578, 2409),\n",
       "   (579, 1899),\n",
       "   (580, 357),\n",
       "   (582, 2213),\n",
       "   (583, 1609),\n",
       "   (584, 273),\n",
       "   (586, 2285),\n",
       "   (587, 601),\n",
       "   (588, 221),\n",
       "   (589, 772),\n",
       "   (590, 705),\n",
       "   (591, 1252),\n",
       "   (592, 57),\n",
       "   (593, 2229),\n",
       "   (594, 403),\n",
       "   (595, 468),\n",
       "   (597, 1748),\n",
       "   (598, 1863),\n",
       "   (599, 2437),\n",
       "   (601, 723),\n",
       "   (602, 972),\n",
       "   (603, 1570),\n",
       "   (604, 574),\n",
       "   (605, 425),\n",
       "   (606, 1246),\n",
       "   (607, 880),\n",
       "   (609, 1811),\n",
       "   (611, 570),\n",
       "   (613, 1922),\n",
       "   (615, 2188),\n",
       "   (616, 2422),\n",
       "   (617, 1914),\n",
       "   (618, 885),\n",
       "   (619, 652),\n",
       "   (620, 698),\n",
       "   (621, 433),\n",
       "   (622, 643),\n",
       "   (623, 1377),\n",
       "   (624, 1690),\n",
       "   (625, 2273),\n",
       "   (626, 1663),\n",
       "   (627, 2354),\n",
       "   (628, 1818),\n",
       "   (629, 67),\n",
       "   (630, 1368),\n",
       "   (631, 1351),\n",
       "   (632, 50),\n",
       "   (633, 313),\n",
       "   (634, 1282),\n",
       "   (635, 791),\n",
       "   (636, 275),\n",
       "   (637, 1340),\n",
       "   (639, 73),\n",
       "   (640, 782),\n",
       "   (641, 1924),\n",
       "   (642, 1556),\n",
       "   (643, 1750),\n",
       "   (644, 247),\n",
       "   (645, 219),\n",
       "   (646, 754),\n",
       "   (647, 334),\n",
       "   (648, 85),\n",
       "   (649, 1525),\n",
       "   (650, 474),\n",
       "   (651, 255),\n",
       "   (652, 1658),\n",
       "   (653, 1490),\n",
       "   (654, 578),\n",
       "   (655, 818),\n",
       "   (656, 845),\n",
       "   (657, 2330),\n",
       "   (658, 1950),\n",
       "   (659, 1934),\n",
       "   (660, 1372),\n",
       "   (661, 1432),\n",
       "   (662, 77),\n",
       "   (663, 75),\n",
       "   (664, 2431),\n",
       "   (665, 424),\n",
       "   (666, 1645),\n",
       "   (667, 1931),\n",
       "   (668, 59),\n",
       "   (669, 498),\n",
       "   (670, 545),\n",
       "   (671, 1076),\n",
       "   (672, 1136),\n",
       "   (673, 519),\n",
       "   (674, 1465),\n",
       "   (676, 311),\n",
       "   (677, 2174),\n",
       "   (678, 2215),\n",
       "   (679, 1054),\n",
       "   (680, 30),\n",
       "   (681, 882),\n",
       "   (682, 999),\n",
       "   (683, 1083),\n",
       "   (684, 967),\n",
       "   (685, 34),\n",
       "   (686, 51),\n",
       "   (687, 773),\n",
       "   (688, 1030),\n",
       "   (689, 1011),\n",
       "   (690, 1138),\n",
       "   (692, 636),\n",
       "   (693, 1240),\n",
       "   (694, 1116),\n",
       "   (695, 957),\n",
       "   (696, 23),\n",
       "   (697, 375),\n",
       "   (698, 1128),\n",
       "   (699, 1275),\n",
       "   (700, 136),\n",
       "   (701, 84),\n",
       "   (702, 1152),\n",
       "   (703, 69),\n",
       "   (704, 76),\n",
       "   (705, 2024),\n",
       "   (706, 72),\n",
       "   (707, 191),\n",
       "   (708, 229),\n",
       "   (709, 1301),\n",
       "   (711, 1976),\n",
       "   (712, 1276),\n",
       "   (713, 1963),\n",
       "   (714, 1181),\n",
       "   (715, 1751),\n",
       "   (716, 1954),\n",
       "   (717, 91),\n",
       "   (718, 1777),\n",
       "   (719, 981),\n",
       "   (720, 1154),\n",
       "   (721, 657),\n",
       "   (722, 667),\n",
       "   (723, 1459),\n",
       "   (724, 1306),\n",
       "   (725, 1611),\n",
       "   (726, 1130),\n",
       "   (727, 1646),\n",
       "   (728, 1648),\n",
       "   (729, 726),\n",
       "   (730, 1261),\n",
       "   (731, 588),\n",
       "   (732, 1857),\n",
       "   (733, 1702),\n",
       "   (734, 505),\n",
       "   (735, 1458),\n",
       "   (736, 483),\n",
       "   (737, 918),\n",
       "   (738, 1630),\n",
       "   (739, 1736),\n",
       "   (740, 628),\n",
       "   (741, 1374),\n",
       "   (742, 214),\n",
       "   (743, 151),\n",
       "   (744, 368),\n",
       "   (745, 262),\n",
       "   (746, 624),\n",
       "   (747, 119),\n",
       "   (748, 1947),\n",
       "   (749, 522),\n",
       "   (750, 1846),\n",
       "   (752, 816),\n",
       "   (753, 29),\n",
       "   (754, 485),\n",
       "   (756, 2095),\n",
       "   (757, 2313),\n",
       "   (758, 1132),\n",
       "   (759, 1142),\n",
       "   (760, 1283),\n",
       "   (762, 194),\n",
       "   (763, 2309),\n",
       "   (764, 831),\n",
       "   (765, 646),\n",
       "   (766, 887),\n",
       "   (767, 2382),\n",
       "   (769, 953),\n",
       "   (770, 895),\n",
       "   (771, 1303),\n",
       "   (773, 2209),\n",
       "   (774, 1719),\n",
       "   (775, 694),\n",
       "   (776, 520),\n",
       "   (777, 1956),\n",
       "   (779, 786),\n",
       "   (780, 1909),\n",
       "   (781, 299),\n",
       "   (782, 335),\n",
       "   (783, 1363),\n",
       "   (784, 1895),\n",
       "   (786, 691),\n",
       "   (787, 193),\n",
       "   (788, 2008),\n",
       "   (789, 1799),\n",
       "   (790, 137),\n",
       "   (792, 1740),\n",
       "   (793, 1828),\n",
       "   (794, 1235),\n",
       "   (795, 1980),\n",
       "   (796, 1902),\n",
       "   (797, 2440),\n",
       "   (798, 37),\n",
       "   (799, 2369),\n",
       "   (800, 2399),\n",
       "   (801, 24),\n",
       "   (802, 27),\n",
       "   (804, 616),\n",
       "   (805, 581),\n",
       "   (806, 526),\n",
       "   (807, 1338),\n",
       "   (808, 810),\n",
       "   (809, 1356),\n",
       "   (810, 650),\n",
       "   (811, 35),\n",
       "   (812, 42),\n",
       "   (813, 728),\n",
       "   (814, 1433),\n",
       "   (815, 1200),\n",
       "   (816, 850),\n",
       "   (817, 823),\n",
       "   (818, 1569),\n",
       "   (819, 1403),\n",
       "   (821, 1768),\n",
       "   (822, 1723),\n",
       "   (823, 2020),\n",
       "   (824, 819),\n",
       "   (825, 715),\n",
       "   (826, 2368),\n",
       "   (827, 1464),\n",
       "   (828, 409),\n",
       "   (829, 748),\n",
       "   (830, 732),\n",
       "   (831, 619),\n",
       "   (833, 751),\n",
       "   (834, 1577),\n",
       "   (836, 2236),\n",
       "   (837, 987),\n",
       "   (838, 1071),\n",
       "   (840, 888),\n",
       "   (841, 920),\n",
       "   (842, 805),\n",
       "   (843, 1014),\n",
       "   (844, 1133),\n",
       "   (845, 546),\n",
       "   (846, 1047),\n",
       "   (847, 1731),\n",
       "   (848, 1383)]}}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "import scipy\n",
    "\n",
    "\n",
    "def get_matches(array_to_optimize):\n",
    "    gt_idxs, test_idxs = scipy.optimize.linear_sum_assignment(\n",
    "        array_to_optimize, maximize=True\n",
    "    )\n",
    "    matches = [\n",
    "        (gt_idx + 1, test_idx + 1)  # add one for background\n",
    "        for gt_idx, test_idx in zip(gt_idxs, test_idxs)\n",
    "        if array_to_optimize[gt_idx, test_idx] > 0\n",
    "    ]\n",
    "    return matches\n",
    "\n",
    "\n",
    "def get_f1_score(gt_test_overlaps):\n",
    "    gt_test_overlaps_without_background = gt_test_overlaps[1:, 1:]\n",
    "    matches = get_matches(gt_test_overlaps_without_background)\n",
    "    n_gt, n_test = gt_test_overlaps_without_background.shape\n",
    "    tp = len(matches)\n",
    "    fp = n_test - tp\n",
    "    fn = n_gt - tp\n",
    "\n",
    "    iou = get_iou(gt_test_overlaps)\n",
    "    average_iou = np.mean(\n",
    "        [iou[gt_idx - 1, test_idx - 1] for (gt_idx, test_idx) in matches]\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"tp\": tp,\n",
    "        \"fp\": fp,\n",
    "        \"fn\": fn,\n",
    "        \"f1_score\": tp / (tp + 0.5 * (fp + fn)),\n",
    "        \"iou\": average_iou,\n",
    "    }\n",
    "\n",
    "\n",
    "def get_iou(gt_test_overlaps):\n",
    "    # iou score\n",
    "    gt_test_overlaps_without_background = gt_test_overlaps[1:, 1:]\n",
    "    gt_volumes = np.sum(gt_test_overlaps, axis=1)[1:]  # ignore background\n",
    "    test_volumes = np.sum(gt_test_overlaps, axis=0)[1:]  # ignore background\n",
    "    # need to subtract overlap otherwise double count it\n",
    "    union = (\n",
    "        np.expand_dims(gt_volumes, 1) + np.expand_dims(test_volumes, 0)\n",
    "    ) - gt_test_overlaps_without_background\n",
    "    iou = gt_test_overlaps_without_background / union\n",
    "    return iou\n",
    "\n",
    "\n",
    "def get_iou_score(gt_test_overlaps):\n",
    "    iou = get_iou(gt_test_overlaps)\n",
    "    matches = get_matches(iou)\n",
    "    average_iou = np.mean(\n",
    "        [iou[gt_idx - 1, test_idx - 1] for (gt_idx, test_idx) in matches]\n",
    "    )\n",
    "    return {\"iou_score\": average_iou, \"iou_matches\": matches}\n",
    "\n",
    "\n",
    "def get_scores_new():\n",
    "    with open(\"testing.pkl\", \"rb\") as f:\n",
    "        pkl = pickle.load(f)\n",
    "    gt_test_overlaps = pkl[\"gt_test_overlaps\"]\n",
    "    f1_score_dict = get_f1_score(gt_test_overlaps)\n",
    "    iou_score_dict = get_iou_score(gt_test_overlaps)\n",
    "    return {\"f1_score_info\": f1_score_dict, \"iou_score_info\": iou_score_dict}\n",
    "\n",
    "\n",
    "def get_scores():\n",
    "    with open(\"testing.pkl\", \"rb\") as f:\n",
    "        pkl = pickle.load(f)\n",
    "    # f1 score:\n",
    "    test_id_renumbering = pkl[\"test_id_renumbering\"]\n",
    "    gt_id_renumbering = pkl[\"gt_id_renumbering\"]\n",
    "    gt_test_overlaps = pkl[\"gt_test_overlaps\"]\n",
    "\n",
    "    # f1 score\n",
    "    # gotta ignore background...\n",
    "    gt_test_overlaps_without_background = gt_test_overlaps[1:, 1:]\n",
    "    matches = scipy.optimize.linear_sum_assignment(\n",
    "        gt_test_overlaps_without_background, maximize=True\n",
    "    )\n",
    "    matches = [\n",
    "        (gt_idx + 1, test_idx + 1)  # add one for background\n",
    "        for gt_idx, test_idx in zip(matches[0], matches[1])\n",
    "        if gt_test_overlaps_without_background[gt_idx, test_idx]\n",
    "        >= 1  # and test_id > 0 and gt_id > 0\n",
    "    ]\n",
    "\n",
    "    # subtract 1 for background\n",
    "    n_test = len(test_id_renumbering) - 1\n",
    "    n_gt = len(gt_id_renumbering) - 1\n",
    "    tp = len(matches)\n",
    "    fp = n_test - tp\n",
    "    fn = n_gt - tp\n",
    "    print(tp, fp, fn, tp / (tp + 0.5 * (fp + fn)))\n",
    "\n",
    "    # iou score\n",
    "    gt_volumes = np.sum(gt_test_overlaps, axis=1)[1:]  # ignore background\n",
    "    test_volumes = np.sum(gt_test_overlaps, axis=0)[1:]  # ignore background\n",
    "    # need to subtract overlap otherwise double count it\n",
    "    union = (\n",
    "        np.expand_dims(gt_volumes, 1) + np.expand_dims(test_volumes, 0)\n",
    "    ) - gt_test_overlaps_without_background\n",
    "    iou = gt_test_overlaps_without_background / union\n",
    "    matches = scipy.optimize.linear_sum_assignment(iou, maximize=True)\n",
    "    matches = [\n",
    "        (gt_idx + 1, test_idx + 1)  # add one for background\n",
    "        for gt_idx, test_idx in zip(matches[0], matches[1])\n",
    "        if gt_test_overlaps_without_background[gt_idx, test_idx]\n",
    "        >= 1  # and test_id > 0 and gt_id > 0\n",
    "    ]\n",
    "\n",
    "\n",
    "get_scores()\n",
    "get_scores_new()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "with open(\n",
    "    \"/groups/cellmap/cellmap/ackermand/Programming/plasmodesmata_dacapo/validation_and_test/scorer_yamls/jrc_22ak351-leaf-3m_2023-12-04.yml\",\n",
    "    \"r\",\n",
    ") as stream:\n",
    "    yml = yaml.safe_load(stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/nrs/cellmap/ackermand/predictions/jrc_22ak351-leaf-3m/jrc_22ak351-leaf-3m.n5/processed/test/finetuned_3d_lsdaffs_weight_ratio_0.50_plasmodesmata_pseudorandom_training_centers_maxshift_18_more_annotations_unet_default_v2_no_dataset_predictor_node_lr_5E-5__0/cyan.n5/iteration_100000_filter_val_0.5_lrb_ratio_-0.08_adj_0.5_lr_-1.2_segs\n",
      "/nrs/cellmap/ackermand/predictions/jrc_22ak351-leaf-3m/jrc_22ak351-leaf-3m.n5/processed/test/finetuned_3d_lsdaffs_weight_ratio_0.50_plasmodesmata_pseudorandom_training_centers_maxshift_18_more_annotations_unet_default_v2_no_dataset_predictor_node_lr_5E-5__0/cyan.n5/iteration_100000_filter_val_0.5_lrb_ratio_-0.08_adj_0.5_lr_-1.2_segs\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import yaml\n",
    "\n",
    "with open(\n",
    "    \"/groups/cellmap/cellmap/ackermand/Programming/plasmodesmata_dacapo/validation_and_test/scorer_yamls/jrc_22ak351-leaf-3m_2023-12-04.yml\",\n",
    "    \"r\",\n",
    ") as stream:\n",
    "    yml = yaml.safe_load(stream)\n",
    "\n",
    "iterations_start, iterations_end, iterations_step = yml[\"iterations\"]\n",
    "test_array_filename = yml[\"test_array\"][\"filename\"]\n",
    "date_and_time = datetime.now().strftime(f\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "for run in yml[\"runs\"]:\n",
    "    for iteration in range(iterations_start, iterations_end + 1, iterations_step):\n",
    "        for roi_name in yml[\"roi_names\"]:\n",
    "            for postprocessing_suffix in yml[\"postprocessing_suffixes\"]:\n",
    "                for test_or_validation in [\"test\", \"validation\"]:\n",
    "                    test_array = yml[\"test_array\"]\n",
    "                    test_array_ds = test_array[\"ds_base_path\"]\n",
    "                    test_array_ds = f\"{test_array_ds}/{run}/{roi_name}.n5/iteration_{iteration}{postprocessing_suffix}\"\n",
    "                    output_directory = f\"/nrs/cellmap/ackermand/validation_and_testing_scores/{date_and_time}/{run}/{roi_name}/iteration_{iteration}{postprocessing_suffix}\"\n",
    "                    break\n",
    "                break\n",
    "            break\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2]), array([2, 1, 0]))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "cost = np.array([[0, 0, 0], [0, 33, 5], [5, 0, 0]])\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "row_ind, col_ind = linear_sum_assignment(cost, maximize=True)\n",
    "row_ind, col_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gt_test_overlaps' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/groups/cellmap/cellmap/ackermand/Programming/plasmodesmata_dacapo/postprocessing/postprocessing.ipynb Cell 23\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Backermand-ws2/groups/cellmap/cellmap/ackermand/Programming/plasmodesmata_dacapo/postprocessing/postprocessing.ipynb#Y166sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m gt_test_overlaps\u001b[39m.\u001b[39mshape\n",
      "\u001b[0;31mNameError\u001b[0m: name 'gt_test_overlaps' is not defined"
     ]
    }
   ],
   "source": [
    "gt_test_overlaps.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 3, 4],\n",
       "       [6, 7, 8]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1 = np.array([[1, 2, 3], [4, 5, 6]])  # 3X2\n",
    "m2 = np.array([[1], [2]])  # 2X1\n",
    "m2 + m1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.arange(25).reshape(5, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 9, 12])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([[1, 2], [3, 4], [5, 6]])\n",
    "np.sum(a, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.argmax(np.sum(overlaps_without_background > 0, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches = scipy.optimize.linear_sum_assignment(overlaps[1:, 1:], maximize=True)\n",
    "overlaps[matches[0], matches[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    1,    2,    3,    4,    5,    6,    7,    8,    9,   11,\n",
       "         13,   14,   15,   16,   17,   19,   20,   22,   25,   26,   27,\n",
       "         30,   31,   32,   34,   35,   36,   38,   40,   41,   42,   44,\n",
       "         45,   46,   47,   50,   56,   57,   59,   64,   66,   72,   75,\n",
       "         76,   81,   86,   88,   89,   90,   93,   94,   98,   99,  100,\n",
       "        103,  107,  108,  109,  110,  111,  113,  119,  125,  129,  133,\n",
       "        134,  143,  149,  153,  156,  168,  170,  173,  178,  187,  188,\n",
       "        191,  192,  199,  201,  208,  211,  212,  213,  216,  217,  219,\n",
       "        220,  222,  228,  231,  233,  235,  236,  239,  240,  245,  247,\n",
       "        257,  260,  262,  263,  271,  273,  275,  277,  278,  285,  290,\n",
       "        293,  294,  296,  299,  304,  306,  307,  312,  319,  321,  326,\n",
       "        328,  331,  333,  334,  342,  347,  348,  353,  355,  357,  363,\n",
       "        374,  377,  378,  381,  382,  384,  385,  388,  394,  395,  396,\n",
       "        398,  403,  408,  409,  412,  413,  414,  418,  424,  427,  429,\n",
       "        433,  437,  444,  446,  449,  453,  459,  460,  464,  467,  470,\n",
       "        471,  474,  478,  481,  482,  483,  486,  491,  492,  493,  498,\n",
       "        506,  507,  508,  509,  510,  511,  512,  513,  514,  517,  518,\n",
       "        521,  522,  525,  526,  528,  529,  532,  533,  534,  536,  540,\n",
       "        542,  543,  546,  548,  551,  554,  556,  566,  569,  570,  575,\n",
       "        576,  578,  580,  581,  583,  584,  585,  586,  587,  588,  589,\n",
       "        590,  593,  596,  597,  599,  600,  602,  603,  614,  619,  620,\n",
       "        621,  622,  623,  625,  626,  629,  631,  632,  635,  636,  637,\n",
       "        638,  640,  643,  644,  647,  649,  650,  651,  652,  653,  655,\n",
       "        656,  657,  658,  660,  662,  666,  667,  670,  674,  676,  678,\n",
       "        680,  682,  683,  687,  688,  689,  691,  692,  693,  694,  695,\n",
       "        696,  697,  698,  699,  704,  705,  706,  710,  713,  714,  716,\n",
       "        717,  718,  719,  720,  721,  724,  725,  727,  728,  730,  731,\n",
       "        732,  733,  734,  735,  738,  740,  741,  742,  743,  745,  747,\n",
       "        748,  750,  751,  756,  757,  758,  759,  761,  762,  763,  764,\n",
       "        766,  769,  770,  771,  774,  775,  776,  777,  778,  779,  780,\n",
       "        781,  782,  783,  784,  790,  791,  793,  796,  798,  801,  802,\n",
       "        803,  804,  805,  806,  807,  809,  810,  811,  816,  817,  818,\n",
       "        820,  821,  825,  827,  828,  830,  831,  834,  835,  836,  837,\n",
       "        839,  840,  841,  845,  846,  847,  848,  849,  851,  852,  854,\n",
       "        855,  857,  858,  859,  862,  863,  864,  868,  870,  871,  873,\n",
       "        876,  877,  879,  880,  881,  883,  884,  886,  887,  889,  890,\n",
       "        893,  894,  896,  897,  898,  901,  902,  903,  904,  905,  906,\n",
       "        908,  911,  916,  922,  925,  926,  927,  928,  929,  932,  934,\n",
       "        936,  937,  940,  941,  942,  944,  945,  948,  950,  951,  954,\n",
       "        956,  957,  959,  960,  961,  962,  963,  969,  970,  973,  974,\n",
       "        975,  976,  977,  978,  979,  982,  983,  985,  986,  988,  990,\n",
       "        995,  996,  997,  999, 1003, 1005, 1006, 1007, 1011, 1014, 1015,\n",
       "       1018, 1019, 1020, 1021, 1027, 1028, 1030, 1031, 1033, 1034, 1035,\n",
       "       1036, 1037, 1038, 1040, 1043, 1046, 1047, 1048, 1052, 1053, 1054,\n",
       "       1055, 1058, 1059, 1060, 1062, 1063, 1074, 1078, 1079, 1080, 1081,\n",
       "       1082, 1084, 1087, 1089, 1094, 1095, 1098, 1099, 1102, 1105, 1106,\n",
       "       1107, 1115, 1116, 1119, 1122, 1123, 1133, 1135, 1140, 1142, 1143,\n",
       "       1144, 1146, 1149, 1150, 1151, 1153, 1154, 1155, 1158, 1161, 1165,\n",
       "       1170, 1172, 1173, 1179, 1181, 1183, 1185, 1190, 1191, 1195, 1196,\n",
       "       1201, 1202, 1206, 1211, 1214, 1218, 1223, 1224, 1227, 1233, 1237,\n",
       "       1238, 1244, 1248, 1251, 1257, 1261, 1267, 1268, 1269, 1272, 1277,\n",
       "       1278, 1280, 1281, 1283, 1306, 1309, 1310, 1311, 1316, 1327, 1329,\n",
       "       1340, 1342, 1351, 1361, 1374, 1375, 1376, 1387, 1404, 1421, 1429,\n",
       "       1444, 1445, 1450, 1452, 1462, 1469, 1471, 1495, 1496, 1520, 1532,\n",
       "       1542, 1568, 1585, 1629, 1804])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(overlaps[1:, 1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0,\n",
       " 8812232705: 1,\n",
       " 8812232706: 2,\n",
       " 8812232707: 3,\n",
       " 8812232708: 4,\n",
       " 1879048193: 5,\n",
       " 1879048194: 6,\n",
       " 1879048195: 7,\n",
       " 1879048196: 8,\n",
       " 111149057: 9,\n",
       " 111149058: 10,\n",
       " 226492417: 11,\n",
       " 1621098497: 12,\n",
       " 1621098498: 13,\n",
       " 784334850: 14,\n",
       " 987758593: 15,\n",
       " 1621098499: 16,\n",
       " 987758594: 17,\n",
       " 987758595: 18,\n",
       " 15627976706: 19,\n",
       " 17003708418: 20,\n",
       " 1621098500: 21,\n",
       " 3003121667: 22,\n",
       " 3642753027: 23,\n",
       " 1287651331: 24,\n",
       " 1293942787: 25,\n",
       " 5614075909: 26,\n",
       " 1568669700: 27,\n",
       " 1568669701: 28,\n",
       " 580911108: 29,\n",
       " 2927624197: 30,\n",
       " 1568669702: 31,\n",
       " 15627976705: 32,\n",
       " 17003708417: 33,\n",
       " 2575302657: 34,\n",
       " 1251999750: 35,\n",
       " 3642753031: 36,\n",
       " 5614075911: 37,\n",
       " 1568669703: 38,\n",
       " 719323143: 39,\n",
       " 5955911687: 40,\n",
       " 5614075912: 41,\n",
       " 1568669704: 42,\n",
       " 5955911688: 43,\n",
       " 1086324744: 44,\n",
       " 1314914311: 45,\n",
       " 4959764489: 46,\n",
       " 5614075913: 47,\n",
       " 6683623433: 48,\n",
       " 1086324745: 49,\n",
       " 501219337: 50,\n",
       " 1568669706: 51,\n",
       " 6683623434: 52,\n",
       " 1086324746: 53,\n",
       " 4441767946: 54,\n",
       " 501219338: 55,\n",
       " 3003121666: 56,\n",
       " 5614075915: 57,\n",
       " 1568669698: 58,\n",
       " 1568669707: 59,\n",
       " 905969666: 60,\n",
       " 2927624194: 61,\n",
       " 4798283778: 62,\n",
       " 687865858: 63,\n",
       " 5955911692: 64,\n",
       " 1086324748: 65,\n",
       " 1086324749: 66,\n",
       " 1314914316: 67,\n",
       " 1314914317: 68,\n",
       " 1566572557: 69,\n",
       " 1516240909: 70,\n",
       " 501219342: 71,\n",
       " 1516240910: 72,\n",
       " 501219341: 73,\n",
       " 1031798797: 74,\n",
       " 1306525709: 75,\n",
       " 501219343: 76,\n",
       " 5020581902: 77,\n",
       " 6362759183: 78,\n",
       " 1822425102: 79,\n",
       " 4217372686: 80,\n",
       " 360710147: 81,\n",
       " 1568669699: 82,\n",
       " 2927624195: 83,\n",
       " 1484783619: 84,\n",
       " 3347054595: 85,\n",
       " 1669332995: 86,\n",
       " 796917763: 87,\n",
       " 931135491: 88,\n",
       " 7524581379: 89,\n",
       " 243269635: 90,\n",
       " 501219345: 91,\n",
       " 6362759185: 92,\n",
       " 463470594: 93,\n",
       " 593494019: 94,\n",
       " 861929475: 95,\n",
       " 1407188993: 96,\n",
       " 601882625: 97,\n",
       " 3416260610: 98,\n",
       " 2927624196: 99,\n",
       " 1484783620: 100,\n",
       " 1769996292: 101,\n",
       " 5955911684: 102,\n",
       " 5049942020: 103,\n",
       " 3347054596: 104,\n",
       " 1669332996: 105,\n",
       " 50331652: 106,\n",
       " 3305111556: 107,\n",
       " 998244356: 108,\n",
       " 1031798795: 109,\n",
       " 9760145418: 110,\n",
       " 5955911685: 111,\n",
       " 796917765: 112,\n",
       " 1593835525: 113,\n",
       " 201326597: 114,\n",
       " 335544325: 115,\n",
       " 872415237: 116,\n",
       " 469762053: 117,\n",
       " 1073741829: 118,\n",
       " 117440517: 119,\n",
       " 1149239301: 120,\n",
       " 1178599432: 121,\n",
       " 4538236935: 122,\n",
       " 1447034888: 123,\n",
       " 5083496453: 124,\n",
       " 1186988038: 125,\n",
       " 1732247556: 126,\n",
       " 13006536708: 127,\n",
       " 260046851: 128,\n",
       " 1065353219: 129,\n",
       " 1870659587: 130,\n",
       " 3082813442: 131,\n",
       " 6304038914: 132,\n",
       " 3347054598: 133,\n",
       " 444596230: 134,\n",
       " 486539270: 135,\n",
       " 679477254: 136,\n",
       " 4471128070: 137,\n",
       " 1593835526: 138,\n",
       " 5083496454: 139,\n",
       " 117440518: 140,\n",
       " 2952790017: 141,\n",
       " 5192548358: 142,\n",
       " 3397386247: 143,\n",
       " 4471128071: 144,\n",
       " 679477255: 145,\n",
       " 3347054599: 146,\n",
       " 444596231: 147,\n",
       " 3003121671: 148,\n",
       " 5083496455: 149,\n",
       " 117440519: 150,\n",
       " 2197815303: 151,\n",
       " 469762055: 152,\n",
       " 576716808: 153,\n",
       " 446693383: 154,\n",
       " 1543503873: 155,\n",
       " 3347054600: 156,\n",
       " 360710152: 157,\n",
       " 3397386248: 158,\n",
       " 5083496456: 159,\n",
       " 117440520: 160,\n",
       " 1786773512: 161,\n",
       " 469762056: 162,\n",
       " 1543503880: 163,\n",
       " 679477256: 164,\n",
       " 463470595: 165,\n",
       " 1268776963: 166,\n",
       " 1000341507: 167,\n",
       " 1805647875: 168,\n",
       " 16846422017: 169,\n",
       " 5572132865: 170,\n",
       " 679477257: 171,\n",
       " 3397386249: 172,\n",
       " 4471128073: 173,\n",
       " 1317011465: 174,\n",
       " 5083496457: 175,\n",
       " 1073741833: 176,\n",
       " 1543503881: 177,\n",
       " 1015021577: 178,\n",
       " 1828716553: 179,\n",
       " 494927881: 180,\n",
       " 679477258: 181,\n",
       " 1166016522: 182,\n",
       " 3397386250: 183,\n",
       " 1291845642: 184,\n",
       " 1317011466: 185,\n",
       " 4471128074: 186,\n",
       " 5083496458: 187,\n",
       " 5595201546: 188,\n",
       " 1543503882: 189,\n",
       " 1501560842: 190,\n",
       " 4538236936: 191,\n",
       " 1447034889: 192,\n",
       " 13006536709: 193,\n",
       " 260046852: 194,\n",
       " 1065353220: 195,\n",
       " 398458883: 196,\n",
       " 805306370: 197,\n",
       " 679477259: 198,\n",
       " 369098763: 199,\n",
       " 5083496459: 200,\n",
       " 1543503883: 201,\n",
       " 2147483650: 202,\n",
       " 1291845643: 203,\n",
       " 1828716555: 204,\n",
       " 260046859: 205,\n",
       " 1065353227: 206,\n",
       " 943718401: 207,\n",
       " 5083496460: 208,\n",
       " 1543503884: 209,\n",
       " 645922828: 210,\n",
       " 1065353228: 211,\n",
       " 1031798796: 212,\n",
       " 4966055948: 213,\n",
       " 4412407820: 214,\n",
       " 9839837196: 215,\n",
       " 576716809: 216,\n",
       " 2195718151: 217,\n",
       " 1828716557: 218,\n",
       " 1543503885: 219,\n",
       " 738197506: 220,\n",
       " 7165968390: 221,\n",
       " 8776581126: 222,\n",
       " 9839837197: 223,\n",
       " 645922829: 224,\n",
       " 1268776964: 225,\n",
       " 1805647876: 226,\n",
       " 65011715: 227,\n",
       " 740294658: 228,\n",
       " 3831496705: 229,\n",
       " 260046850: 230,\n",
       " 3456106507: 231,\n",
       " 1447034890: 232,\n",
       " 4538236937: 233,\n",
       " 13006536710: 234,\n",
       " 260046853: 235,\n",
       " 1065353221: 236,\n",
       " 398458884: 237,\n",
       " 805306371: 238,\n",
       " 2952790019: 239,\n",
       " 1073741827: 240,\n",
       " 2147483651: 241,\n",
       " 943718402: 242,\n",
       " 1342177283: 243,\n",
       " 7524581377: 244,\n",
       " 268435459: 245,\n",
       " 373293063: 246,\n",
       " 276824065: 247,\n",
       " 381681669: 248,\n",
       " 7165968391: 249,\n",
       " 1000341509: 250,\n",
       " 1805647877: 251,\n",
       " 740294659: 252,\n",
       " 1147142146: 253,\n",
       " 480247809: 254,\n",
       " 211812353: 255,\n",
       " 7996440577: 256,\n",
       " 1285554177: 257,\n",
       " 8264876033: 258,\n",
       " 2090860545: 259,\n",
       " 4538236938: 260,\n",
       " 13006536711: 261,\n",
       " 796917766: 262,\n",
       " 260046854: 263,\n",
       " 1065353222: 264,\n",
       " 2009071621: 265,\n",
       " 398458885: 266,\n",
       " 6304038917: 267,\n",
       " 1073741828: 268,\n",
       " 2147483652: 269,\n",
       " 805306372: 270,\n",
       " 2554331139: 271,\n",
       " 2952790020: 272,\n",
       " 7524581378: 273,\n",
       " 276824066: 274,\n",
       " 15577645058: 275,\n",
       " 5783945217: 276,\n",
       " 1220542465: 277,\n",
       " 7165968392: 278,\n",
       " 8776581124: 279,\n",
       " 740294660: 280,\n",
       " 1147142147: 281,\n",
       " 7996440578: 282,\n",
       " 1285554178: 283,\n",
       " 8264876034: 284,\n",
       " 350224385: 285,\n",
       " 1155530753: 286,\n",
       " 2090860546: 287,\n",
       " 484442115: 288,\n",
       " 1593835529: 289,\n",
       " 260046855: 290,\n",
       " 1065353223: 291,\n",
       " 6304038918: 292,\n",
       " 2952790021: 293,\n",
       " 1342177285: 294,\n",
       " 2554331140: 295,\n",
       " 943718404: 296,\n",
       " 276824067: 297,\n",
       " 4441767938: 298,\n",
       " 822083585: 299,\n",
       " 1895825409: 300,\n",
       " 5117050881: 301,\n",
       " 285212673: 302,\n",
       " 3940548614: 303,\n",
       " 7165968393: 304,\n",
       " 3424649221: 305,\n",
       " 1822425091: 306,\n",
       " 2090860547: 307,\n",
       " 7996440579: 308,\n",
       " 350224386: 309,\n",
       " 1285554179: 310,\n",
       " 1155530754: 311,\n",
       " 757071873: 312,\n",
       " 1293942785: 313,\n",
       " 2367684609: 314,\n",
       " 2904555521: 315,\n",
       " 8810135553: 316,\n",
       " 6394216449: 317,\n",
       " 5052039169: 318,\n",
       " 1025507329: 319,\n",
       " 614465540: 320,\n",
       " 1593835530: 321,\n",
       " 1065353224: 322,\n",
       " 2009071623: 323,\n",
       " 6304038919: 324,\n",
       " 2952790022: 325,\n",
       " 1: 326,\n",
       " 2147483654: 327,\n",
       " 2554331141: 328,\n",
       " 943718405: 329,\n",
       " 1342177286: 330,\n",
       " 276824068: 331,\n",
       " 4441767939: 332,\n",
       " 5783945219: 333,\n",
       " 822083586: 334,\n",
       " 16777218: 335,\n",
       " 12096372738: 336,\n",
       " 5117050882: 337,\n",
       " 1497366529: 338,\n",
       " 1895825410: 339,\n",
       " 960495617: 340,\n",
       " 7165968394: 341,\n",
       " 3424649222: 342,\n",
       " 3831496709: 343,\n",
       " 1822425092: 344,\n",
       " 1285554180: 345,\n",
       " 7996440580: 346,\n",
       " 1155530755: 347,\n",
       " 350224387: 348,\n",
       " 2090860548: 349,\n",
       " 2367684610: 350,\n",
       " 1562378242: 351,\n",
       " 1293942786: 352,\n",
       " 627048449: 353,\n",
       " 2506096641: 354,\n",
       " 895483905: 355,\n",
       " 1969225729: 356,\n",
       " 5052039170: 357,\n",
       " 1163919361: 358,\n",
       " 1432354817: 359,\n",
       " 796917762: 360,\n",
       " 752877571: 361,\n",
       " 1065353225: 362,\n",
       " 398458888: 363,\n",
       " 2009071624: 364,\n",
       " 6304038920: 365,\n",
       " 1073741831: 366,\n",
       " 1342177287: 367,\n",
       " 943718406: 368,\n",
       " 276824069: 369,\n",
       " 5783945220: 370,\n",
       " 12096372739: 371,\n",
       " 16777219: 372,\n",
       " 1895825411: 373,\n",
       " 1497366530: 374,\n",
       " 576716807: 375,\n",
       " 960495618: 376,\n",
       " 1904214017: 377,\n",
       " 25165825: 378,\n",
       " 2172649473: 379,\n",
       " 562036737: 380,\n",
       " 6736052225: 381,\n",
       " 7165968395: 382,\n",
       " 740294663: 383,\n",
       " 3424649223: 384,\n",
       " 7996440581: 385,\n",
       " 2090860549: 386,\n",
       " 3034578948: 387,\n",
       " 350224388: 388,\n",
       " 2904555523: 389,\n",
       " 6394216451: 390,\n",
       " 5052039171: 391,\n",
       " 90177538: 392,\n",
       " 627048450: 393,\n",
       " 2506096642: 394,\n",
       " 228589569: 395,\n",
       " 497025025: 396,\n",
       " 1033895937: 397,\n",
       " 7069499394: 398,\n",
       " 1031798794: 399,\n",
       " 2107637761: 400,\n",
       " 765460481: 401,\n",
       " 926941187: 402,\n",
       " 6304038921: 403,\n",
       " 1342177288: 404,\n",
       " 935329793: 405,\n",
       " 2554331143: 406,\n",
       " 943718407: 407,\n",
       " 268435457: 408,\n",
       " 276824070: 409,\n",
       " 5783945221: 410,\n",
       " 12096372740: 411,\n",
       " 5117050884: 412,\n",
       " 423624707: 413,\n",
       " 960495619: 414,\n",
       " 25165826: 415,\n",
       " 163577857: 416,\n",
       " 432013313: 417,\n",
       " 861929483: 418,\n",
       " 3424649224: 419,\n",
       " 1822425094: 420,\n",
       " 3034578949: 421,\n",
       " 2904555524: 422,\n",
       " 2506096643: 423,\n",
       " 7069499395: 424,\n",
       " 90177539: 425,\n",
       " 1033895938: 426,\n",
       " 2107637762: 427,\n",
       " 497025026: 428,\n",
       " 2246049793: 429,\n",
       " 903872513: 430,\n",
       " 3856662529: 431,\n",
       " 765460482: 432,\n",
       " 9762242561: 433,\n",
       " 9760145417: 434,\n",
       " 1065353218: 435,\n",
       " 1688207363: 436,\n",
       " 6304038922: 437,\n",
       " 1342177289: 438,\n",
       " 943718408: 439,\n",
       " 5783945222: 440,\n",
       " 12096372741: 441,\n",
       " 1895825413: 442,\n",
       " 1497366532: 443,\n",
       " 960495620: 444,\n",
       " 2172649475: 445,\n",
       " 25165827: 446,\n",
       " 1178599431: 447,\n",
       " 163577858: 448,\n",
       " 6736052227: 449,\n",
       " 2986344449: 450,\n",
       " 1186988037: 451,\n",
       " 8776581125: 452,\n",
       " 3831496712: 453,\n",
       " 7996440583: 454,\n",
       " 3034578950: 455,\n",
       " 6394216453: 456,\n",
       " 2904555525: 457,\n",
       " 627048452: 458,\n",
       " 90177540: 459,\n",
       " 1033895939: 460,\n",
       " 497025027: 461,\n",
       " 765460483: 462,\n",
       " 367001602: 463,\n",
       " 14325645314: 464,\n",
       " 236978177: 465,\n",
       " 1847590913: 466,\n",
       " 1310720001: 467,\n",
       " 484442116: 468,\n",
       " 6304038923: 469,\n",
       " 1342177290: 470,\n",
       " 943718409: 471,\n",
       " 5783945223: 472,\n",
       " 12096372742: 473,\n",
       " 1895825414: 474,\n",
       " 423624709: 475,\n",
       " 960495621: 476,\n",
       " 6736052228: 477,\n",
       " 9688842244: 478,\n",
       " 3523215362: 479,\n",
       " 708837377: 480,\n",
       " 440401921: 481,\n",
       " 1822425096: 482,\n",
       " 6394216454: 483,\n",
       " 2904555526: 484,\n",
       " 2506096645: 485,\n",
       " 627048453: 486,\n",
       " 7069499397: 487,\n",
       " 497025028: 488,\n",
       " 765460484: 489,\n",
       " 90177541: 490,\n",
       " 98566147: 491,\n",
       " 236978178: 492,\n",
       " 1449132033: 493,\n",
       " 1180696577: 494,\n",
       " 1342177291: 495,\n",
       " 943718410: 496,\n",
       " 4043309063: 497,\n",
       " 12096372743: 498,\n",
       " 423624710: 499,\n",
       " 960495622: 500,\n",
       " 25165829: 501,\n",
       " 2449473539: 502,\n",
       " 3523215363: 503,\n",
       " 2986344451: 504,\n",
       " 708837378: 505,\n",
       " 1245708290: 506,\n",
       " 1447034887: 507,\n",
       " 1652555777: 508,\n",
       " 9168748545: 509,\n",
       " 7132413955: 510,\n",
       " 1822425097: 511,\n",
       " 90177542: 512,\n",
       " 497025029: 513,\n",
       " 765460485: 514,\n",
       " 98566148: 515,\n",
       " 7891582978: 516,\n",
       " 1180696578: 517,\n",
       " 2929721345: 518,\n",
       " 2124414977: 519,\n",
       " 513802241: 520,\n",
       " 245366785: 521,\n",
       " 943718411: 522,\n",
       " 423624711: 523,\n",
       " 6736052230: 524,\n",
       " 805306369: 525,\n",
       " 25165830: 526,\n",
       " 2449473540: 527,\n",
       " 1245708291: 528,\n",
       " 708837379: 529,\n",
       " 440401923: 530,\n",
       " 578813954: 531,\n",
       " 1652555778: 532,\n",
       " 9168748546: 533,\n",
       " 2864709633: 534,\n",
       " 1522532353: 535,\n",
       " 717225985: 536,\n",
       " 448790529: 537,\n",
       " 180355073: 538,\n",
       " 585105414: 539,\n",
       " 2904555528: 540,\n",
       " 7069499399: 541,\n",
       " 90177543: 542,\n",
       " 497025030: 543,\n",
       " 1593835524: 544,\n",
       " 98566149: 545,\n",
       " 1180696579: 546,\n",
       " 1050673154: 547,\n",
       " 2929721346: 548,\n",
       " 245366786: 549,\n",
       " 1457520641: 550,\n",
       " 2531262465: 551,\n",
       " 1189085185: 552,\n",
       " 268435458: 553,\n",
       " 25165831: 554,\n",
       " 708837380: 555,\n",
       " 1245708292: 556,\n",
       " 440401924: 557,\n",
       " 578813955: 558,\n",
       " 448790530: 559,\n",
       " 717225986: 560,\n",
       " 2864709634: 561,\n",
       " 5955911681: 562,\n",
       " 14277410817: 563,\n",
       " 1522532354: 564,\n",
       " 50331649: 565,\n",
       " 318767105: 566,\n",
       " 180355074: 567,\n",
       " 587202561: 568,\n",
       " 11056185345: 569,\n",
       " 2197815297: 570,\n",
       " 3808428033: 571,\n",
       " 7069499400: 572,\n",
       " 90177544: 573,\n",
       " 497025031: 574,\n",
       " 765460487: 575,\n",
       " 98566150: 576,\n",
       " 1180696580: 577,\n",
       " 1050673155: 578,\n",
       " 1457520642: 579,\n",
       " 2531262466: 580,\n",
       " 3474980865: 581,\n",
       " 522190849: 582,\n",
       " 5622464513: 583,\n",
       " 16896753665: 584,\n",
       " 1732247555: 585,\n",
       " 1688207364: 586,\n",
       " 5783945227: 587,\n",
       " 1073741825: 588,\n",
       " 7281311750: 589,\n",
       " 708837381: 590,\n",
       " 578813956: 591,\n",
       " 448790531: 592,\n",
       " 1522532355: 593,\n",
       " 180355075: 594,\n",
       " 5955911682: 595,\n",
       " 50331650: 596,\n",
       " 587202562: 597,\n",
       " 6362759169: 598,\n",
       " 5020581889: 599,\n",
       " 2197815298: 600,\n",
       " 3808428034: 601,\n",
       " 985661443: 602,\n",
       " 13203668994: 603,\n",
       " 90177545: 604,\n",
       " 497025032: 605,\n",
       " 1180696581: 606,\n",
       " 2929721348: 607,\n",
       " 2531262467: 608,\n",
       " 3474980866: 609,\n",
       " 522190850: 610,\n",
       " 16896753666: 611,\n",
       " 929038337: 612,\n",
       " 3881828353: 613,\n",
       " 2449473543: 614,\n",
       " 440401926: 615,\n",
       " 578813957: 616,\n",
       " 448790532: 617,\n",
       " 1522532356: 618,\n",
       " 717225988: 619,\n",
       " 2197815299: 620,\n",
       " 180355076: 621,\n",
       " 587202563: 622,\n",
       " 2604662786: 623,\n",
       " 11056185347: 624,\n",
       " 3808428035: 625,\n",
       " 58720257: 626,\n",
       " 2466250755: 627,\n",
       " 1180696582: 628,\n",
       " 1050673157: 629,\n",
       " 2929721349: 630,\n",
       " 2531262468: 631,\n",
       " 3474980867: 632,\n",
       " 929038338: 633,\n",
       " 3881828354: 634,\n",
       " 448790533: 635,\n",
       " 1522532357: 636,\n",
       " 587202564: 637,\n",
       " 11056185348: 638,\n",
       " 2197815300: 639,\n",
       " 5020581891: 640,\n",
       " 2466250756: 641,\n",
       " 13203668996: 642,\n",
       " 1669332994: 643,\n",
       " 327155714: 644,\n",
       " 734003201: 645,\n",
       " 1270874113: 646,\n",
       " 1539309569: 647,\n",
       " 3642753025: 648,\n",
       " 1562378241: 649,\n",
       " 807403521: 650,\n",
       " 606076929: 651,\n",
       " 337641473: 652,\n",
       " 2216689665: 653,\n",
       " 8927576065: 654,\n",
       " 2485125121: 655,\n",
       " 1218445313: 656,\n",
       " 614465537: 657,\n",
       " 228589570: 658,\n",
       " 7241465858: 659,\n",
       " 1537212418: 660,\n",
       " 2275409922: 661,\n",
       " 530579458: 662,\n",
       " 1000341506: 663,\n",
       " 1805647874: 664,\n",
       " 3047161858: 665,\n",
       " 14380171266: 666,\n",
       " 606076930: 667,\n",
       " 1180696583: 668,\n",
       " 2929721350: 669,\n",
       " 580911107: 670,\n",
       " 228589571: 671,\n",
       " 2275409923: 672,\n",
       " 7241465859: 673,\n",
       " 530579459: 674,\n",
       " 1176502275: 675,\n",
       " 2577399811: 676,\n",
       " 606076931: 677,\n",
       " 2216689667: 678,\n",
       " 3424649219: 679,\n",
       " 3474980868: 680,\n",
       " 262144002: 681,\n",
       " 929038339: 682,\n",
       " 668991489: 683,\n",
       " 3881828355: 684,\n",
       " 1205862401: 685,\n",
       " 1067450370: 686,\n",
       " 1742733313: 687,\n",
       " 228589572: 688,\n",
       " 7241465860: 689,\n",
       " 1537212420: 690,\n",
       " 530579460: 691,\n",
       " 2275409924: 692,\n",
       " 5622464516: 693,\n",
       " 186646532: 694,\n",
       " 2216689668: 695,\n",
       " 8927576068: 696,\n",
       " 2954887172: 697,\n",
       " 228589573: 698,\n",
       " 3474980869: 699,\n",
       " 446693381: 700,\n",
       " 530579461: 701,\n",
       " 2275409925: 702,\n",
       " 262144005: 703,\n",
       " 1503657989: 704,\n",
       " 2216689669: 705,\n",
       " 1218445317: 706,\n",
       " 1822425093: 707,\n",
       " 3003121669: 708,\n",
       " 587202565: 709,\n",
       " 11056185349: 710,\n",
       " 5020581892: 711,\n",
       " 2604662788: 712,\n",
       " 6362759172: 713,\n",
       " 2197815301: 714,\n",
       " 2466250757: 715,\n",
       " 327155715: 716,\n",
       " 734003202: 717,\n",
       " 1539309570: 718,\n",
       " 2613051394: 719,\n",
       " 1050673158: 720,\n",
       " 1000341510: 721,\n",
       " 530579462: 722,\n",
       " 7241465862: 723,\n",
       " 3474980870: 724,\n",
       " 446693382: 725,\n",
       " 2216689670: 726,\n",
       " 5622464518: 727,\n",
       " 1218445318: 728,\n",
       " 882900998: 729,\n",
       " 7241465863: 730,\n",
       " 1251999751: 731,\n",
       " 1050673159: 732,\n",
       " 2929721351: 733,\n",
       " 8885633031: 734,\n",
       " 3474980871: 735,\n",
       " 7098859527: 736,\n",
       " 530579463: 737,\n",
       " 1218445319: 738,\n",
       " 1822425095: 739,\n",
       " 7241465864: 740,\n",
       " 1251999752: 741,\n",
       " 1050673160: 742,\n",
       " 2929721352: 743,\n",
       " 446693384: 744,\n",
       " 3474980872: 745,\n",
       " 7098859528: 746,\n",
       " 5622464520: 747,\n",
       " 2585788424: 748,\n",
       " 2954887176: 749,\n",
       " 262144003: 750,\n",
       " 937426946: 751,\n",
       " 3881828356: 752,\n",
       " 1205862402: 753,\n",
       " 270532609: 754,\n",
       " 2149580801: 755,\n",
       " 1067450371: 756,\n",
       " 2585788425: 757,\n",
       " 7241465865: 758,\n",
       " 3474980873: 759,\n",
       " 497025033: 760,\n",
       " 1050673161: 761,\n",
       " 2929721353: 762,\n",
       " 446693385: 763,\n",
       " 7098859529: 764,\n",
       " 5622464521: 765,\n",
       " 1218445321: 766,\n",
       " 2225078276: 767,\n",
       " 3474980874: 768,\n",
       " 2585788426: 769,\n",
       " 1050673162: 770,\n",
       " 446693386: 771,\n",
       " 8885633034: 772,\n",
       " 7098859530: 773,\n",
       " 1822425098: 774,\n",
       " 840957962: 775,\n",
       " 10815012874: 776,\n",
       " 2954887178: 777,\n",
       " 587202566: 778,\n",
       " 11056185350: 779,\n",
       " 3808428038: 780,\n",
       " 2466250758: 781,\n",
       " 13203668998: 782,\n",
       " 4085252100: 783,\n",
       " 327155716: 784,\n",
       " 1539309571: 785,\n",
       " 465567747: 786,\n",
       " 2076180483: 787,\n",
       " 872415234: 788,\n",
       " 1218445323: 789,\n",
       " 7098859531: 790,\n",
       " 1251999755: 791,\n",
       " 1050673163: 792,\n",
       " 2929721355: 793,\n",
       " 446693387: 794,\n",
       " 335544322: 795,\n",
       " 1822425099: 796,\n",
       " 840957963: 797,\n",
       " 1010827265: 798,\n",
       " 446693388: 799,\n",
       " 1822425100: 800,\n",
       " 840957964: 801,\n",
       " 7165968396: 802,\n",
       " 1180696585: 803,\n",
       " 446693389: 804,\n",
       " 1822425101: 805,\n",
       " 5681184781: 806,\n",
       " 660602885: 807,\n",
       " 3881828357: 808,\n",
       " 262144004: 809,\n",
       " 1205862403: 810,\n",
       " 1742733315: 811,\n",
       " 807403522: 812,\n",
       " 2954887170: 813,\n",
       " 270532610: 814,\n",
       " 2556428289: 815,\n",
       " 1482686465: 816,\n",
       " 2097154: 817,\n",
       " 538968066: 818,\n",
       " 2149580802: 819,\n",
       " 408944641: 820,\n",
       " 10953424899: 821,\n",
       " 587202567: 822,\n",
       " 3808428039: 823,\n",
       " 985661444: 824,\n",
       " 13203668999: 825,\n",
       " 327155717: 826,\n",
       " 465567748: 827,\n",
       " 2076180484: 828,\n",
       " 335544323: 829,\n",
       " 872415235: 830,\n",
       " 603979779: 831,\n",
       " 1010827266: 832,\n",
       " 3426746370: 833,\n",
       " 1417674753: 834,\n",
       " 1149239297: 835,\n",
       " 1686110209: 836,\n",
       " 1954545665: 837,\n",
       " 5712642049: 838,\n",
       " 2529165317: 839,\n",
       " 2195718149: 840,\n",
       " 3959422977: 841,\n",
       " 3881828358: 842,\n",
       " 1205862404: 843,\n",
       " 1742733316: 844,\n",
       " 270532611: 845,\n",
       " 2954887171: 846,\n",
       " 538968067: 847,\n",
       " 1482686466: 848,\n",
       " 7925137410: 849,\n",
       " 2149580803: 850,\n",
       " 408944642: 851,\n",
       " 587202568: 852,\n",
       " 2466250760: 853,\n",
       " 5020581895: 854,\n",
       " 1270874117: 855,\n",
       " 465567749: 856,\n",
       " 2076180485: 857,\n",
       " 335544324: 858,\n",
       " 872415236: 859,\n",
       " 4362076164: 860,\n",
       " 1807745029: 861,\n",
       " 1149239298: 862,\n",
       " 612368386: 863,\n",
       " 880803842: 864,\n",
       " 3972005889: 865,\n",
       " 1686110210: 866,\n",
       " 750780417: 867,\n",
       " 465567745: 868,\n",
       " 660602887: 869,\n",
       " 3881828359: 870,\n",
       " 262144006: 871,\n",
       " 1205862405: 872,\n",
       " 1742733317: 873,\n",
       " 2149580804: 874,\n",
       " 1482686467: 875,\n",
       " 7925137411: 876,\n",
       " 408944643: 877,\n",
       " 278921218: 878,\n",
       " 10485762: 879,\n",
       " 10081009665: 880,\n",
       " 6054477825: 881,\n",
       " 6591348737: 882,\n",
       " 3370123265: 883,\n",
       " 1342177282: 884,\n",
       " 587202569: 885,\n",
       " 1270874118: 886,\n",
       " 465567750: 887,\n",
       " 2076180486: 888,\n",
       " 603979781: 889,\n",
       " 4362076165: 890,\n",
       " 1010827268: 891,\n",
       " 880803843: 892,\n",
       " 1686110211: 893,\n",
       " 1954545667: 894,\n",
       " 5712642051: 895,\n",
       " 750780418: 896,\n",
       " 1742733318: 897,\n",
       " 270532613: 898,\n",
       " 1482686468: 899,\n",
       " 7925137412: 900,\n",
       " 408944644: 901,\n",
       " 278921219: 902,\n",
       " 6054477826: 903,\n",
       " 287309825: 904,\n",
       " 587202570: 905,\n",
       " 465567751: 906,\n",
       " 2076180487: 907,\n",
       " 872415238: 908,\n",
       " 2147483649: 909,\n",
       " 10737418241: 910,\n",
       " 603979782: 911,\n",
       " 4362076166: 912,\n",
       " 1417674756: 913,\n",
       " 612368388: 914,\n",
       " 1686110212: 915,\n",
       " 3972005891: 916,\n",
       " 750780419: 917,\n",
       " 5712642052: 918,\n",
       " 3443523585: 919,\n",
       " 2906652673: 920,\n",
       " 660602889: 921,\n",
       " 3881828361: 922,\n",
       " 1742733319: 923,\n",
       " 67108865: 924,\n",
       " 1482686469: 925,\n",
       " 7925137413: 926,\n",
       " 278921220: 927,\n",
       " 3101687811: 928,\n",
       " 3370123267: 929,\n",
       " 287309826: 930,\n",
       " 6331301889: 931,\n",
       " 425721857: 932,\n",
       " 1499463681: 933,\n",
       " 1231028225: 934,\n",
       " 1270874120: 935,\n",
       " 4362076167: 936,\n",
       " 612368389: 937,\n",
       " 1686110213: 938,\n",
       " 750780420: 939,\n",
       " 3305111555: 940,\n",
       " 7470055426: 941,\n",
       " 6396313602: 942,\n",
       " 1702887425: 943,\n",
       " 360710145: 944,\n",
       " 18345885697: 945,\n",
       " 629145601: 946,\n",
       " 1434451969: 947,\n",
       " 897581057: 948,\n",
       " 1166016513: 949,\n",
       " 3850371073: 950,\n",
       " 660602890: 951,\n",
       " 270532615: 952,\n",
       " 2556428294: 953,\n",
       " 1482686470: 954,\n",
       " 7925137414: 955,\n",
       " 3370123268: 956,\n",
       " 954204164: 957,\n",
       " 287309827: 958,\n",
       " 824180739: 959,\n",
       " 6331301890: 960,\n",
       " 1499463682: 961,\n",
       " 1231028226: 962,\n",
       " 1906311169: 963,\n",
       " 1637875713: 964,\n",
       " 5020581899: 965,\n",
       " 4362076168: 966,\n",
       " 3082813441: 967,\n",
       " 1686110214: 968,\n",
       " 750780421: 969,\n",
       " 19818086403: 970,\n",
       " 7470055427: 971,\n",
       " 6396313603: 972,\n",
       " 360710146: 973,\n",
       " 18345885698: 974,\n",
       " 1434451970: 975,\n",
       " 1166016514: 976,\n",
       " 2195718150: 977,\n",
       " 3959422978: 978,\n",
       " 3881828363: 979,\n",
       " 1482686471: 980,\n",
       " 7925137415: 981,\n",
       " 408944647: 982,\n",
       " 335544321: 983,\n",
       " 954204165: 984,\n",
       " 3370123269: 985,\n",
       " 287309828: 986,\n",
       " 824180740: 987,\n",
       " 6331301891: 988,\n",
       " 425721859: 989,\n",
       " 1767899139: 990,\n",
       " 1906311170: 991,\n",
       " 8885633026: 992,\n",
       " 1637875714: 993,\n",
       " 434110465: 994,\n",
       " 13050576897: 995,\n",
       " 4460642305: 996,\n",
       " 1231028227: 997,\n",
       " 165675009: 998,\n",
       " 2984247305: 999,\n",
       " ...}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_id_renumbering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find best run by comparing metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tp': 543, 'fp': 506, 'fn': 658, 'f1_score': 0.4826666666666667, 'average_f1_score': 0.5356503585471971} {'tp': 705, 'fp': 449, 'fn': 451, 'f1_score': 0.6103896103896104, 'average_f1_score': 0.5827579943762884} finetuned_3d_lsdaffs_weight_ratio_0.50_plasmodesmata_pseudorandom_training_centers_maxshift_18_more_annotations_unet_default_v2_no_dataset_predictor_node_lr_5E-5__0 100000\n",
      "{'tp': 722, 'fp': 1063, 'fn': 479, 'f1_score': 0.4835900870730074, 'average_f1_score': 0.527193412015262} {'tp': 777, 'fp': 952, 'fn': 379, 'f1_score': 0.5386481802426343, 'average_f1_score': 0.535797834165656} finetuned_3d_lsdaffs_weight_ratio_0.50_plasmodesmata_pseudorandom_training_centers_maxshift_18_more_annotations_unet_default_v2_no_dataset_predictor_node_lr_5E-5__0 140000\n",
      "{'tp': 677, 'fp': 900, 'fn': 524, 'f1_score': 0.48740100791936647, 'average_f1_score': 0.5277175531523643} {'tp': 770, 'fp': 766, 'fn': 386, 'f1_score': 0.5720653789004457, 'average_f1_score': 0.5435632301681438} finetuned_3d_lsdaffs_weight_ratio_0.50_plasmodesmata_pseudorandom_training_centers_maxshift_18_more_annotations_unet_default_v2_no_dataset_predictor_node_lr_5E-5__0 160000\n",
      "{'tp': 707, 'fp': 846, 'fn': 494, 'f1_score': 0.5134350036310821, 'average_f1_score': 0.5530797529757663} {'tp': 737, 'fp': 602, 'fn': 419, 'f1_score': 0.5907815631262525, 'average_f1_score': 0.5599071766719201} finetuned_3d_lsdaffs_weight_ratio_0.50_plasmodesmata_pseudorandom_training_centers_maxshift_18_more_annotations_unet_default_v2_no_dataset_predictor_node_lr_5E-5__0 175000\n",
      "{'tp': 655, 'fp': 671, 'fn': 546, 'f1_score': 0.518401266323704, 'average_f1_score': 0.5716426284254502} {'tp': 704, 'fp': 569, 'fn': 452, 'f1_score': 0.5796624125154385, 'average_f1_score': 0.5557892797015216} finetuned_3d_lsdaffs_weight_ratio_0.50_plasmodesmata_pseudorandom_training_centers_maxshift_18_more_annotations_unet_default_v2_no_dataset_predictor_node_lr_5E-5__1 140000\n",
      "{'tp': 599, 'fp': 489, 'fn': 602, 'f1_score': 0.5233726518130188, 'average_f1_score': 0.5647008435204975} {'tp': 687, 'fp': 403, 'fn': 469, 'f1_score': 0.6117542297417632, 'average_f1_score': 0.6088540953541071} finetuned_3d_lsdaffs_weight_ratio_1.00_plasmodesmata_pseudorandom_training_centers_maxshift_18_unet_default_v2_no_dataset_predictor_node_lr_5E-5__0 135000\n",
      "{'tp': 641, 'fp': 600, 'fn': 560, 'f1_score': 0.5249795249795249, 'average_f1_score': 0.564424169513621} {'tp': 674, 'fp': 578, 'fn': 482, 'f1_score': 0.5598006644518272, 'average_f1_score': 0.5418744753914604} finetuned_3d_lsdaffs_weight_ratio_1.00_plasmodesmata_pseudorandom_training_centers_maxshift_18_unet_default_v2_no_dataset_predictor_node_lr_5E-5__1 145000\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import yaml\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def update_combined_dict(combined_dict, output_directory, validation_or_test, roi_name):\n",
    "    output_directory = output_directory.replace(\n",
    "        \"validation_or_test\", validation_or_test\n",
    "    ).replace(\"roi_name\", str(roi_name))\n",
    "    with open(f\"{output_directory}/scores.json\") as f:\n",
    "        roi_dict = json.load(f)\n",
    "        for k in [\"tp_gt_test_id_pairs\", \"fp_test_ids\", \"fn_gt_ids\"]:\n",
    "            del roi_dict[\"f1_score_info\"][k]\n",
    "        combined_dict[roi_name] = roi_dict\n",
    "    for key in [\"fp\", \"tp\", \"fn\"]:\n",
    "        combined_dict[\"combined\"][key] += combined_dict[roi_name][\"f1_score_info\"][key]\n",
    "    combined_dict[\"combined\"][\"average_f1_score\"].append(\n",
    "        combined_dict[roi_name][\"f1_score_info\"][\"f1_score\"]\n",
    "    )\n",
    "\n",
    "\n",
    "yaml_name = \"jrc_22ak351-leaf-3m_2023-12-06\"\n",
    "with open(\n",
    "    # \"/groups/cellmap/cellmap/ackermand/Programming/plasmodesmata_dacapo/validation_and_test/metrics_yamls/jrc_22ak351-leaf-3m_2023-12-04.yml\",\n",
    "    f\"/groups/cellmap/cellmap/ackermand/Programming/plasmodesmata_dacapo/validation_and_test/yamls/combined_yamls/{yaml_name}.yml\",\n",
    "    \"r\",\n",
    ") as stream:\n",
    "    yml = yaml.safe_load(stream)\n",
    "\n",
    "dataset = yml[\"dataset\"]\n",
    "gt_array_filename = yml[\"gt_array\"][\"filename\"]\n",
    "gt_array_ds_name = yml[\"gt_array\"][\"ds_name\"]\n",
    "mask_array_filename = yml[\"mask_array\"][\"filename\"]\n",
    "mask_array_ds_name = yml[\"mask_array\"][\"ds_name\"]\n",
    "\n",
    "iterations_start, iterations_end, iterations_step = yml[\"iterations\"]\n",
    "previous_best_f1_score = -1\n",
    "count = 0\n",
    "for run in yml[\"runs\"]:\n",
    "    for iteration in range(iterations_start, iterations_end + 1, iterations_step):\n",
    "        for postprocessing_suffix in yml[\"postprocessing_suffixes\"]:\n",
    "            test_array = yml[\"test_array\"]\n",
    "            # test_array_filename = f'{test_array[\"base_filename\"]}/processed/validation/{run}/{roi_name}.n5'\n",
    "            # test_array_ds_name = f\"iteration_{iteration}{postprocessing_suffix}\"\n",
    "            # output_directory = f\"/nrs/cellmap/ackermand/validation_and_testing_scores/20231204_232852/{validation_or_test}/{run}/{roi_name}/iteration_{iteration}{postprocessing_suffix}\"\n",
    "\n",
    "            # if roi_name == \"cyan\" and validation_or_test == \"validation\":\n",
    "            combined_validation_dict = {\n",
    "                \"combined\": {\n",
    "                    \"tp\": 0,\n",
    "                    \"fp\": 0,\n",
    "                    \"fn\": 0,\n",
    "                    \"f1_score\": 0,\n",
    "                    \"average_f1_score\": [],\n",
    "                }\n",
    "            }\n",
    "            combined_test_dict = {\n",
    "                \"combined\": {\n",
    "                    \"tp\": 0,\n",
    "                    \"fp\": 0,\n",
    "                    \"fn\": 0,\n",
    "                    \"f1_score\": 0,\n",
    "                    \"average_f1_score\": [],\n",
    "                }\n",
    "            }\n",
    "            for roi in yml[\"rois\"]:\n",
    "                roi_name = roi[\"name\"]\n",
    "                output_directory = f\"/nrs/cellmap/ackermand/validation_and_testing_scores/{yaml_name}/validation_or_test/{run}/roi_name/iteration_{iteration}{postprocessing_suffix}\"\n",
    "                update_combined_dict(\n",
    "                    combined_validation_dict,\n",
    "                    output_directory,\n",
    "                    \"validation\",\n",
    "                    roi_name,\n",
    "                )\n",
    "                count += 1\n",
    "                if roi[\"split_dimension\"] is not None:\n",
    "                    update_combined_dict(\n",
    "                        combined_test_dict, output_directory, \"test\", roi_name\n",
    "                    )\n",
    "                    count += 1\n",
    "\n",
    "            combined_validation_dict[\"combined\"][\"f1_score\"] = combined_validation_dict[\n",
    "                \"combined\"\n",
    "            ][\"tp\"] / (\n",
    "                combined_validation_dict[\"combined\"][\"tp\"]\n",
    "                + 0.5\n",
    "                * (\n",
    "                    combined_validation_dict[\"combined\"][\"fp\"]\n",
    "                    + combined_validation_dict[\"combined\"][\"fn\"]\n",
    "                )\n",
    "            )\n",
    "\n",
    "            combined_test_dict[\"combined\"][\"f1_score\"] = combined_test_dict[\"combined\"][\n",
    "                \"tp\"\n",
    "            ] / (\n",
    "                combined_test_dict[\"combined\"][\"tp\"]\n",
    "                + 0.5\n",
    "                * (\n",
    "                    combined_test_dict[\"combined\"][\"fp\"]\n",
    "                    + combined_test_dict[\"combined\"][\"fn\"]\n",
    "                )\n",
    "            )\n",
    "\n",
    "            combined_validation_dict[\"combined\"][\"average_f1_score\"] = np.mean(\n",
    "                combined_validation_dict[\"combined\"][\"average_f1_score\"]\n",
    "            )\n",
    "            combined_test_dict[\"combined\"][\"average_f1_score\"] = np.mean(\n",
    "                combined_test_dict[\"combined\"][\"average_f1_score\"]\n",
    "            )\n",
    "\n",
    "            if (\n",
    "                combined_validation_dict[\"combined\"][\"f1_score\"]\n",
    "                >= previous_best_f1_score\n",
    "            ):\n",
    "                previous_best_f1_score = combined_validation_dict[\"combined\"][\n",
    "                    \"f1_score\"\n",
    "                ]\n",
    "                best_combined_validation_dict = combined_validation_dict\n",
    "                best_combined_test_dict = combined_test_dict\n",
    "                print(\n",
    "                    combined_validation_dict[\"combined\"],\n",
    "                    combined_test_dict[\"combined\"],\n",
    "                    run,\n",
    "                    iteration,\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['finetuned_3d_lsdaffs_weight_ratio_0.50_plasmodesmata_pseudorandom_training_centers_maxshift_18_more_annotations_unet_default_v2_no_dataset_predictor_node_lr_5E-5__0',\n",
       " 'finetuned_3d_lsdaffs_weight_ratio_0.50_plasmodesmata_pseudorandom_training_centers_maxshift_18_more_annotations_unet_default_v2_no_dataset_predictor_node_lr_5E-5__1',\n",
       " 'finetuned_3d_lsdaffs_weight_ratio_0.50_plasmodesmata_pseudorandom_training_centers_maxshift_18_more_annotations_unet_default_v2_no_dataset_predictor_node_lr_5E-5__2',\n",
       " 'finetuned_3d_lsdaffs_weight_ratio_0.50_plasmodesmata_pseudorandom_training_centers_maxshift_18_removed_dummy_annotations_unet_default_v2_no_dataset_predictor_node_lr_5E-5__0',\n",
       " 'finetuned_3d_lsdaffs_weight_ratio_0.50_plasmodesmata_pseudorandom_training_centers_maxshift_18_removed_dummy_annotations_unet_default_v2_no_dataset_predictor_node_lr_5E-5__1',\n",
       " 'finetuned_3d_lsdaffs_weight_ratio_1.00_plasmodesmata_pseudorandom_training_centers_maxshift_18_more_annotations_unet_default_v2_no_dataset_predictor_node_lr_5E-5__0',\n",
       " 'finetuned_3d_lsdaffs_weight_ratio_1.00_plasmodesmata_pseudorandom_training_centers_maxshift_18_more_annotations_unet_default_v2_no_dataset_predictor_node_lr_5E-5__1',\n",
       " 'finetuned_3d_lsdaffs_weight_ratio_1.00_plasmodesmata_pseudorandom_training_centers_maxshift_18_more_annotations_unet_default_v2_no_dataset_predictor_node_lr_5E-5__2',\n",
       " 'finetuned_3d_lsdaffs_weight_ratio_1.00_plasmodesmata_pseudorandom_training_centers_maxshift_18_unet_default_v2_no_dataset_predictor_node_lr_5E-5__0',\n",
       " 'finetuned_3d_lsdaffs_weight_ratio_1.00_plasmodesmata_pseudorandom_training_centers_maxshift_18_unet_default_v2_no_dataset_predictor_node_lr_5E-5__1']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yml[\"runs\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## original best run score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73770fa3309b4bfe890262252c041a96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "block_processing ▶:   0%|          | 0/512 [00:00<?, ?blocks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Execution Summary\n",
      "-----------------\n",
      "\n",
      "  Task block_processing:\n",
      "\n",
      "    num blocks : 512\n",
      "    completed ✔: 512 (skipped 0)\n",
      "    failed    ✗: 0\n",
      "    orphaned  ∅: 0\n",
      "\n",
      "    all blocks processed successfully\n",
      "{'f1_score_info': {'tp': 91, 'fp': 112, 'fn': 65, 'f1_score': 0.5069637883008357, 'iou': 0.35075486199466865, 'tp_gt_test_id_pairs': [[3072, 405190737932], [3074, 428859195406], [3073, 416911720466], [3075, 416911720463], [3077, 416911720457], [3078, 428859195395], [3080, 428859195398], [3081, 416911720460], [3082, 416911720452], [3083, 428859195397], [3084, 428859195400], [3076, 428859195409], [3085, 405243166727], [3086, 416966246406], [3087, 405241069577], [3088, 416966246402], [3089, 405241069573], [3090, 405241069571], [3092, 416911720451], [3093, 428804669446], [3094, 428804669444], [3095, 428804669443], [3091, 405241069574], [3097, 453318279182], [3098, 440922013698], [3099, 453318279177], [3102, 453318279176], [3103, 453318279178], [3105, 465890705417], [3106, 465890705413], [3107, 465890705416], [3104, 453318279179], [3110, 505436700673], [3112, 492029607941], [3113, 560979771394], [3114, 532619984901], [3119, 453318279174], [3120, 453318279175], [3121, 440922013697], [3122, 465890705418], [3123, 416911720464], [3127, 546666708993], [3129, 560897982466], [3133, 546664611843], [3157, 546599600130], [3159, 478983225352], [3200, 453318279181], [3204, 416861388809], [3236, 491895390210], [2893, 492029607942], [2895, 532689190913], [2896, 518875250691], [2898, 532689190916], [2899, 505367494658], [2900, 518875250695], [2901, 518875250696], [2902, 518875250697], [2903, 546748497921], [2904, 532689190914], [2905, 491960401923], [2906, 491960401921], [2909, 505294094338], [2910, 478922407939], [2912, 491960401922], [2914, 478985322497], [2915, 478922407938], [2917, 492019122178], [2918, 492084133890], [2919, 478985322498], [2921, 491958304769], [2924, 466119294978], [2925, 478924505092], [2926, 466119294977], [2932, 478987419649], [2934, 478924505090], [2939, 478924505091], [2940, 478924505093], [2950, 546666708996], [2951, 546666708997], [2953, 575515131905], [2955, 546666708994], [2956, 546666708995], [2958, 575586435073], [2961, 620664717314], [2963, 605359702020], [2964, 605359702019], [2971, 575661932546], [2972, 590463631361], [2974, 575661932547], [3070, 416911720458], [3071, 416911720462]], 'fp_test_ids': [518806044673, 416913817601, 428859195393, 605359702018, 453431525378, 453490245634, 441087688708, 620664717315, 518875250693, 532689190917, 491895390213, 546607988741, 546601697281, 428857098241, 440976539649, 441031065601, 505229082625, 453431525377, 453490245633, 478928699393, 532689190919, 532619984903, 532619984904, 532619984905, 532619984906, 393740288009, 636143796226, 491964596226, 453318279170, 532676608002, 478800773122, 491836669954, 492029607938, 465945231362, 453318279180, 532689190915, 453318279171, 465890705411, 478859493379, 491895390211, 491964596227, 532619984899, 478983225347, 532691288065, 518799753217, 466001854465, 416911720467, 478863687682, 491895390212, 478928699396, 492096716804, 532609499140, 440922013700, 478993711108, 492029607940, 560979771396, 478928699397, 478983225349, 546748497922, 532619984902, 605359702022, 532676608001, 478922407937, 405243166726, 478983225350, 492029607943, 478993711107, 561109794817, 505231179777, 441087688706, 491960401924, 560979771393, 505229082626, 532546584577, 491962499073, 518873153537, 505233276929, 605359702017, 575513034753, 478926602241, 466125586433, 478993711105, 478804967426, 491840864257, 465888608258, 491964596225, 620662620161, 532548681729, 492029607939, 561036394497, 492021219329, 416913817603, 532676608003, 491962499074, 440922013699, 620664717313, 478863687681, 505354911745, 518738935810, 466125586434, 560979771395, 478928699398, 478928699395, 466060574722, 465888608259, 505365397507, 532552876033, 492086231041, 505357008897, 518862667777, 478748344321, 478928699394], 'fn_gt_ids': [3079, 3096, 3100, 3101, 3111, 3124, 3125, 3126, 3128, 3130, 3134, 3158, 3160, 3171, 3172, 3173, 3176, 3199, 3201, 3202, 3203, 3205, 3224, 2894, 2897, 2907, 2908, 2911, 2913, 2916, 2920, 2922, 2923, 2927, 2928, 2929, 2930, 2931, 2933, 2935, 2936, 2937, 2938, 2941, 2942, 2943, 2944, 2945, 2946, 2947, 2948, 2949, 2952, 2954, 2957, 2959, 2960, 2962, 2965, 2966, 2967, 2968, 2969, 2970, 2973]}, 'iou_score_info': {'iou_score': 0.35075486199466865}}\n"
     ]
    }
   ],
   "source": [
    "from funlib.persistence import open_ds, Array\n",
    "from funlib.geometry import Roi\n",
    "from utils import *\n",
    "\n",
    "\n",
    "total_roi = Roi(\n",
    "    [82304, 22808, 34936][::-1], [3832, 15672, 7328][::-1]\n",
    ")  # Roi([82304, 22808, 24712][::-1], [3832, 15672, 9064][::-1])\n",
    "\n",
    "test_array: Array = open_ds(\n",
    "    filename=\"/nrs/cellmap/ackermand/predictions/jrc_22ak351-leaf-3m/jrc_22ak351-leaf-3m.n5\",\n",
    "    ds_name=\"processed/2023-07-26/plasmodesmata_affs_lsds/0/fragments_relabeled/\",\n",
    ")\n",
    "gt_array: Array = open_ds(\n",
    "    filename=\"/nrs/cellmap/ackermand/cellmap/leaf-gall/jrc_22ak351-leaf-3m.n5\",\n",
    "    ds_name=\"plasmodesmata_as_cylinders\",\n",
    ")\n",
    "mask_array: Array = open_ds(\n",
    "    filename=\"/nrs/cellmap/ackermand/cellpose/jrc_22ak351-leaf-3m/cellpose_results.n5\",\n",
    "    ds_name=\"raw_s4_inverted_cp_masks_from_jeff_inverted\",\n",
    ")\n",
    "\n",
    "iso = InstanceSegmentationOverlap(gt_array, test_array, mask_array, total_roi=total_roi)\n",
    "overlap_dict = iso.get_overlap_dict()\n",
    "iss = InstanceSegmentationScorer(overlap_dict)\n",
    "print(iss.get_scores())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2449 2449 2449\n",
      "849 849 849\n"
     ]
    }
   ],
   "source": [
    "pkl_test_gt_counts = pkl[\"test_gt_counts\"]\n",
    "pkl_test_id_renumbering = pkl[\"test_id_renumbering\"]\n",
    "pkl_gt_id_renumbering = pkl[\"gt_id_renumbering\"]\n",
    "pkl_overlaps = pkl[\"overlaps\"]\n",
    "for (gt_id, test_id), v in pkl_test_gt_counts.items():\n",
    "    if (\n",
    "        pkl_overlaps[pkl_test_id_renumbering[test_id], pkl_gt_id_renumbering[gt_id]]\n",
    "        != overlaps[test_id_renumbering[test_id], gt_id_renumbering[gt_id]]\n",
    "    ):\n",
    "        raise Exception((\"fail\"))\n",
    "print(\n",
    "    len(pkl[\"test_id_renumbering\"].keys() & test_id_renumbering.keys()),\n",
    "    len(test_id_renumbering),\n",
    "    len(pkl[\"test_id_renumbering\"]),\n",
    ")\n",
    "print(\n",
    "    len(pkl[\"gt_id_renumbering\"].keys() & gt_id_renumbering.keys()),\n",
    "    len(gt_id_renumbering),\n",
    "    len(pkl[\"gt_id_renumbering\"]),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True,  True,  True, ...,  True,  True,  True],\n",
       "       [False,  True,  True, ...,  True,  True,  True],\n",
       "       [False,  True,  True, ...,  True,  True,  True],\n",
       "       ...,\n",
       "       [False,  True,  True, ...,  True,  True,  True],\n",
       "       [ True,  True,  True, ...,  True,  True,  True],\n",
       "       [False,  True,  True, ...,  True,  True,  True]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.equal(overlaps, pkl_overlaps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2763 2763 2763\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    len(pkl[\"test_id_renumbering\"].keys() & test_id_renumbering.keys()),\n",
    "    len(test_id_renumbering),\n",
    "    len(pkl[\"test_id_renumbering\"]),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (gt_id, test_id), v in test_gt_counts.items():\n",
    "    pkl[\"overlaps\"][test_id_renumbering[test_id], gt_id_renumbering[gt_id]] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from funlib.persistence import Array, open_ds\n",
    "\n",
    "test_array: Array = open_ds(\n",
    "    filename=\"/nrs/cellmap/ackermand/predictions/jrc_22ak351-leaf-3m/jrc_22ak351-leaf-3m.n5\",\n",
    "    ds_name=\"processed/2023-08-17/plasmodesmata_affs_lsds/0/fragments_relabeled/\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19952, 9736, 153344)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_array.roi.begin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
      " 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n",
      " 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179\n",
      " 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197\n",
      " 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215\n",
      " 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233\n",
      " 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251\n",
      " 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269\n",
      " 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287\n",
      " 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305\n",
      " 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323\n",
      " 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341\n",
      " 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359\n",
      " 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377\n",
      " 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395\n",
      " 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413\n",
      " 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431\n",
      " 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449\n",
      " 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467\n",
      " 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485\n",
      " 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503\n",
      " 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521\n",
      " 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539\n",
      " 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557\n",
      " 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575\n",
      " 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593\n",
      " 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611\n",
      " 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629\n",
      " 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647\n",
      " 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665\n",
      " 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683\n",
      " 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701\n",
      " 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 736 737\n",
      " 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755\n",
      " 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773\n",
      " 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791\n",
      " 792 793 794 795 796 797 798 805 806 807 808 809 810 811 812 813 814 815\n",
      " 816 817 818 819 820 821 822 823 824 825 826 827 828 829 830 831 832 833\n",
      " 834 835 836 837 838 839 840 841 842 843 844 845 846 847 848 849 850 851\n",
      " 852 853 854 855 856 857 858 859 860 861 862 863 864 865 866 867 868 869\n",
      " 870 871 872 873 874 875 876 877 878 879 880 881 882 883 884 885 886 887\n",
      " 888 889 890 891 892 893 894 895 896 897 898 899 900 901 902 903 904 905\n",
      " 906 907 908 909 910 911 912 913 914 915 916 917 918 919 920 921 922 923\n",
      " 924 925 926 927 928 929 930 931 932 933 934 935 936 937 938 939 940 941\n",
      " 942 943 944 945 946 947 948 949 950 951 952 953 954 955 956 957 958 959\n",
      " 960 961 962 963 964 965 966 967 968 969 970 971 972 973 974]\n"
     ]
    }
   ],
   "source": [
    "print(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f2d8a41cbb0>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(gt[:, :, 500], interpolation=\"none\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "826"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overlaps = np.load(\"testing.npz\")\n",
    "overlaps = overlaps[\"overlaps\"]\n",
    "np.sum(overlaps > 0) - np.sum(overlaps.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5129, 849)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overlaps.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7961/4012258690.py:11: DeprecationWarning: This function is deprecated. Please call randint(0, 1000 + 1) instead\n",
      "  a = Array(np.random.random_integers(0,1000,shape), roi=Roi((0,), shape), voxel_size=(1,))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0df17a0ced3a403586e70509c24dbd0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sum_reduce ▶:   0%|          | 0/16 [00:00<?, ?blocks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Execution Summary\n",
      "-----------------\n",
      "\n",
      "  Task sum_reduce:\n",
      "\n",
      "    num blocks : 16\n",
      "    completed ✔: 16 (skipped 0)\n",
      "    failed    ✗: 0\n",
      "    orphaned  ∅: 0\n",
      "\n",
      "    all blocks processed successfully\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import daisy\n",
    "from funlib.geometry import Roi\n",
    "import zarr\n",
    "from funlib.persistence import Array\n",
    "\n",
    "shape = 4096000\n",
    "reduce_shape = shape / 16\n",
    "block_shape = 1024 * 16\n",
    "\n",
    "a = Array(\n",
    "    np.random.random_integers(0, 1000, shape), roi=Roi((0,), shape), voxel_size=(1,)\n",
    ")\n",
    "# to parallelize across processes, we need persistent read/write arrays\n",
    "# we'll use zarr here to do do that\n",
    "b = zarr.open_array(\n",
    "    zarr.TempStore(), \"w\", (shape,), chunks=(block_shape,), dtype=np.int64\n",
    ")\n",
    "# output array is wrapped in Array for easy of Roi indexing\n",
    "b = Array(b, roi=Roi((0,), shape), voxel_size=(1,))\n",
    "# while using zarr with `Array` can be easier to understand and less error prone, it is not a requirement.\n",
    "# Here we make a shared memory array for collecting results from different workers\n",
    "c = np.ones(\n",
    "    int(shape / reduce_shape)\n",
    ")  # multiprocessing.Array('Q', range(int(shape/reduce_shape)))\n",
    "\n",
    "\n",
    "def process_fn_sum_reduce(block):\n",
    "    a_sub = a[block.write_roi].to_ndarray()\n",
    "    s = np.sum(a_sub)\n",
    "    # compute c idx based on block offset and shape\n",
    "    idx = (block.write_roi.offset / block.write_roi.shape)[0]\n",
    "    c[idx] = s\n",
    "\n",
    "\n",
    "total_roi = Roi((0,), shape)  # total ROI to map process over\n",
    "block_roi = Roi((0,), reduce_shape)  # block ROI for parallel processing\n",
    "task1 = daisy.Task(\n",
    "    total_roi=total_roi,\n",
    "    read_roi=block_roi,\n",
    "    write_roi=block_roi,\n",
    "    process_function=process_fn_sum_reduce,\n",
    "    num_workers=8,\n",
    "    task_id=\"sum_reduce\",\n",
    ")\n",
    "daisy.run_blockwise([task1])\n",
    "print(c[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = zarr.open_array(\n",
    "    zarr.TempStore(),\n",
    "    \"w\",\n",
    "    (shape,),\n",
    "    chunks=(block_shape,),\n",
    "    dtype=object,\n",
    "    object_codec=numcodecs.JSON(),\n",
    ")\n",
    "b[0] = \"asdfsaf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_mask_da = da.from_zarr(\n",
    "    \"/nrs/cellmap/ackermand/cellmap/leaf-gall/validation_masks.zarr\",\n",
    "    \"jrc_22ak351-leaf-3m\",\n",
    "    chunks=(128, 128, 128),\n",
    ")\n",
    "\n",
    "start_prediction = np.array(roi.begin / 128).astype(int)\n",
    "end_prediction = np.array(roi.end / 128).astype(int)\n",
    "prediction_mask_da = prediction_mask_da[\n",
    "    start_prediction[0] : end_prediction[0],\n",
    "    start_prediction[1] : end_prediction[1],\n",
    "    start_prediction[2] : end_prediction[2],\n",
    "]\n",
    "prediction_mask_da = (\n",
    "    prediction_mask_da.repeat(16, axis=0).repeat(16, axis=1).repeat(16, axis=2)\n",
    ")\n",
    "prediction_mask_da = prediction_mask_da.rechunk((256, 256, 256))\n",
    "prediction_mask_da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.subplots(3, 1, figsize=(20, 12))\n",
    "plt.subplot(3, 1, 1)\n",
    "p = prediction_mask_da[:, 1000, :]\n",
    "p = p.compute()\n",
    "plt.imshow(p, interpolation=\"none\")\n",
    "\n",
    "gt = gt_da[:, 1000, :]\n",
    "gt = gt.compute()\n",
    "plt.subplot(3, 1, 2)\n",
    "plt.imshow(gt > 0, interpolation=\"none\")\n",
    "\n",
    "test = test_da[:, 1000, :]\n",
    "test = test.compute()\n",
    "plt.subplot(3, 1, 3)\n",
    "plt.imshow(test > 0, interpolation=\"none\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "with open(\"validation_processing_result.pickle\", \"rb\") as f:\n",
    "    res = pickle.load(f)\n",
    "test_id_counts = {}\n",
    "gt_id_counts = {}\n",
    "test_gt_counts = {}\n",
    "test_ids = {0}\n",
    "gt_ids = {0}\n",
    "for current_dict in res:\n",
    "    if current_dict:\n",
    "        for (gt_id, test_id), v in current_dict.items():\n",
    "            gt_ids.add(gt_id)\n",
    "            test_ids.add(test_id)\n",
    "            test_gt_counts[(gt_id, test_id)] = (\n",
    "                test_gt_counts.get((gt_id, test_id), 0) + v\n",
    "            )\n",
    "\n",
    "vs = np.array(list(test_id_counts.values()))\n",
    "print(np.sum(np.array(list(gt_id_counts.values())) > 0), np.sum(vs > 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_id_renumbering = {test_id: i for i, test_id in enumerate(test_ids)}\n",
    "gt_id_renumbering = {gt_id: i for i, gt_id in enumerate(gt_ids)}\n",
    "n_test = len(test_ids) - 1\n",
    "n_gt = len(gt_ids) - 1\n",
    "\n",
    "\n",
    "overlaps = np.zeros((len(test_id_renumbering), len(gt_id_renumbering)), dtype=np.int64)\n",
    "\n",
    "for (gt_id, test_id), v in test_gt_counts.items():\n",
    "    overlaps[test_id_renumbering[test_id], gt_id_renumbering[gt_id]] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "gotta ignore background...\n",
    "matches = scipy.optimize.linear_sum_assignment(\n",
    "        overlaps,\n",
    "        maximize=True)\n",
    "matches = [\n",
    "        (test_id, gt_id)\n",
    "        for test_id, gt_id in zip(matches[0], matches[1])\n",
    "        if overlaps[test_id,gt_id]>1\n",
    "        and test_id > 0\n",
    "        and gt_id > 0\n",
    "    ]\n",
    "\n",
    "tp = len(matches)\n",
    "fp = n_test - tp\n",
    "fn = n_gt - tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp, fp, fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from funlib.persistence import open_ds\n",
    "from funlib.geometry import Roi\n",
    "\n",
    "ds = open_ds(\n",
    "    \"/nrs/cellmap/ackermand/predictions/jrc_22ak351-leaf-3m/jrc_22ak351-leaf-3m.n5\",\n",
    "    \"predictions/2023-07-26/plasmodesmata_affs_lsds/0__affs\",\n",
    ")\n",
    "d = ds.to_ndarray(Roi([82296, 22800, 24704][::-1], [3856, 15696, 9072][::-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "d_pad = np.pad(\n",
    "    d, [(0, 0), (10, 10), (10, 10), (10, 10)], mode=\"constant\", constant_values=0\n",
    ")\n",
    "out = np.zeros_like(np.squeeze(d[0]))\n",
    "c = 0\n",
    "for axis in [0, 1, 2]:\n",
    "    for o in [1, 3, 9]:\n",
    "        if axis == 0:\n",
    "            default_slice = np.s_[10 + o : -(10 - o), 10:-10, 10:-10]\n",
    "        elif axis == 1:\n",
    "            default_slice = np.s_[10:-10, 10 + o : -(10 - o), 10:-10]\n",
    "        else:\n",
    "            default_slice = np.s_[10:-10, 10:-10, 10 + o : -(10 - o)]\n",
    "\n",
    "        current = np.squeeze(d_pad[c])\n",
    "        out += (current[default_slice] >= 127) + (\n",
    "            current[10:-10, 10:-10, 10:-10] >= 127\n",
    "        )\n",
    "        c += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9896158874790567"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(out == 0) / np.prod(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9898218459228268"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(out == 0) / np.prod(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=int64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([1, 2, 3, 4])\n",
    "a[:0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'tuple' object does not support item assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/groups/cellmap/cellmap/ackermand/Programming/plasmodesmata_dacapo/postprocessing/postprocessing.ipynb Cell 27\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Backermand-ws2/groups/cellmap/cellmap/ackermand/Programming/plasmodesmata_dacapo/postprocessing/postprocessing.ipynb#Y123sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Backermand-ws2/groups/cellmap/cellmap/ackermand/Programming/plasmodesmata_dacapo/postprocessing/postprocessing.ipynb#Y123sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m default_slice \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39ms_[\u001b[39m9\u001b[39m:\u001b[39m-\u001b[39m\u001b[39m9\u001b[39m,\u001b[39m9\u001b[39m:\u001b[39m-\u001b[39m\u001b[39m9\u001b[39m,\u001b[39m9\u001b[39m:\u001b[39m-\u001b[39m\u001b[39m9\u001b[39m]\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Backermand-ws2/groups/cellmap/cellmap/ackermand/Programming/plasmodesmata_dacapo/postprocessing/postprocessing.ipynb#Y123sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m default_slice[\u001b[39m0\u001b[39;49m] \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39ms_[\u001b[39m10\u001b[39m:\u001b[39m-\u001b[39m\u001b[39m10\u001b[39m]\n",
      "\u001b[0;31mTypeError\u001b[0m: 'tuple' object does not support item assignment"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "default_slice = np.s_[9:-9, 9:-9, 9:-9]\n",
    "default_slice[0] = np.s_[10:-10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/groups/cellmap/cellmap/ackermand/Programming/plasmodesmata_dacapo/postprocessing/postprocessing.ipynb Cell 26\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Backermand-ws2/groups/cellmap/cellmap/ackermand/Programming/plasmodesmata_dacapo/postprocessing/postprocessing.ipynb#Y121sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mscipy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mndimage\u001b[39;00m \u001b[39mimport\u001b[39;00m shift\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Backermand-ws2/groups/cellmap/cellmap/ackermand/Programming/plasmodesmata_dacapo/postprocessing/postprocessing.ipynb#Y121sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m shift(d,[\u001b[39m0\u001b[39;49m,\u001b[39m9\u001b[39;49m,\u001b[39m0\u001b[39;49m,\u001b[39m0\u001b[39;49m],order\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m, mode\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mconstant\u001b[39;49m\u001b[39m'\u001b[39;49m, cval\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)\n",
      "File \u001b[0;32m~/miniconda3/envs/cellmap_experiments/lib/python3.10/site-packages/scipy/ndimage/_interpolation.py:689\u001b[0m, in \u001b[0;36mshift\u001b[0;34m(input, shift, output, order, mode, cval, prefilter)\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m shift\u001b[39m.\u001b[39mflags\u001b[39m.\u001b[39mcontiguous:\n\u001b[1;32m    688\u001b[0m     shift \u001b[39m=\u001b[39m shift\u001b[39m.\u001b[39mcopy()\n\u001b[0;32m--> 689\u001b[0m _nd_image\u001b[39m.\u001b[39;49mzoom_shift(filtered, \u001b[39mNone\u001b[39;49;00m, shift, output, order, mode, cval,\n\u001b[1;32m    690\u001b[0m                      npad, \u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    691\u001b[0m \u001b[39mreturn\u001b[39;00m output\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from scipy.ndimage import shift\n",
    "\n",
    "shift(d, [0, 9, 0, 0], order=0, mode=\"constant\", cval=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = np.pad(d, [(0, 0), (9, 9), (9, 9), (9, 9)], mode=\"constant\", constant_values=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 1152, 1980, 500)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shift\n",
    "offsets = [(1,0,0),(0,1,0),(0,0,1),(3,0,0),(0,3,0),(0,0,3),(9,0,0),(0,9,0),(0,0,9)]\n",
    "s = d[s+1:-]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([i / 255 for i in range(255)], dtype=np.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.      , 0.00392 , 0.00784 , 0.011765, 0.01569 , 0.0196  ,\n",
       "       0.02353 , 0.02745 , 0.03137 , 0.0353  , 0.0392  , 0.04315 ,\n",
       "       0.04706 , 0.051   , 0.0549  , 0.05884 , 0.06274 , 0.06665 ,\n",
       "       0.0706  , 0.0745  , 0.0784  , 0.08234 , 0.0863  , 0.0902  ,\n",
       "       0.0941  , 0.098   , 0.102   , 0.1059  , 0.1098  , 0.1137  ,\n",
       "       0.1177  , 0.1216  , 0.1255  , 0.1294  , 0.1333  , 0.1372  ,\n",
       "       0.1412  , 0.1451  , 0.149   , 0.153   , 0.1569  , 0.1608  ,\n",
       "       0.1647  , 0.1686  , 0.1726  , 0.1765  , 0.1804  , 0.1843  ,\n",
       "       0.1882  , 0.1921  , 0.196   , 0.2     , 0.204   , 0.2079  ,\n",
       "       0.2118  , 0.2157  , 0.2196  , 0.2235  , 0.2274  , 0.2313  ,\n",
       "       0.2354  , 0.2393  , 0.2432  , 0.2471  , 0.251   , 0.255   ,\n",
       "       0.2588  , 0.2627  , 0.2666  , 0.2705  , 0.2744  , 0.2783  ,\n",
       "       0.2825  , 0.2864  , 0.2903  , 0.2942  , 0.298   , 0.302   ,\n",
       "       0.306   , 0.3098  , 0.3137  , 0.3176  , 0.3215  , 0.3254  ,\n",
       "       0.3293  , 0.3333  , 0.3372  , 0.341   , 0.3452  , 0.349   ,\n",
       "       0.353   , 0.357   , 0.3608  , 0.3647  , 0.3687  , 0.3726  ,\n",
       "       0.3765  , 0.3804  , 0.3843  , 0.3882  , 0.392   , 0.396   ,\n",
       "       0.4     , 0.4038  , 0.408   , 0.4119  , 0.4158  , 0.4197  ,\n",
       "       0.4236  , 0.4275  , 0.4314  , 0.4353  , 0.4392  , 0.443   ,\n",
       "       0.447   , 0.451   , 0.4548  , 0.4587  , 0.4626  , 0.4666  ,\n",
       "       0.4707  , 0.4746  , 0.4785  , 0.4824  , 0.4863  , 0.4902  ,\n",
       "       0.4941  , 0.498   , 0.502   , 0.506   , 0.51    , 0.5137  ,\n",
       "       0.5176  , 0.5215  , 0.5254  , 0.5293  , 0.533   , 0.537   ,\n",
       "       0.541   , 0.545   , 0.549   , 0.5527  , 0.5566  , 0.5605  ,\n",
       "       0.565   , 0.569   , 0.5728  , 0.5767  , 0.5806  , 0.5845  ,\n",
       "       0.5884  , 0.5923  , 0.596   , 0.6     , 0.604   , 0.608   ,\n",
       "       0.612   , 0.6157  , 0.6196  , 0.6235  , 0.6274  , 0.6313  ,\n",
       "       0.6353  , 0.639   , 0.643   , 0.647   , 0.651   , 0.655   ,\n",
       "       0.6587  , 0.6626  , 0.6665  , 0.6704  , 0.6743  , 0.678   ,\n",
       "       0.682   , 0.686   , 0.6904  , 0.6943  , 0.698   , 0.702   ,\n",
       "       0.706   , 0.71    , 0.714   , 0.718   , 0.7217  , 0.7256  ,\n",
       "       0.7295  , 0.7334  , 0.7373  , 0.741   , 0.745   , 0.749   ,\n",
       "       0.753   , 0.757   , 0.7607  , 0.7646  , 0.7686  , 0.7725  ,\n",
       "       0.7764  , 0.7803  , 0.784   , 0.788   , 0.792   , 0.796   ,\n",
       "       0.8     , 0.8037  , 0.8076  , 0.8115  , 0.816   , 0.82    ,\n",
       "       0.8237  , 0.8276  , 0.8315  , 0.8354  , 0.8394  , 0.8433  ,\n",
       "       0.847   , 0.851   , 0.855   , 0.859   , 0.863   , 0.8667  ,\n",
       "       0.8706  , 0.8745  , 0.8784  , 0.8823  , 0.886   , 0.89    ,\n",
       "       0.894   , 0.898   , 0.902   , 0.906   , 0.9097  , 0.9136  ,\n",
       "       0.9175  , 0.9214  , 0.9253  , 0.929   , 0.933   , 0.937   ,\n",
       "       0.9414  , 0.9453  , 0.949   , 0.953   , 0.957   , 0.961   ,\n",
       "       0.965   , 0.9688  , 0.9727  , 0.9766  , 0.9805  , 0.9844  ,\n",
       "       0.9883  , 0.992   , 0.996   ], dtype=float16)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.all(d, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01825692052558382"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(a) / np.prod(a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Array' object has no attribute 'data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/groups/cellmap/cellmap/ackermand/Programming/plasmodesmata_dacapo/postprocessing/postprocessing.ipynb Cell 26\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Backermand-ws2/groups/cellmap/cellmap/ackermand/Programming/plasmodesmata_dacapo/postprocessing/postprocessing.ipynb#Y111sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Backermand-ws2/groups/cellmap/cellmap/ackermand/Programming/plasmodesmata_dacapo/postprocessing/postprocessing.ipynb#Y111sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m np\u001b[39m.\u001b[39msum(d\u001b[39m.\u001b[39;49mdata\u001b[39m>\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m/\u001b[39m(\u001b[39m9\u001b[39m\u001b[39m*\u001b[39m\u001b[39m1683\u001b[39m\u001b[39m*\u001b[39m\u001b[39m1758\u001b[39m\u001b[39m*\u001b[39m\u001b[39m1888\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Array' object has no attribute 'data'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.sum(d.data > 1) / (9 * 1683 * 1758 * 1888)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.array as da\n",
    "from funlib.geometry import Roi\n",
    "import numpy as np\n",
    "\n",
    "roi = Roi((19952, 9736, 153344), (13464, 14064, 15104)).snap_to_grid((8, 8, 8))\n",
    "# need to snap to 256 since we are using that for chunk size and because chunks start at 0,0,0\n",
    "# in voxels\n",
    "s_original = np.array(roi.begin / 8).astype(int)\n",
    "e = np.array(roi.end / 8).astype(int)\n",
    "\n",
    "roi = roi.snap_to_grid((256 * 8, 256 * 8, 256 * 8))\n",
    "s = np.array(roi.begin / 8).astype(int)\n",
    "\n",
    "test_da = da.from_zarr(\n",
    "    \"/nrs/cellmap/ackermand/predictions/jrc_22ak351-leaf-3m/jrc_22ak351-leaf-3m.n5\",\n",
    "    \"processed/2023-08-17/plasmodesmata_affs_lsds/0/fragments_relabeled/\",\n",
    "    chunks=(256, 256, 256),\n",
    ")\n",
    "test_da = da.pad(\n",
    "    test_da,\n",
    "    [(s_original[i] - s[i], 0) for i in range(3)],\n",
    "    mode=\"constant\",\n",
    "    constant_values=0,\n",
    ")\n",
    "test_da = test_da.rechunk((256, 256, 256))\n",
    "\n",
    "gt_da = da.from_zarr(\n",
    "    \"/nrs/cellmap/ackermand/cellmap/leaf-gall/jrc_22ak351-leaf-3m.n5\",\n",
    "    \"larger_validation_crop\",\n",
    "    chunks=(256, 256, 256),\n",
    ")\n",
    "gt_da = gt_da[s[0] : e[0], s[1] : e[1], s[2] : e[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.random((2, 2, 2))\n",
    "b = np.random.random((2, 2, 2))\n",
    "\n",
    "print(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs, counts = np.unique(np.array([a.ravel(), b.ravel()]), axis=1, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = a[a > 2]\n",
    "np.unique(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.array as da\n",
    "from dask.distributed import Client, LocalCluster\n",
    "import numpy as np\n",
    "from scipy.ndimage import binary_erosion\n",
    "import socket\n",
    "import itertools\n",
    "from funlib.persistence import open_ds\n",
    "from funlib.geometry import Roi\n",
    "\n",
    "# startup dask\n",
    "with LocalCluster(n_workers=8, threads_per_worker=1) as cluster:\n",
    "    with Client(cluster) as client:\n",
    "        print(\n",
    "            f'Click here to monitor job: {client.dashboard_link.replace(\"127.0.0.1\", socket.gethostname())}'\n",
    "        )\n",
    "\n",
    "        # get nucleus data\n",
    "        offset = np.array([13048, 54080, 15944])\n",
    "        dimension = np.array(\n",
    "            [10696, 10536, 12960]\n",
    "            # [100,100,100]\n",
    "            # [5000, 5000, 5000]\n",
    "        )\n",
    "\n",
    "        roi = Roi(offset, dimension).snap_to_grid((16, 16, 16))\n",
    "        offset = np.array(roi.begin / 8)\n",
    "        dimension = np.array(roi.shape / 8)\n",
    "\n",
    "        # now offset = (1630, 6760, 1992)\n",
    "        # now dimension = (1338, 1318, 1622)\n",
    "        # used to be (1631, 6760, 1993)\n",
    "        # (1337, 1317, 1620)\n",
    "\n",
    "        nucleus = da.from_zarr(\n",
    "            \"/nrs/cellmap/ackermand/cellmap/jrc_mus-liver-zon-1.n5\",\n",
    "            \"nucleus\",\n",
    "            chunks=(256, 256, 256),\n",
    "        )\n",
    "        s = (offset / 2).astype(int)\n",
    "        e = ((offset + dimension) / 2).astype(int)\n",
    "        nucleus = nucleus[s[0] : e[0], s[1] : e[1], s[2] : e[2]]\n",
    "        nucleus = nucleus == 93  # the specific nucleus we are choosing\n",
    "\n",
    "        # get surface\n",
    "        surface = nucleus ^ binary_erosion(nucleus)\n",
    "\n",
    "        # convert from 16 nm to 8 nm resolution\n",
    "        surface = surface.repeat(2, axis=0).repeat(2, axis=1).repeat(2, axis=2)\n",
    "        nucleus = nucleus.repeat(2, axis=0).repeat(2, axis=1).repeat(2, axis=2)\n",
    "\n",
    "        # get pore voxels\n",
    "        pores = da.from_zarr(\n",
    "            \"/nrs/cellmap/nguyenh3/cellmap/predictions/jrc_mus-liver-zon-1/jrc_mus-liver-zon-1.n5\",\n",
    "            \"processed/2023-07-19-masked/nuclear_pores_affs_lsds/0/fragments_relabeled/\",\n",
    "            chunks=(512, 512, 512),\n",
    "        )\n",
    "\n",
    "        # so basically pores starts at whatever my predictions box is, but reading from zarr it sees that corner as 0,0,0\n",
    "        # not what the ROI actually is. (the nucleus predictions do actually start at 0,0,0 tho)\n",
    "        # so i have to subtract to make it line up\n",
    "\n",
    "        pred_roi = Roi(\n",
    "            np.array([7704, 54080, 14152]), np.array([315048, 74488, 85432])\n",
    "        ).snap_to_grid((16, 16, 16))\n",
    "        print(pred_roi)\n",
    "        pred_offset = np.array(pred_roi.begin) / 8  # to get to voxels\n",
    "        print(pred_offset)\n",
    "        pores_offset = offset - pred_offset\n",
    "        print(pores_offset)\n",
    "        s = (pores_offset).astype(int)\n",
    "        e = ((pores_offset + dimension)).astype(int)\n",
    "\n",
    "        pores = pores > 0\n",
    "        pores = pores[s[0] : e[0], s[1] : e[1], s[2] : e[2]]\n",
    "\n",
    "        # summer to return count of surface exposed faces\n",
    "        def summer(n, s):\n",
    "            return da.sum(da.map_overlap(get_surface_counts, n, s, depth=1))\n",
    "        \n",
    "        da.reduction(\n",
    "        # do calculations\n",
    "        prod = da.multiply(surface, pores)  # gets where surface and pores overlap\n",
    "        num = summer(nucleus, prod).compute()  # specifically counts surface of pores\n",
    "\n",
    "        print(f\"# surface faces at nuclear pores: {num}\")\n",
    "\n",
    "        den = summer(nucleus, surface).compute()  # counts surface of whole nuc\n",
    "\n",
    "        print(f\"# surface faces: {den}\")\n",
    "        print(f\"Fraction of surface faces at nuclear pores: {num/den}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "best.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_max = max(df[\"detection_f1\"].max(), df[\"detection_iou_f1\"].max())\n",
    "df_maxs = df[(df[\"detection_f1\"] == f1_max) | (df[\"detection_iou_f1\"] == f1_max)]\n",
    "print(f1_max, df_maxs[\"full_path\"].values)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write out segmentations as annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuroglancer.write_annotations import AnnotationWriter\n",
    "annotation_writer = AnnotationWriter(coordinate_space=,annotation_type=\"point\",relationships=[],properties=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "391068it [00:00, 440798.30it/s]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from funlib.persistence import open_ds\n",
    "\n",
    "mask = open_ds(\n",
    "    \"/nrs/cellmap/jonesa/jrc_22ak351-leaf-3m/crop352_mask_revised.zarr\", \"s0\"\n",
    ")\n",
    "mask.materialize()\n",
    "frags = pd.read_csv(\n",
    "    \"/nrs/cellmap/ackermand/cellmap/analysisResults/leaf-gall/jrc_22ak351-leaf-3m.n5/fragments_relabeled.csv\"\n",
    ")\n",
    "volume = frags[\"Volume (nm^3)\"].to_numpy()\n",
    "offsets = np.array([22400.0, 12800.0, 0])\n",
    "count = 0\n",
    "ids = frags[\"Object ID\"].to_numpy()\n",
    "com_z = frags[\"COM Z (nm)\"].to_numpy() - offsets[0]\n",
    "com_y = frags[\"COM Y (nm)\"].to_numpy() - offsets[1]\n",
    "com_x = frags[\"COM X (nm)\"].to_numpy() - offsets[2]\n",
    "ids_to_keep = np.ones_like(ids, dtype=bool)\n",
    "for idx, (id, v, z, y, x) in tqdm(enumerate(zip(ids, volume, com_z, com_y, com_x))):\n",
    "    try:\n",
    "        if (\n",
    "            v < (250 * 8**3)\n",
    "            or mask.data[int(z // 128), int(y // 128), int(x // 128)] > 0\n",
    "        ):\n",
    "            ids_to_keep[idx] = 0\n",
    "            # print(np.sum(v<10*10*10*8*8*8)/len(v),len(v))\n",
    "            # plt.hist(v,bins=list(range(0,3_000_000,100000)))\n",
    "            # ds.data\n",
    "    except:\n",
    "        ids_to_keep[idx] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## useful link showing coloring of points based on density:\n",
    "https://neuroglancer-demo.appspot.com/#!gs://flyem-user-links/short/2023-10-09.205321.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "199409"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids_to_keep.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 199409/199409 [01:05<00:00, 3027.48it/s] \n",
      "100%|██████████| 10000/10000 [00:00<00:00, 187201.42it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'precomputed://https://cellmap-vm1.int.janelia.org/dm11/ackermand/neuroglancer_annotations/segmentations/fragments_relabeled_with_property_point'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import struct\n",
    "import os\n",
    "import struct\n",
    "import numpy as np\n",
    "import json\n",
    "from time import sleep\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def write_precomputed_annotations(annotation_type, annotations, densities):\n",
    "    # write_time = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    output_directory = f\"/groups/cellmap/cellmap/ackermand/neuroglancer_annotations/segmentations/fragments_relabeled_with_property_{annotation_type}\"\n",
    "    os.system(f\"rm -rf {output_directory}\")\n",
    "    os.makedirs(f\"{output_directory}/spatial0\", exist_ok=True)\n",
    "    os.makedirs(f\"{output_directory}/relationships\", exist_ok=True)\n",
    "\n",
    "    if annotation_type == \"line\":\n",
    "        coords_to_write = 6\n",
    "    else:\n",
    "        coords_to_write = 3\n",
    "\n",
    "    annotations_and_densities = list(zip(annotations, densities))\n",
    "    with open(f\"{output_directory}/spatial0/0_0_0\", \"wb\") as outfile:\n",
    "        total_count = len(annotations)\n",
    "        buf = struct.pack(\"<Q\", total_count)\n",
    "        for annotation, density in tqdm(annotations_and_densities):\n",
    "            annotation_buf = struct.pack(f\"<{coords_to_write}f\", *annotation)\n",
    "            buf += annotation_buf\n",
    "            buf += struct.pack(f\"<1f\", np.float32(density))  # property\n",
    "\n",
    "            # if c < 10000:\n",
    "            #     buf += struct.pack(f\"<I\", 1)  # number of objects it is associated with\n",
    "            #     buf += struct.pack(f\"<Q\", 1)  # ids it is associated with\n",
    "            # else:\n",
    "            #     buf += struct.pack(f\"<I\", 0)  # ids it is associated with\n",
    "\n",
    "        # write the ids at the end of the buffer as increasing integers\n",
    "        id_buf = struct.pack(\n",
    "            f\"<{total_count}Q\", *range(1, len(annotations) + 1, 1)\n",
    "        )  # so start at 1\n",
    "        # id_buf = struct.pack('<%sQ' % len(coordinates), 3,1 )#s*range(len(coordinates)))\n",
    "        buf += id_buf\n",
    "        outfile.write(buf)\n",
    "\n",
    "    with open(f\"{output_directory}/relationships/1\", \"wb\") as outfile:\n",
    "        annotations = annotations[:10000]\n",
    "        densities = densities[:10000]\n",
    "        annotations_and_densities = list(zip(annotations, densities))\n",
    "        total_count = len(annotations_and_densities)\n",
    "        buf = struct.pack(\"<Q\", total_count)\n",
    "        for annotation, density in tqdm(annotations_and_densities):\n",
    "            annotation_buf = struct.pack(f\"<{coords_to_write}f\", *annotation)\n",
    "            buf += annotation_buf\n",
    "            buf += struct.pack(f\"<1f\", np.float32(density))  # property\n",
    "\n",
    "        # write the ids at the end of the buffer as increasing integers\n",
    "        id_buf = struct.pack(\n",
    "            f\"<{total_count}Q\", *range(1, len(annotations) + 1, 1)\n",
    "        )  # so start at 1\n",
    "        # id_buf = struct.pack('<%sQ' % len(coordinates), 3,1 )#s*range(len(coordinates)))\n",
    "        buf += id_buf\n",
    "        outfile.write(buf)\n",
    "\n",
    "    max_extents = annotations.reshape((-1, 3)).max(axis=0) + 1\n",
    "    max_extents = [int(max_extent) for max_extent in max_extents]\n",
    "    info = {\n",
    "        \"@type\": \"neuroglancer_annotations_v1\",\n",
    "        \"dimensions\": {\"x\": [1, \"nm\"], \"y\": [1, \"nm\"], \"z\": [1, \"nm\"]},\n",
    "        \"by_id\": {\"key\": \"by_id\"},\n",
    "        \"lower_bound\": [0, 0, 0],\n",
    "        \"upper_bound\": max_extents,\n",
    "        \"annotation_type\": annotation_type,\n",
    "        \"properties\": [{\"id\": \"density\", \"type\": \"float32\", \"description\": \"density\"}],\n",
    "        \"relationships\": [{\"id\": \"associated_column_cell\", \"key\": \"relationships\"}],\n",
    "        \"spatial\": [\n",
    "            {\n",
    "                \"chunk_size\": max_extents,\n",
    "                \"grid_shape\": [1, 1, 1],\n",
    "                \"key\": \"spatial0\",\n",
    "                \"limit\": 1,\n",
    "            }\n",
    "        ],\n",
    "    }\n",
    "\n",
    "    with open(f\"{output_directory}/info\", \"w\") as info_file:\n",
    "        json.dump(info, info_file)\n",
    "\n",
    "    return output_directory.replace(\n",
    "        \"/groups/cellmap/cellmap/ackermand/\",\n",
    "        \"precomputed://https://cellmap-vm1.int.janelia.org/dm11/ackermand/\",\n",
    "    )\n",
    "\n",
    "\n",
    "frags = pd.read_csv(\n",
    "    \"/nrs/cellmap/ackermand/cellmap/analysisResults/leaf-gall/jrc_22ak351-leaf-3m.n5/fragments_relabeled.csv\"\n",
    ")\n",
    "id = frags[\"Object ID\"]\n",
    "com_x = frags[\"COM X (nm)\"].to_numpy()\n",
    "com_y = frags[\"COM Y (nm)\"].to_numpy()\n",
    "com_z = frags[\"COM Z (nm)\"].to_numpy()\n",
    "min_x = frags[\"MIN X (nm)\"].to_numpy()\n",
    "min_y = frags[\"MIN Y (nm)\"].to_numpy()\n",
    "min_z = frags[\"MIN Z (nm)\"].to_numpy()\n",
    "max_x = frags[\"MAX X (nm)\"].to_numpy()\n",
    "max_y = frags[\"MAX Y (nm)\"].to_numpy()\n",
    "max_z = frags[\"MAX Z (nm)\"].to_numpy()\n",
    "annotations = np.column_stack(\n",
    "    (\n",
    "        min_x[ids_to_keep],\n",
    "        min_y[ids_to_keep],\n",
    "        min_z[ids_to_keep],\n",
    "        max_x[ids_to_keep],\n",
    "        max_y[ids_to_keep],\n",
    "        max_z[ids_to_keep],\n",
    "    )\n",
    ")\n",
    "\n",
    "import numpy as np\n",
    "import scipy.spatial as spatial\n",
    "\n",
    "tree = spatial.KDTree(\n",
    "    np.column_stack([com_x[ids_to_keep], com_y[ids_to_keep], com_z[ids_to_keep]])\n",
    ")\n",
    "radius = 1000.0\n",
    "neighbors = tree.query_ball_tree(tree, radius)\n",
    "densities = np.array([len(n) for n in neighbors])\n",
    "# densities = densities / densities.max()\n",
    "\n",
    "# # write_precomputed_annotations(\"line\", annotations)\n",
    "# # write_precomputed_annotations(\n",
    "# #     \"line\",\n",
    "# #     annotations,\n",
    "# #     densities,\n",
    "# # )\n",
    "\n",
    "write_precomputed_annotations(\n",
    "    \"point\",\n",
    "    np.column_stack((com_x[ids_to_keep], com_y[ids_to_keep], com_z[ids_to_keep])),\n",
    "    densities,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "199409"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids_to_keep.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11.357742, 79.70125599999999)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "densities.max()*0.0767415,densities.max()*0.538522"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://neuroglancer-demo.appspot.com/#!gs://flyem-user-links/short/2023-10-06.195006.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "# import numpy as np\n",
    "# from scipy.optimize import leastsq\n",
    "\n",
    "# # https://stackoverflow.com/a/44164662\n",
    "# def cylinderFitting(xyz,p,th):\n",
    "\n",
    "#     \"\"\"\n",
    "#     This is a fitting for a vertical cylinder fitting\n",
    "#     Reference:\n",
    "#     http://www.int-arch-photogramm-remote-sens-spatial-inf-sci.net/XXXIX-B5/169/2012/isprsarchives-XXXIX-B5-169-2012.pdf\n",
    "\n",
    "#     xyz is a matrix contain at least 5 rows, and each row stores x y z of a cylindrical surface\n",
    "#     p is initial values of the parameter;\n",
    "#     p[0] = Xc, x coordinate of the cylinder centre\n",
    "#     P[1] = Yc, y coordinate of the cylinder centre\n",
    "#     P[2] = alpha, rotation angle (radian) about the x-axis\n",
    "#     P[3] = beta, rotation angle (radian) about the y-axis\n",
    "#     P[4] = r, radius of the cylinder\n",
    "\n",
    "#     th, threshold for the convergence of the least squares\n",
    "\n",
    "#     \"\"\"\n",
    "#     x = xyz[:,0]\n",
    "#     y = xyz[:,1]\n",
    "#     z = xyz[:,2]\n",
    "\n",
    "#     fitfunc = lambda p, x, y, z: (- np.cos(p[3])*(p[0] - x) - z*np.cos(p[2])*np.sin(p[3]) - np.sin(p[2])*np.sin(p[3])*(p[1] - y))**2 + (z*np.sin(p[2]) - np.cos(p[2])*(p[1] - y))**2 #fit function\n",
    "#     errfunc = lambda p, x, y, z: fitfunc(p, x, y, z) - p[4]**2 #error function\n",
    "\n",
    "#     est_p , success = leastsq(errfunc, p, args=(x, y, z), maxfev=1000)\n",
    "\n",
    "#     return est_p\n",
    "\n",
    "# def cylinder_function(x):\n",
    "#     return None\n",
    "\n",
    "# def cylindrical_fit():\n",
    "#     # read in image\n",
    "#     # select desired id\n",
    "#     # extract x,y,z\n",
    "#     return None\n",
    "#     # scipy.optimize.least_squares(fun, )\n",
    "\n",
    "\n",
    "def in_cylinder(end_1, end_2, radius):\n",
    "    # https://stackoverflow.com/questions/56463412/distance-from-a-point-to-a-line-segment-in-3d-python\n",
    "    # normalized tangent vector\n",
    "    d = np.divide(end_2 - end_1, np.linalg.norm(end_2 - end_1))\n",
    "\n",
    "    # possible points\n",
    "    mins = np.floor(np.minimum(end_1, end_2)).astype(int) - (\n",
    "        np.ceil(radius).astype(int) + 1\n",
    "    )  # 1s for padding\n",
    "    maxs = np.ceil(np.maximum(end_1, end_2)).astype(int) + (\n",
    "        np.ceil(radius).astype(int) + 1\n",
    "    )\n",
    "    x, y, z = [list(range(mins[i], maxs[i] + 1, 1)) for i in range(3)]\n",
    "    p = np.array(np.meshgrid(x, y, z)).T.reshape((-1, 3))\n",
    "\n",
    "    # signed parallel distance components\n",
    "    s = np.dot(end_1 - p, d)\n",
    "    t = np.dot(p - end_2, d)\n",
    "\n",
    "    # clamped parallel distance\n",
    "    h = np.maximum.reduce([s, t, np.zeros_like(s)])\n",
    "\n",
    "    # perpendicular distance component\n",
    "    c = np.linalg.norm(np.cross(p - end_1, d), axis=1)\n",
    "\n",
    "    is_in_cylinder = (h == 0) & (c <= radius)\n",
    "    return set(map(tuple, p[is_in_cylinder]))\n",
    "\n",
    "\n",
    "def line_seg_dist(x, predicted_points):\n",
    "    end_1 = x[:3]\n",
    "    end_2 = x[3:]\n",
    "    # normalized tangent vector\n",
    "    d = np.divide(end_2 - end_1, np.linalg.norm(end_2 - end_1))\n",
    "\n",
    "    # signed parallel distance components\n",
    "    s = np.dot(end_1 - predicted_points, d)\n",
    "    t = np.dot(predicted_points - end_2, d)\n",
    "\n",
    "    # clamped parallel distance\n",
    "    h = np.maximum.reduce([s, t, np.zeros_like(s)])\n",
    "\n",
    "    # perpendicular distance component\n",
    "    c = np.cross(predicted_points - end_1, d)\n",
    "\n",
    "    return np.mean(np.hypot(h, np.linalg.norm(c)))\n",
    "\n",
    "\n",
    "def cylinder_f1_score(x, predicted_points):\n",
    "    end_1 = x[:3]\n",
    "    end_2 = x[3:]\n",
    "    cylindrical_fit_points = in_cylinder(end_1, end_2, radius=6)\n",
    "    true_positives = len(predicted_points & cylindrical_fit_points)\n",
    "    false_positives = len(predicted_points - cylindrical_fit_points)\n",
    "    false_negatives = len(cylindrical_fit_points - predicted_points)\n",
    "    f1_score = true_positives / (\n",
    "        true_positives + 0.5 * (false_positives + false_negatives)\n",
    "    )\n",
    "    # print(end_1, end_2, -f1_score)\n",
    "    # f1_score = np.median(-cdist(list(predicted_points), list(cylindrical_fit_points)))\n",
    "    # print(f1_score)\n",
    "    return -f1_score  # negative for minimize\n",
    "\n",
    "\n",
    "predicted_image = np.zeros((100, 100, 100))\n",
    "for x in range(100):\n",
    "    for y in range(100):\n",
    "        for z in range(100):\n",
    "            if z >= 25 and z < 90:\n",
    "                if (x - 50) ** 2 + (y - 20) ** 2 <= 6**2:\n",
    "                    predicted_image[x, y, z] = 1\n",
    "x, y, z = np.where(predicted_image)\n",
    "initial_guess = np.array([min(x), min(y), min(z), max(x), max(y), max(z)])\n",
    "predicted_points = set(tuple(zip(x, y, z)))\n",
    "\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "# res = minimize(\n",
    "#     lambda x: cylinder_f1_score(x, predicted_points),\n",
    "#     initial_guess,\n",
    "# )\n",
    "res = minimize(\n",
    "    lambda x: line_seg_dist(x, np.array(list(predicted_points))),\n",
    "    initial_guess,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  message: Optimization terminated successfully.\n",
       "  success: True\n",
       "   status: 0\n",
       "      fun: 363.7856512081891\n",
       "        x: [ 5.000e+01  2.000e+01  2.503e+01  5.000e+01  2.000e+01\n",
       "             8.897e+01]\n",
       "      nit: 10\n",
       "      jac: [ 0.000e+00  0.000e+00  0.000e+00  7.629e-06  0.000e+00\n",
       "             0.000e+00]\n",
       " hess_inv: [[ 2.056e-01  1.654e-02 ... -7.312e-03 -5.644e-02]\n",
       "            [ 1.654e-02  1.575e-01 ... -7.233e-02 -4.396e-02]\n",
       "            ...\n",
       "            [-7.312e-03 -7.233e-02 ...  1.934e-01  4.879e-02]\n",
       "            [-5.644e-02 -4.396e-02 ...  4.879e-02  8.988e-01]]\n",
       "     nfev: 112\n",
       "     njev: 16"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  message: Optimization terminated successfully.\n",
       "  success: True\n",
       "   status: 0\n",
       "      fun: 363.7856512081891\n",
       "        x: [ 5.000e+01  2.000e+01  2.503e+01  5.000e+01  2.000e+01\n",
       "             8.897e+01]\n",
       "      nit: 10\n",
       "      jac: [ 0.000e+00  0.000e+00  0.000e+00  7.629e-06  0.000e+00\n",
       "             0.000e+00]\n",
       " hess_inv: [[ 2.056e-01  1.654e-02 ... -7.312e-03 -5.644e-02]\n",
       "            [ 1.654e-02  1.575e-01 ... -7.233e-02 -4.396e-02]\n",
       "            ...\n",
       "            [-7.312e-03 -7.233e-02 ...  1.934e-01  4.879e-02]\n",
       "            [-5.644e-02 -4.396e-02 ...  4.879e-02  8.988e-01]]\n",
       "     nfev: 112\n",
       "     njev: 16"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  message: Optimization terminated successfully.\n",
       "  success: True\n",
       "   status: 0\n",
       "      fun: -0.15468620403649433\n",
       "        x: [ 8.900e+01  2.600e+01  5.600e+01  2.700e+01  1.800e+01\n",
       "             4.900e+01]\n",
       "      nit: 1\n",
       "      jac: [ 0.000e+00  0.000e+00  0.000e+00  0.000e+00  0.000e+00\n",
       "             0.000e+00]\n",
       " hess_inv: [[1 0 ... 0 0]\n",
       "            [0 1 ... 0 0]\n",
       "            ...\n",
       "            [0 0 ... 1 0]\n",
       "            [0 0 ... 0 1]]\n",
       "     nfev: 77\n",
       "     njev: 11"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  message: Optimization terminated successfully.\n",
       "  success: True\n",
       "   status: 0\n",
       "      fun: -0.5721403083552145\n",
       "        x: [ 4.400e+01  1.400e+01  2.500e+01  5.600e+01  2.600e+01\n",
       "             8.900e+01]\n",
       "      nit: 1\n",
       "      jac: [ 0.000e+00  0.000e+00  0.000e+00  0.000e+00  0.000e+00\n",
       "             0.000e+00]\n",
       " hess_inv: [[1 0 ... 0 0]\n",
       "            [0 1 ... 0 0]\n",
       "            ...\n",
       "            [0 0 ... 1 0]\n",
       "            [0 0 ... 0 1]]\n",
       "     nfev: 77\n",
       "     njev: 11"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "dist = cdist(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_cylinder([4.400e01, 1.400e01, 2.500e01], end_2, radius)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f29af4ae200>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(predicted_image[50, :, :] > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2**3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{(52, 20, 78), (52, 19, 33), (50, 20, 86), (51, 20, 53), (52, 21, 42), (48, 20, 29), (51, 21, 54), (52, 21, 78), (48, 21, 30), (49, 21, 54), (48, 19, 69), (50, 20, 63), (51, 20, 30), (51, 20, 66), (51, 21, 31), (52, 21, 55), (48, 20, 42), (49, 21, 31), (49, 20, 72), (50, 19, 75), (50, 20, 40), (48, 19, 82), (52, 20, 68), (51, 20, 43), (52, 21, 32), (50, 22, 85), (51, 22, 89), (51, 19, 83), (49, 19, 84), (50, 18, 87), (50, 19, 52), (48, 19, 59), (49, 20, 85), (52, 20, 45), (50, 19, 88), (50, 20, 53), (52, 20, 81), (52, 21, 45), (51, 19, 60), (50, 18, 64), (48, 19, 36), (49, 20, 62), (50, 19, 65), (50, 20, 30), (48, 19, 72), (52, 20, 58), (51, 20, 33), (51, 18, 72), (50, 22, 75), (51, 22, 79), (51, 19, 73), (49, 19, 74), (49, 20, 39), (50, 18, 77), (50, 19, 42), (48, 19, 49), (49, 20, 75), (52, 20, 35), (50, 21, 88), (50, 20, 43), (49, 22, 84), (50, 22, 52), (52, 19, 75), (51, 22, 56), (51, 18, 85), (51, 19, 50), (49, 18, 86), (49, 19, 51), (50, 22, 88), (50, 18, 54), (48, 19, 26), (49, 19, 87), (49, 20, 52), (48, 21, 72), (50, 19, 55), (52, 20, 48), (51, 18, 62), (51, 19, 27), (49, 18, 63), (50, 22, 65), (52, 19, 88), (51, 22, 69), (50, 18, 31), (51, 19, 63), (49, 19, 64), (49, 20, 29), (48, 20, 84), (50, 18, 67), (50, 19, 32), (48, 19, 39), (52, 20, 25), (50, 21, 78), (48, 21, 85), (49, 22, 74), (51, 18, 39), (50, 22, 42), (52, 19, 65), (51, 22, 46), (51, 18, 75), (51, 19, 40), (49, 18, 76), (49, 19, 41), (50, 18, 44), (51, 21, 86), (49, 20, 42), (50, 21, 55), (48, 21, 62), (49, 21, 86), (49, 22, 51), (52, 19, 42), (49, 22, 87), (51, 18, 52), (49, 18, 53), (50, 22, 55), (52, 19, 78), (51, 22, 59), (51, 21, 63), (49, 19, 54), (52, 21, 87), (48, 20, 74), (48, 21, 39), (50, 21, 68), (48, 21, 75), (49, 22, 64), (51, 18, 29), (49, 18, 30), (50, 22, 32), (52, 19, 55), (51, 22, 36), (51, 20, 75), (51, 19, 30), (49, 18, 66), (49, 19, 31), (50, 18, 34), (51, 21, 76), (50, 21, 45), (48, 20, 87), (48, 21, 52), (49, 21, 76), (49, 22, 41), (52, 19, 32), (50, 20, 85), (51, 18, 42), (49, 18, 43), (51, 20, 88), (51, 21, 53), (52, 21, 77), (48, 20, 64), (48, 21, 29), (49, 21, 53), (50, 21, 58), (49, 22, 54), (52, 19, 45), (51, 22, 26), (51, 20, 65), (51, 21, 30), (48, 20, 41), (51, 21, 66), (50, 21, 35), (48, 21, 42), (49, 21, 66), (48, 19, 81), (49, 22, 31), (50, 20, 75), (49, 18, 33), (51, 20, 78), (51, 21, 43), (52, 21, 67), (48, 20, 54), (49, 21, 43), (49, 20, 84), (50, 19, 87), (50, 20, 52), (49, 22, 44), (52, 20, 80), (50, 20, 88), (51, 20, 55), (52, 21, 44), (48, 20, 31), (50, 21, 25), (48, 21, 32), (50, 19, 64), (49, 21, 56), (48, 19, 71), (52, 20, 57), (50, 20, 65), (51, 20, 32), (51, 21, 33), (52, 21, 57), (51, 19, 72), (48, 20, 44), (50, 18, 76), (49, 21, 33), (48, 19, 48), (49, 20, 74), (50, 19, 77), (50, 20, 42), (48, 19, 84), (52, 20, 70), (51, 20, 45), (51, 18, 84), (52, 21, 34), (50, 22, 87), (51, 19, 85), (49, 19, 86), (49, 20, 51), (50, 18, 89), (50, 19, 54), (48, 19, 61), (49, 20, 87), (52, 20, 47), (50, 20, 55), (52, 19, 87), (51, 22, 68), (52, 21, 47), (51, 19, 62), (49, 19, 63), (50, 18, 66), (50, 19, 31), (48, 19, 38), (49, 20, 64), (48, 21, 84), (50, 19, 67), (50, 20, 32), (52, 20, 60), (51, 20, 35), (51, 18, 74), (51, 19, 39), (49, 18, 75), (50, 22, 77), (51, 22, 81), (50, 18, 43), (51, 19, 75), (49, 19, 76), (49, 20, 41), (50, 18, 79), (50, 19, 44), (48, 19, 51), (52, 20, 37), (49, 22, 86), (51, 18, 51), (50, 22, 54), (52, 19, 77), (51, 22, 58), (51, 18, 87), (51, 19, 52), (49, 18, 88), (49, 19, 53), (50, 18, 56), (48, 19, 28), (49, 20, 54), (50, 21, 67), (48, 21, 74), (52, 20, 50), (52, 19, 54), (51, 22, 35), (51, 18, 64), (51, 19, 29), (49, 18, 65), (49, 19, 30), (50, 22, 67), (51, 22, 71), (50, 18, 33), (51, 21, 75), (49, 19, 66), (49, 20, 31), (48, 20, 86), (50, 19, 34), (52, 20, 27), (50, 21, 80), (48, 21, 87), (49, 22, 76), (51, 18, 41), (49, 18, 42), (50, 22, 44), (52, 19, 67), (51, 22, 48), (51, 19, 42), (49, 18, 78), (49, 19, 43), (50, 18, 46), (51, 21, 88), (50, 21, 57), (48, 21, 64), (49, 21, 88), (49, 22, 53), (52, 19, 44), (51, 22, 25), (49, 22, 89), (51, 18, 54), (49, 18, 55), (50, 22, 57), (51, 21, 65), (52, 21, 89), (48, 20, 76), (48, 21, 41), (49, 21, 65), (50, 21, 70), (48, 21, 77), (49, 22, 66), (51, 18, 31), (49, 18, 32), (50, 22, 34), (52, 19, 57), (51, 22, 38), (51, 20, 77), (49, 19, 33), (48, 20, 53), (50, 18, 36), (51, 21, 78), (50, 21, 47), (48, 20, 89), (48, 21, 54), (49, 21, 78), (49, 22, 43), (52, 19, 34), (50, 20, 87), (51, 18, 44), (49, 18, 45), (51, 21, 55), (52, 21, 79), (48, 20, 66), (48, 21, 31), (49, 21, 55), (50, 21, 60), (50, 20, 64), (49, 22, 56), (51, 20, 67), (51, 21, 32), (52, 21, 56), (48, 20, 43), (51, 21, 68), (49, 21, 32), (50, 21, 37), (48, 21, 44), (50, 19, 76), (49, 21, 68), (48, 19, 83), (49, 22, 33), (50, 20, 77), (51, 20, 44), (49, 18, 35), (51, 20, 80), (51, 21, 45), (52, 21, 69), (51, 19, 84), (48, 20, 56), (50, 18, 88), (49, 21, 45), (49, 20, 86), (50, 19, 89), (50, 20, 54), (52, 20, 82), (51, 20, 57), (52, 21, 46), (48, 20, 33), (49, 20, 63), (50, 21, 27), (50, 19, 66), (50, 20, 31), (48, 19, 73), (52, 20, 59), (50, 20, 67), (51, 20, 34), (51, 22, 80), (51, 21, 35), (52, 21, 59), (51, 19, 74), (49, 19, 75), (50, 18, 78), (49, 21, 35), (48, 19, 50), (49, 20, 76), (50, 19, 79), (50, 20, 44), (52, 20, 72), (51, 20, 47), (51, 18, 86), (52, 21, 36), (49, 18, 87), (50, 22, 89), (51, 19, 87), (49, 19, 88), (49, 20, 53), (50, 19, 56), (48, 19, 63), (52, 20, 49), (50, 22, 66), (52, 19, 89), (51, 22, 70), (51, 19, 64), (49, 19, 65), (50, 18, 68), (50, 19, 33), (48, 19, 40), (49, 20, 66), (52, 20, 26), (48, 21, 86), (50, 20, 34), (52, 20, 62), (52, 19, 66), (51, 22, 47), (51, 18, 76), (51, 19, 41), (49, 18, 77), (50, 22, 79), (52, 21, 26), (51, 22, 83), (50, 18, 45), (49, 19, 78), (49, 20, 43), (50, 18, 81), (50, 19, 46), (48, 19, 53), (52, 20, 39), (49, 22, 88), (51, 18, 53), (50, 22, 56), (52, 19, 79), (51, 22, 60), (51, 18, 89), (51, 19, 54), (49, 19, 55), (50, 18, 58), (48, 19, 30), (50, 21, 69), (48, 21, 76), (49, 22, 65), (50, 22, 33), (52, 19, 56), (51, 22, 37), (51, 18, 66), (51, 19, 31), (49, 18, 67), (49, 19, 32), (50, 22, 69), (50, 18, 35), (51, 21, 77), (49, 19, 68), (49, 20, 33), (48, 20, 88), (48, 21, 53), (50, 19, 36), (49, 21, 77), (52, 20, 29), (50, 21, 82), (48, 21, 89), (49, 22, 78), (51, 18, 43), (49, 18, 44), (50, 22, 46), (52, 19, 69), (51, 22, 50), (51, 20, 89), (51, 19, 44), (49, 18, 80), (49, 19, 45), (48, 20, 65), (50, 18, 48), (50, 21, 59), (48, 21, 66), (49, 22, 55), (52, 19, 46), (51, 22, 27), (51, 18, 56), (49, 18, 57), (50, 18, 25), (51, 21, 67), (50, 21, 36), (48, 20, 78), (48, 21, 43), (49, 21, 67), (49, 22, 32), (50, 21, 72), (50, 20, 76), (49, 22, 68), (51, 18, 33), (49, 18, 34), (50, 22, 36), (52, 19, 59), (51, 22, 40), (51, 20, 79), (51, 21, 44), (49, 19, 35), (52, 21, 68), (48, 20, 55), (51, 21, 80), (49, 21, 44), (50, 21, 49), (48, 21, 56), (49, 21, 80), (49, 22, 45), (52, 19, 36), (50, 20, 89), (51, 20, 56), (49, 18, 47), (48, 20, 32), (51, 21, 57), (52, 21, 81), (50, 21, 26), (48, 20, 68), (48, 21, 33), (49, 21, 57), (50, 20, 66), (51, 20, 69), (51, 21, 34), (52, 21, 58), (48, 20, 45), (49, 21, 34), (50, 21, 39), (50, 19, 78), (48, 19, 85), (49, 22, 35), (52, 20, 71), (52, 19, 26), (50, 20, 79), (51, 20, 46), (52, 21, 35), (51, 21, 47), (52, 21, 71), (51, 19, 86), (49, 21, 47), (48, 19, 62), (49, 20, 88), (50, 20, 56), (52, 20, 84), (51, 20, 59), (52, 21, 48), (48, 20, 35), (49, 20, 65), (50, 19, 68), (50, 20, 33), (48, 19, 75), (49, 22, 25), (52, 20, 61), (50, 20, 69), (51, 20, 36), (52, 21, 25), (50, 22, 78), (51, 22, 82), (51, 19, 76), (49, 19, 77), (50, 18, 80), (50, 19, 45), (49, 21, 37), (48, 19, 52), (49, 20, 78), (52, 20, 38), (50, 19, 81), (50, 20, 46), (52, 20, 74), (51, 18, 88), (51, 19, 53), (49, 18, 89), (52, 21, 38), (48, 20, 25), (50, 18, 57), (48, 19, 29), (51, 19, 89), (49, 20, 55), (50, 19, 58), (48, 19, 65), (52, 20, 51), (51, 20, 26), (51, 18, 65), (50, 22, 68), (51, 22, 72), (51, 19, 66), (49, 19, 67), (49, 20, 32), (50, 18, 70), (50, 19, 35), (48, 19, 42), (49, 20, 68), (52, 20, 28), (50, 21, 81), (48, 21, 88), (50, 20, 36), (49, 22, 77), (50, 22, 45), (52, 19, 68), (51, 22, 49), (51, 18, 78), (51, 19, 43), (49, 18, 79), (49, 19, 44), (50, 22, 81), (52, 21, 28), (51, 22, 85), (50, 18, 47), (51, 21, 89), (49, 19, 80), (49, 20, 45), (48, 21, 65), (50, 19, 48), (49, 21, 89), (52, 20, 41), (51, 18, 55), (49, 18, 56), (50, 22, 58), (52, 19, 81), (51, 22, 62), (51, 19, 56), (49, 19, 57), (48, 20, 77), (50, 18, 60), (50, 19, 25), (48, 19, 32), (50, 21, 71), (48, 21, 78), (49, 22, 67), (51, 18, 32), (50, 22, 35), (52, 19, 58), (51, 22, 39), (51, 18, 68), (51, 19, 33), (49, 18, 69), (49, 19, 34), (50, 18, 37), (51, 21, 79), (49, 20, 35), (50, 21, 48), (48, 21, 55), (49, 21, 79), (52, 20, 31), (50, 21, 84), (52, 19, 35), (49, 22, 80), (51, 18, 45), (49, 18, 46), (50, 22, 48), (52, 19, 71), (51, 22, 52), (51, 21, 56), (49, 19, 47), (52, 21, 80), (48, 20, 67), (50, 21, 61), (48, 21, 68), (49, 22, 57), (50, 22, 25), (52, 19, 48), (51, 22, 29), (51, 20, 68), (49, 18, 59), (50, 18, 27), (51, 21, 69), (50, 21, 38), (48, 20, 80), (48, 21, 45), (49, 21, 69), (49, 22, 34), (52, 19, 25), (50, 20, 78), (49, 22, 70), (51, 18, 35), (49, 18, 36), (50, 22, 38), (51, 20, 81), (51, 21, 46), (52, 21, 70), (48, 20, 57), (49, 21, 46), (50, 21, 51), (48, 21, 58), (49, 21, 82), (49, 22, 47), (52, 20, 83), (52, 19, 38), (51, 20, 58), (48, 20, 34), (51, 21, 59), (52, 21, 83), (50, 21, 28), (48, 20, 70), (48, 21, 35), (49, 21, 59), (48, 19, 74), (50, 20, 68), (49, 18, 26), (51, 20, 71), (51, 21, 36), (52, 21, 60), (48, 20, 47), (49, 21, 36), (49, 20, 77), (50, 21, 41), (50, 19, 80), (50, 20, 45), (48, 19, 87), (49, 22, 37), (52, 20, 73), (50, 20, 81), (51, 20, 48), (52, 21, 37), (51, 21, 49), (52, 21, 73), (51, 19, 88), (49, 19, 89), (48, 21, 25), (50, 19, 57), (49, 21, 49), (48, 19, 64), (50, 20, 58), (51, 20, 25), (52, 20, 86), (51, 20, 61), (51, 21, 26), (52, 21, 50), (51, 19, 65), (48, 20, 37), (50, 18, 69), (49, 21, 26), (48, 19, 41), (49, 20, 67), (50, 19, 70), (50, 20, 35), (48, 19, 77), (52, 20, 63), (51, 20, 38), (51, 18, 77), (52, 21, 27), (50, 22, 80), (51, 22, 84), (51, 19, 78), (49, 19, 79), (49, 20, 44), (50, 18, 82), (50, 19, 47), (48, 19, 54), (49, 20, 80), (52, 20, 40), (50, 20, 48), (52, 20, 76), (52, 19, 80), (51, 22, 61), (52, 21, 40), (51, 19, 55), (49, 19, 56), (50, 18, 59), (48, 19, 31), (49, 20, 57), (50, 19, 60), (50, 20, 25), (52, 20, 53), (51, 20, 28), (51, 18, 67), (51, 19, 32), (49, 18, 68), (50, 22, 70), (51, 22, 74), (51, 19, 68), (49, 19, 69), (49, 20, 34), (50, 18, 72), (50, 19, 37), (48, 19, 44), (52, 20, 30), (50, 21, 83), (49, 22, 79), (50, 22, 47), (52, 19, 70), (51, 22, 51), (51, 18, 80), (51, 19, 45), (49, 18, 81), (49, 19, 46), (50, 22, 83), (50, 18, 49), (49, 20, 47), (48, 21, 67), (52, 20, 43), (52, 19, 47), (51, 22, 28), (51, 18, 57), (49, 18, 58), (50, 22, 60), (52, 19, 83), (51, 22, 64), (50, 18, 26), (49, 19, 59), (48, 20, 79), (50, 19, 27), (48, 19, 34), (50, 21, 73), (48, 21, 80), (49, 22, 69), (51, 18, 34), (50, 22, 37), (52, 19, 60), (51, 22, 41), (51, 19, 35), (49, 18, 71), (49, 19, 36), (50, 18, 39), (51, 21, 81), (50, 21, 50), (48, 21, 57), (49, 21, 81), (49, 22, 46), (50, 21, 86), (52, 19, 37), (49, 22, 82), (51, 18, 47), (49, 18, 48), (50, 22, 50), (51, 21, 58), (52, 21, 82), (48, 20, 69), (48, 21, 34), (49, 21, 58), (50, 21, 63), (48, 21, 70), (49, 22, 59), (49, 18, 25), (50, 22, 27), (52, 19, 50), (51, 22, 31), (51, 20, 70), (51, 19, 25), (49, 18, 61), (49, 19, 26), (48, 20, 46), (50, 18, 29), (51, 21, 71), (50, 21, 40), (48, 20, 82), (48, 21, 47), (49, 21, 71), (48, 19, 86), (49, 22, 36), (52, 19, 27), (50, 20, 80), (51, 18, 37), (49, 18, 38), (51, 20, 83), (51, 21, 48), (52, 21, 72), (48, 20, 59), (49, 21, 48), (49, 20, 89), (50, 21, 53), (50, 20, 57), (49, 22, 49), (52, 20, 85), (52, 19, 40), (51, 20, 60), (51, 21, 25), (52, 21, 49), (48, 20, 36), (51, 21, 61), (49, 21, 25), (52, 21, 85), (50, 21, 30), (48, 21, 37), (50, 19, 69), (49, 21, 61), (48, 19, 76), (49, 22, 26), (50, 20, 70), (51, 20, 37), (49, 18, 28), (51, 20, 73), (51, 21, 38), (52, 21, 62), (51, 19, 77), (48, 20, 49), (49, 21, 38), (49, 20, 79), (50, 19, 82), (50, 20, 47), (48, 19, 89), (52, 20, 75), (51, 20, 50), (52, 21, 39), (48, 20, 26), (49, 20, 56), (50, 19, 59), (48, 19, 66), (52, 20, 52), (50, 20, 60), (51, 20, 27), (52, 20, 88), (51, 22, 73), (51, 21, 28), (52, 21, 52), (51, 19, 67), (50, 18, 71), (49, 21, 28), (48, 19, 43), (49, 20, 69), (50, 19, 72), (50, 20, 37), (48, 19, 79), (52, 20, 65), (51, 20, 40), (51, 18, 79), (52, 21, 29), (50, 22, 82), (51, 22, 86), (51, 19, 80), (49, 19, 81), (49, 20, 46), (50, 18, 84), (50, 19, 49), (48, 19, 56), (52, 20, 42), (50, 20, 50), (50, 22, 59), (52, 19, 82), (51, 22, 63), (51, 19, 57), (49, 19, 58), (50, 18, 61), (50, 19, 26), (48, 19, 33), (49, 20, 59), (48, 21, 79), (50, 19, 62), (50, 20, 27), (52, 20, 55), (51, 18, 69), (51, 19, 34), (49, 18, 70), (50, 22, 72), (51, 22, 76), (50, 18, 38), (51, 19, 70), (49, 19, 71), (49, 20, 36), (50, 18, 74), (50, 19, 39), (48, 19, 46), (52, 20, 32), (50, 21, 85), (49, 22, 81), (51, 18, 46), (50, 22, 49), (52, 19, 72), (51, 22, 53), (51, 18, 82), (51, 19, 47), (49, 18, 83), (49, 19, 48), (50, 18, 51), (49, 20, 49), (50, 21, 62), (48, 21, 69), (49, 22, 58), (50, 22, 26), (52, 19, 49), (51, 22, 30), (51, 18, 59), (49, 18, 60), (49, 19, 25), (50, 22, 62), (52, 19, 85), (51, 22, 66), (50, 18, 28), (51, 21, 70), (49, 19, 61), (49, 20, 26), (48, 20, 81), (48, 21, 46), (50, 19, 29), (49, 21, 70), (50, 21, 75), (48, 21, 82), (49, 22, 71), (51, 18, 36), (49, 18, 37), (50, 22, 39), (52, 19, 62), (51, 22, 43), (51, 20, 82), (51, 19, 37), (49, 18, 73), (49, 19, 38), (48, 20, 58), (50, 18, 41), (51, 21, 83), (50, 21, 52), (48, 21, 59), (49, 21, 83), (49, 22, 48), (52, 19, 39), (51, 18, 49), (49, 18, 50), (51, 21, 60), (52, 21, 84), (50, 21, 29), (48, 20, 71), (48, 21, 36), (49, 21, 60), (50, 21, 65), (49, 22, 61), (51, 18, 26), (49, 18, 27), (50, 22, 29), (52, 19, 52), (51, 22, 33), (51, 20, 72), (51, 21, 37), (49, 19, 28), (52, 21, 61), (48, 20, 48), (51, 21, 73), (50, 21, 42), (48, 21, 49), (49, 21, 73), (48, 19, 88), (49, 22, 38), (52, 19, 29), (50, 20, 82), (51, 20, 49), (49, 18, 40), (51, 20, 85), (51, 21, 50), (52, 21, 74), (48, 20, 61), (48, 21, 26), (49, 21, 50), (50, 20, 59), (52, 20, 87), (51, 20, 62), (51, 21, 27), (52, 21, 51), (48, 20, 38), (49, 21, 27), (50, 21, 32), (50, 19, 71), (49, 21, 63), (48, 19, 78), (49, 22, 28), (52, 20, 64), (50, 20, 72), (51, 20, 39), (51, 21, 40), (52, 21, 64), (51, 19, 79), (48, 20, 51), (50, 18, 83), (49, 21, 40), (48, 19, 55), (49, 20, 81), (50, 19, 84), (50, 20, 49), (52, 20, 77), (51, 20, 52), (52, 21, 41), (48, 20, 28), (49, 20, 58), (50, 19, 61), (50, 20, 26), (48, 19, 68), (52, 20, 54), (50, 20, 62), (51, 20, 29), (50, 22, 71), (51, 22, 75), (52, 21, 54), (51, 19, 69), (49, 19, 70), (50, 18, 73), (50, 19, 38), (49, 21, 30), (48, 19, 45), (49, 20, 71), (50, 19, 74), (50, 20, 39), (52, 20, 67), (51, 20, 42), (51, 18, 81), (51, 19, 46), (49, 18, 82), (50, 22, 84), (52, 21, 31), (51, 22, 88), (50, 18, 50), (51, 19, 82), (49, 19, 83), (49, 20, 48), (50, 18, 86), (50, 19, 51), (48, 19, 58), (52, 20, 44), (51, 18, 58), (50, 22, 61), (52, 19, 84), (51, 22, 65), (51, 19, 59), (49, 19, 60), (49, 20, 25), (50, 18, 63), (50, 19, 28), (48, 19, 35), (49, 20, 61), (50, 21, 74), (48, 21, 81), (50, 20, 29), (52, 19, 61), (51, 22, 42), (51, 18, 71), (51, 19, 36), (49, 18, 72), (49, 19, 37), (50, 22, 74), (51, 22, 78), (50, 18, 40), (51, 21, 82), (49, 19, 73), (49, 20, 38), (50, 19, 41), (52, 20, 34), (50, 21, 87), (49, 22, 83), (51, 18, 48), (49, 18, 49), (50, 22, 51), (52, 19, 74), (51, 22, 55), (51, 19, 49), (49, 18, 85), (49, 19, 50), (50, 18, 53), (48, 19, 25), (50, 21, 64), (48, 21, 71), (49, 22, 60), (51, 18, 25), (50, 22, 28), (52, 19, 51), (51, 22, 32), (51, 18, 61), (51, 19, 26), (49, 18, 62), (49, 19, 27), (50, 22, 64), (50, 18, 30), (51, 21, 72), (49, 20, 28), (48, 20, 83), (48, 21, 48), (49, 21, 72), (50, 21, 77), (52, 19, 28), (49, 22, 73), (51, 18, 38), (49, 18, 39), (50, 22, 41), (52, 19, 64), (51, 22, 45), (51, 20, 84), (49, 19, 40), (48, 20, 60), (51, 21, 85), (50, 21, 54), (48, 21, 61), (49, 21, 85), (49, 22, 50), (52, 19, 41), (49, 18, 52), (51, 21, 62), (52, 21, 86), (50, 21, 31), (48, 20, 73), (48, 21, 38), (49, 21, 62), (49, 22, 27), (50, 20, 71), (49, 22, 63), (51, 18, 28), (49, 18, 29), (50, 22, 31), (51, 20, 74), (51, 21, 39), (52, 21, 63), (48, 20, 50), (49, 21, 39), (50, 21, 44), (48, 21, 51), (50, 19, 83), (49, 21, 75), (49, 22, 40), (52, 19, 31), (50, 20, 84), (51, 20, 51), (48, 20, 27), (51, 20, 87), (51, 21, 52), (52, 21, 76), (48, 20, 63), (48, 21, 28), (49, 21, 52), (48, 19, 67), (50, 20, 61), (52, 20, 89), (51, 20, 64), (51, 21, 29), (52, 21, 53), (48, 20, 40), (49, 21, 29), (49, 20, 70), (50, 21, 34), (50, 19, 73), (50, 20, 38), (48, 19, 80), (49, 22, 30), (52, 20, 66), (50, 20, 74), (51, 20, 41), (52, 21, 30), (51, 22, 87), (51, 21, 42), (52, 21, 66), (51, 19, 81), (49, 19, 82), (50, 18, 85), (50, 19, 50), (49, 21, 42), (48, 19, 57), (49, 20, 83), (50, 19, 86), (50, 20, 51), (52, 20, 79), (51, 20, 54), (52, 21, 43), (51, 19, 58), (48, 20, 30), (50, 18, 62), (49, 20, 60), (50, 19, 63), (50, 20, 28), (48, 19, 70), (52, 20, 56), (51, 20, 31), (51, 18, 70), (50, 22, 73), (51, 22, 77), (51, 19, 71), (49, 19, 72), (49, 20, 37), (50, 18, 75), (50, 19, 40), (48, 19, 47), (49, 20, 73), (52, 20, 33), (50, 20, 41), (52, 20, 69), (52, 19, 73), (51, 22, 54), (51, 18, 83), (51, 19, 48), (49, 18, 84), (49, 19, 49), (50, 22, 86), (52, 21, 33), (50, 18, 52), (49, 19, 85), (49, 20, 50), (50, 19, 53), (48, 19, 60), (52, 20, 46), (51, 18, 60), (50, 22, 63), (52, 19, 86), (51, 22, 67), (51, 19, 61), (49, 19, 62), (49, 20, 27), (50, 18, 65), (50, 19, 30), (48, 19, 37), (50, 21, 76), (48, 21, 83), (49, 22, 72), (50, 22, 40), (52, 19, 63), (51, 22, 44), (51, 18, 73), (51, 19, 38), (49, 18, 74), (49, 19, 39), (50, 22, 76), (50, 18, 42), (51, 21, 84), (49, 20, 40), (48, 21, 60), (50, 19, 43), (49, 21, 84), (52, 20, 36), (50, 21, 89), (49, 22, 85), (51, 18, 50), (49, 18, 51), (50, 22, 53), (52, 19, 76), (51, 22, 57), (51, 19, 51), (49, 19, 52), (48, 20, 72), (50, 18, 55), (48, 19, 27), (50, 21, 66), (48, 21, 73), (49, 22, 62), (51, 18, 27), (50, 22, 30), (52, 19, 53), (51, 22, 34), (51, 18, 63), (51, 19, 28), (49, 18, 64), (49, 19, 29), (50, 18, 32), (51, 21, 74), (49, 20, 30), (50, 21, 43), (48, 20, 85), (48, 21, 50), (49, 21, 74), (49, 22, 39), (50, 21, 79), (52, 19, 30), (50, 20, 83), (49, 22, 75), (51, 18, 40), (49, 18, 41), (50, 22, 43), (51, 20, 86), (51, 21, 51), (49, 19, 42), (52, 21, 75), (48, 20, 62), (48, 21, 27), (51, 21, 87), (49, 21, 51), (50, 21, 56), (48, 21, 63), (49, 21, 87), (49, 22, 52), (52, 19, 43), (51, 20, 63), (49, 18, 54), (48, 20, 39), (51, 21, 64), (52, 21, 88), (50, 21, 33), (48, 20, 75), (48, 21, 40), (49, 21, 64), (49, 22, 29), (50, 20, 73), (51, 18, 30), (49, 18, 31), (51, 20, 76), (51, 21, 41), (52, 21, 65), (48, 20, 52), (49, 21, 41), (49, 20, 82), (50, 21, 46), (50, 19, 85), (49, 22, 42)}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "predicted_points = np.zeros((100, 100, 100))\n",
    "for x in range(100):\n",
    "    for y in range(100):\n",
    "        for z in range(100):\n",
    "            if z >= 25 and z < 90:\n",
    "                if (x - 50) ** 2 + (y - 20) ** 2 <= 6:\n",
    "                    predicted_points[x, y, z] = 1\n",
    "x, y, z = np.where(predicted_points)\n",
    "predicted_points = set(tuple(zip(x, y, z)))\n",
    "print(predicted_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.spatial as spatial\n",
    "\n",
    "tree = spatial.KDTree(\n",
    "    np.column_stack([com_x[ids_to_keep], com_y[ids_to_keep], com_z[ids_to_keep]])\n",
    ")\n",
    "radius = 1000.0\n",
    "\n",
    "neighbors = tree.query_ball_tree(tree, radius)\n",
    "density = [len(n) for n in neighbors]\n",
    "# print(neighbors)\n",
    "# [[0, 1], [0, 1, 2], [1, 2], [3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "117"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "density = np.array([len(n) for n in neighbors])\n",
    "density.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import gaussian_kde\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "frags = pd.read_csv(\n",
    "    \"/nrs/cellmap/ackermand/cellmap/analysisResults/leaf-gall/jrc_22ak351-leaf-3m.n5/fragments_relabeled.csv\"\n",
    ")\n",
    "id = frags[\"Object ID\"]\n",
    "com_x = frags[\"COM X (nm)\"].to_numpy()\n",
    "com_y = frags[\"COM Y (nm)\"].to_numpy()\n",
    "com_z = frags[\"COM Z (nm)\"].to_numpy()\n",
    "density = gaussian_kde(np.column_stack((com_x, com_y, com_z)).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "def measure(n):\n",
    "    \"Measurement model, return two coupled measurements.\"\n",
    "    m1 = np.random.normal(size=n)\n",
    "    m2 = np.random.normal(scale=0.5, size=n)\n",
    "    m3 = np.random.normal(size=n)\n",
    "    return m1 + m2, m1 - m2, m3\n",
    "\n",
    "\n",
    "m1, m2, m3 = measure(2000)\n",
    "xmin = m1.min()\n",
    "xmax = m1.max()\n",
    "ymin = m2.min()\n",
    "ymax = m2.max()\n",
    "zmin = m3.min()\n",
    "zmax = m3.max()\n",
    "\n",
    "X, Y, Z = np.mgrid[xmin:xmax:100j, ymin:ymax:100j, zmin:zmax:100j]\n",
    "positions = np.vstack([X.ravel(), Y.ravel(), Z.ravel()])\n",
    "values = np.vstack([m1, m2, m3])\n",
    "kernel = stats.gaussian_kde(values)\n",
    "Z = np.reshape(kernel(positions).T, X.shape)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.imshow(\n",
    "    np.rot90(Z), cmap=plt.cm.gist_earth_r, extent=[xmin, xmax, ymin, ymax, zmin, zmax]\n",
    ")\n",
    "ax.plot(m1, m2, \"k.\", markersize=2)\n",
    "ax.set_xlim([xmin, xmax])\n",
    "ax.set_ylim([ymin, ymax])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cellmap_experiments",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
