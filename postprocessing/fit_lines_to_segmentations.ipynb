{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit Lines to Segmentations\n",
    "Here we fit lines to the predicted segmentations. To do so we first must run some analysis code to find the bounding box of each corresponding to true positive, false positive etc. This is in a separate repo but could also be done here. We then look at each segmentated object one at a time and fit a line to its voxels. We then project all these voxels along this line to find the extents of the line to make it a line segment. We then write this out as neuroglancer annotations. You can also write these out however you would like, you would just have to update the downstream code accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 258/391068 [00:12<5:21:13, 20.28it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 86\u001b[0m\n\u001b[1;32m     83\u001b[0m roi \u001b[38;5;241m=\u001b[39m Roi(cube_min \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m8\u001b[39m, (cube_max \u001b[38;5;241m-\u001b[39m cube_min) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m16\u001b[39m)\n\u001b[1;32m     85\u001b[0m \u001b[38;5;66;03m# only look at pixels corresponding to current object\u001b[39;00m\n\u001b[0;32m---> 86\u001b[0m cube \u001b[38;5;241m=\u001b[39m \u001b[43mto_ndarray_tensorstore\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[43m    \u001b[49m\u001b[43mts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mroi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvoxel_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCoordinate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     89\u001b[0m data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mcolumn_stack(np\u001b[38;5;241m.\u001b[39mwhere(cube \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mid\u001b[39m))\n\u001b[1;32m     90\u001b[0m start_point, end_point \u001b[38;5;241m=\u001b[39m fit_line_to_points(data, com)\n",
      "File \u001b[0;32m/groups/cellmap/cellmap/ackermand/Programming/plasmodesmata_dacapo/postprocessing/utils/utils.py:76\u001b[0m, in \u001b[0;36mto_ndarray_tensorstore\u001b[0;34m(dataset, roi, voxel_size, offset)\u001b[0m\n\u001b[1;32m     63\u001b[0m padded_slices \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\n\u001b[1;32m     64\u001b[0m     [\n\u001b[1;32m     65\u001b[0m         \u001b[38;5;28mslice\u001b[39m(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     72\u001b[0m     ]\n\u001b[1;32m     73\u001b[0m )\n\u001b[1;32m     74\u001b[0m \u001b[38;5;66;03m# print(padded_slices[0], valid_slices[0], roi_slices[0])\u001b[39;00m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;66;03m# Read the region of interest from the dataset\u001b[39;00m\n\u001b[0;32m---> 76\u001b[0m padded_data[padded_slices] \u001b[38;5;241m=\u001b[39m \u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43mvalid_slices\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m padded_data\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from neuroglancer.write_annotations import AnnotationWriter\n",
    "from neuroglancer import AnnotationPropertySpec\n",
    "from neuroglancer.coordinate_space import CoordinateSpace\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "from funlib.geometry import Roi\n",
    "from funlib.persistence import open_ds\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from importlib import reload\n",
    "import utils.utils\n",
    "from funlib.geometry import Coordinate\n",
    "\n",
    "reload(utils.utils)\n",
    "from utils.utils import open_ds_tensorstore, to_ndarray_tensorstore\n",
    "\n",
    "\n",
    "def find_min_max_projected_points(points, line_point, line_direction):\n",
    "    # chatgpt\n",
    "    line_direction = line_direction / np.linalg.norm(\n",
    "        line_direction\n",
    "    )  # Normalize direction vector\n",
    "\n",
    "    # Calculate the vector from line_point to each point\n",
    "    point_vectors = points - line_point\n",
    "\n",
    "    # Calculate the projection scalar for each point using dot product and broadcasting\n",
    "    projection_scalars = np.sum(point_vectors * line_direction, axis=1)\n",
    "\n",
    "    # Calculate the projected points for each point\n",
    "    projected_points = line_point + projection_scalars[:, np.newaxis] * line_direction\n",
    "\n",
    "    # Find the minimum and maximum projection scalar indices\n",
    "    min_projection_idx = np.argmin(projection_scalars)\n",
    "    max_projection_idx = np.argmax(projection_scalars)\n",
    "\n",
    "    return projected_points[min_projection_idx], projected_points[max_projection_idx]\n",
    "\n",
    "\n",
    "def fit_line_to_points(points, line_origin=0):\n",
    "    # fit line to object voxels\n",
    "    _, _, vv = np.linalg.svd(points - np.mean(points, axis=0), full_matrices=False)\n",
    "    line_direction = vv[0]\n",
    "\n",
    "    # find endpoints of line segment so that we can write it as neuroglancer annotations\n",
    "    start_point, end_point = find_min_max_projected_points(\n",
    "        points * 8 + 4 + roi.begin, line_origin, line_direction\n",
    "    )\n",
    "\n",
    "    return start_point, end_point\n",
    "\n",
    "\n",
    "plasmodesmata_df = pd.read_csv(\n",
    "    \"/nrs/cellmap/ackermand/cellmap/analysisResults/leaf-gall/jrc_22ak351-leaf-3m.n5/fragments_relabeled.csv\"\n",
    ")\n",
    "ds = open_ds(\n",
    "    \"/nrs/cellmap/ackermand/cellmap/leaf-gall/jrc_22ak351-leaf-3m.n5\",\n",
    "    \"fragments_relabeled\",\n",
    ")\n",
    "ts = open_ds_tensorstore(\n",
    "    \"/nrs/cellmap/ackermand/cellmap/leaf-gall/jrc_22ak351-leaf-3m.n5/fragments_relabeled\"\n",
    ")\n",
    "\n",
    "# since it is arbitrary to have endpoints for line segment in terms of fitting, will just fit a line and then truncate it\n",
    "annotation_writer = AnnotationWriter(\n",
    "    CoordinateSpace(names=(\"x\", \"y\", \"z\"), scales=(1, 1, 1), units=\"nm\"),\n",
    "    annotation_type=\"line\",\n",
    "    properties=[\n",
    "        AnnotationPropertySpec(id=\"identifier\", type=\"uint16\"),\n",
    "    ],\n",
    ")\n",
    "\n",
    "# uu, dd, vv = np.linalg.svd(data - datamean, full_matrices=False)\n",
    "for _, row in tqdm(plasmodesmata_df.iterrows(), total=len(plasmodesmata_df)):\n",
    "    # object id, bounding box and center of mass information, calculated beforehand\n",
    "    id = row[\"Object ID\"]\n",
    "    cube_min = np.array([row[f\"MIN {d} (nm)\"] for d in [\"X\", \"Y\", \"Z\"]])\n",
    "    cube_max = np.array([row[f\"MAX {d} (nm)\"] for d in [\"X\", \"Y\", \"Z\"]])\n",
    "    com = np.array([row[f\"COM {d} (nm)\"] for d in [\"X\", \"Y\", \"Z\"]])\n",
    "\n",
    "    # define an roi to actually ecompass the bounding box\n",
    "    roi = Roi(cube_min - 8, (cube_max - cube_min) + 16)\n",
    "\n",
    "    # only look at pixels corresponding to current object\n",
    "    cube = to_ndarray_tensorstore(\n",
    "        ts, roi, ds.voxel_size, Coordinate(ds.roi.begin[::-1])\n",
    "    )\n",
    "    data = np.column_stack(np.where(cube == id))\n",
    "    start_point, end_point = fit_line_to_points(data, com)\n",
    "    # # fit line to object voxels\n",
    "    # uu, dd, vv = np.linalg.svd(data - np.mean(data, axis=0), full_matrices=False)\n",
    "    # line_direction = vv[0]\n",
    "    # line_origin = com\n",
    "\n",
    "    # # find endpoints of line segment so that we can write it as neuroglancer annotations\n",
    "    # start_point, end_point = find_min_max_projected_points(\n",
    "    #     data * 8 + 4 + roi.begin, line_origin, line_direction\n",
    "    # )\n",
    "\n",
    "    # write out lines as neuroglancer annotations\n",
    "    # annotation_writer.add_line(\n",
    "    #     point_a=start_point[::-1],\n",
    "    #     point_b=end_point[::-1],\n",
    "    #     id=int(id),\n",
    "    #     identifier=int(id),\n",
    "    # )\n",
    "\n",
    "    # annotation_writer.write(\n",
    "    #     f\"/groups/cellmap/cellmap/ackermand/neuroglancer_annotations/leaf-gall/forAnnotators/{yaml_name}/{ds_name}\"\n",
    "    # )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roi_slices slice(2, 42, None), valid_slices slice(2, 42, None), padded_slicesslice(-2, 40, None), (0, 0, 0)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (23,40,22) into shape (23,2,22)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[55], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m reload(utils\u001b[38;5;241m.\u001b[39mutils)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m open_ds_tensorstore, to_ndarray_tensorstore\n\u001b[0;32m----> 7\u001b[0m cube \u001b[38;5;241m=\u001b[39m \u001b[43mto_ndarray_tensorstore\u001b[49m\u001b[43m(\u001b[49m\u001b[43mts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mroi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvoxel_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCoordinate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/groups/cellmap/cellmap/ackermand/Programming/plasmodesmata_dacapo/postprocessing/utils/utils.py:74\u001b[0m, in \u001b[0;36mto_ndarray_tensorstore\u001b[0;34m(dataset, roi, voxel_size, offset)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mroi_slices \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mroi_slices[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, valid_slices \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalid_slices[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, padded_slices\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpadded_slices[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdomain\u001b[38;5;241m.\u001b[39minclusive_min\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     72\u001b[0m )\n\u001b[1;32m     73\u001b[0m \u001b[38;5;66;03m# Read the region of interest from the dataset\u001b[39;00m\n\u001b[0;32m---> 74\u001b[0m \u001b[43mpadded_data\u001b[49m\u001b[43m[\u001b[49m\u001b[43mpadded_slices\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m dataset[valid_slices]\u001b[38;5;241m.\u001b[39mread()\u001b[38;5;241m.\u001b[39mresult()\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m padded_data\n",
      "\u001b[0;31mValueError\u001b[0m: could not broadcast input array from shape (23,40,22) into shape (23,2,22)"
     ]
    }
   ],
   "source": [
    "import utils.utils\n",
    "from funlib.geometry import Coordinate\n",
    "\n",
    "reload(utils.utils)\n",
    "from utils.utils import open_ds_tensorstore, to_ndarray_tensorstore\n",
    "\n",
    "cube = to_ndarray_tensorstore(ts, roi, ds.voxel_size, Coordinate(ds.roi.begin[::-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([174888:175072, 12816:13136, 54616:54792] (184, 320, 176),\n",
       " [22400:73728, 12800:38528, 0:261120] (51328, 25728, 261120))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roi, ds.roi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from neuroglancer.write_annotations import AnnotationWriter\n",
    "from neuroglancer import AnnotationPropertySpec\n",
    "from neuroglancer.coordinate_space import CoordinateSpace\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "from funlib.geometry import Roi\n",
    "from funlib.persistence import open_ds\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from utils.utils import open_ds_tensorstore, to_ndarray_tensorstore\n",
    "\n",
    "\n",
    "def find_min_max_projected_points(points, line_point, line_direction):\n",
    "    # chatgpt\n",
    "    line_direction = line_direction / np.linalg.norm(\n",
    "        line_direction\n",
    "    )  # Normalize direction vector\n",
    "\n",
    "    # Calculate the vector from line_point to each point\n",
    "    point_vectors = points - line_point\n",
    "\n",
    "    # Calculate the projection scalar for each point using dot product and broadcasting\n",
    "    projection_scalars = np.sum(point_vectors * line_direction, axis=1)\n",
    "\n",
    "    # Calculate the projected points for each point\n",
    "    projected_points = line_point + projection_scalars[:, np.newaxis] * line_direction\n",
    "\n",
    "    # Find the minimum and maximum projection scalar indices\n",
    "    min_projection_idx = np.argmin(projection_scalars)\n",
    "    max_projection_idx = np.argmax(projection_scalars)\n",
    "\n",
    "    return projected_points[min_projection_idx], projected_points[max_projection_idx]\n",
    "\n",
    "\n",
    "plasmodesmata_df = pd.read_csv(\n",
    "    \"/nrs/cellmap/ackermand/cellmap/analysisResults/leaf-gall/jrc_22ak351-leaf-3m.n5/fragments_relabeled.csv\"\n",
    ")\n",
    "ds = open_ds(\n",
    "    \"/nrs/cellmap/ackermand/cellmap/leaf-gall/jrc_22ak351-leaf-3m.n5\",\n",
    "    \"fragments_relabeled\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22400, 12800, 0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.roi.begin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "plasmodesmata_dacapo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
