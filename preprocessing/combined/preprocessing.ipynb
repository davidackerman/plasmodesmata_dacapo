{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dacapo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dacapo.experiments.architectures import CNNectomeUNetConfig\n",
    "from dacapo.experiments.trainers import GunpowderTrainerConfig\n",
    "from dacapo.experiments.trainers.gp_augments import (\n",
    "    ElasticAugmentConfig,\n",
    "    IntensityAugmentConfig,\n",
    ")\n",
    "from dacapo.experiments.tasks import AffinitiesTaskConfig\n",
    "from funlib.geometry.coordinate import Coordinate\n",
    "import math"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_config = GunpowderTrainerConfig(\n",
    "    name=\"default_v2_no_dataset_predictor_node_lr_5E-5\",\n",
    "    batch_size=2,\n",
    "    learning_rate=0.00005,\n",
    "    augments=[\n",
    "        ElasticAugmentConfig(\n",
    "            control_point_spacing=(100, 100, 100),\n",
    "            control_point_displacement_sigma=(10.0, 10.0, 10.0),\n",
    "            rotation_interval=(0, math.pi / 2.0),\n",
    "            subsample=8,\n",
    "            uniform_3d_rotation=True,\n",
    "        ),\n",
    "        IntensityAugmentConfig(\n",
    "            scale=(0.7, 1.3),\n",
    "            shift=(-0.2, 0.2),\n",
    "            clip=True,\n",
    "        ),\n",
    "    ],\n",
    "    clip_raw=True,\n",
    "    num_data_fetchers=20,\n",
    "    snapshot_interval=10000,\n",
    "    min_masked=0.05,\n",
    "    add_predictor_nodes_to_dataset=False,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_config = AffinitiesTaskConfig(\n",
    "    name=f\"3d_lsdaffs_weight_ratio_0.50\",\n",
    "    neighborhood=[\n",
    "        (1, 0, 0),\n",
    "        (0, 1, 0),\n",
    "        (0, 0, 1),\n",
    "        (3, 0, 0),\n",
    "        (0, 3, 0),\n",
    "        (0, 0, 3),\n",
    "        (9, 0, 0),\n",
    "        (0, 9, 0),\n",
    "        (0, 0, 9),\n",
    "    ],\n",
    "    lsds=True,\n",
    "    lsds_to_affs_weight_ratio=0.50,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I had an issue where, by default, I created the rasterization at the same resolution as the raw data. But the default architecture (with the upsampling layer `upsample_factors`) expects it to be at 2x the resolution including mask and validation. This resulted in an error when submitting. Since we don't really care about a higher res (at the moment), we can just comment out the upsampling layer (`constant_upsample` and `upsample_factors`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "architecture_config = CNNectomeUNetConfig(\n",
    "    name=\"unet\",\n",
    "    input_shape=Coordinate(216, 216, 216),\n",
    "    eval_shape_increase=Coordinate(72, 72, 72),\n",
    "    fmaps_in=1,\n",
    "    num_fmaps=12,\n",
    "    fmaps_out=72,\n",
    "    fmap_inc_factor=6,\n",
    "    downsample_factors=[(2, 2, 2), (3, 3, 3), (3, 3, 3)],\n",
    "    # constant_upsample=True,\n",
    "    # upsample_factors=[(2, 2, 2)],\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasplit"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EVERYTHING MUST BE IN Z,Y,X AND NM!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "combined datasplits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dacapo.store.create_store import create_config_store, MongoConfigStore\n",
    "from dacapo.experiments.datasplits import TrainValidateDataSplitConfig\n",
    "from dacapo.experiments.datasplits import DataSplitConfig\n",
    "from dacapo.options import Options\n",
    "from dacapo.store.converter import converter\n",
    "\n",
    "options = Options.instance()\n",
    "\n",
    "combined_train_configs = []\n",
    "combined_validate_configs = []\n",
    "config_store = create_config_store()\n",
    "annotation_name = \"plasmodesmata\"\n",
    "for dataset in [\"jrc_22ak351-leaf-3m\", \"jrc_22ak351-leaf-3r\", \"jrc_22ak351-leaf-2l\"]:\n",
    "    # arbitrarily use last run, doesn't matter since we really only care about datasplit\n",
    "    if dataset == \"jrc_22ak351-leaf-3m\":\n",
    "        run_name = \"finetuned_3d_lsdaffs_weight_ratio_0.50_plasmodesmata_pseudorandom_training_centers_maxshift_18_more_annotations_unet_default_v2_no_dataset_predictor_node_lr_5E-5__0\"\n",
    "    else:\n",
    "        run_name = f\"finetuned_3d_lsdaffs_weight_ratio_0.50_{dataset}_plasmodesmata_pseudorandom_training_centers_unet_default_v2_no_dataset_predictor_node_lr_5E-5__0\"\n",
    "    run_config = config_store.retrieve_run_config(run_name)\n",
    "    datasplit_config = run_config.datasplit_config\n",
    "\n",
    "    combined_train_configs.extend(datasplit_config.train_configs)\n",
    "    combined_validate_configs.extend(datasplit_config.validate_configs)\n",
    "\n",
    "combined_datasplit_config = TrainValidateDataSplitConfig(\n",
    "    name=f\"combined_{annotation_name}_pseudorandom_training_centers\",\n",
    "    train_configs=combined_train_configs,\n",
    "    validate_configs=combined_validate_configs,\n",
    ")\n",
    "config_store.store_datasplit_config(combined_datasplit_config)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "visualize run: python /groups/scicompsoft/home/ackermand/Programming/ml_experiments/scripts/visualize_pipeline.py visualize-pipeline -r finetuned_3d_lsdaffs_weight_ratio_0.50_combined_plasmodesmata_pseudorandom_training_centers_unet_default_v2_no_dataset_predictor_node_lr_5E-5__0\n",
      "visualize run: python /groups/scicompsoft/home/ackermand/Programming/ml_experiments/scripts/visualize_pipeline.py visualize-pipeline -r finetuned_3d_lsdaffs_weight_ratio_0.50_combined_plasmodesmata_pseudorandom_training_centers_unet_default_v2_no_dataset_predictor_node_lr_5E-5__1\n",
      "visualize run: python /groups/scicompsoft/home/ackermand/Programming/ml_experiments/scripts/visualize_pipeline.py visualize-pipeline -r finetuned_3d_lsdaffs_weight_ratio_0.50_combined_plasmodesmata_pseudorandom_training_centers_unet_default_v2_no_dataset_predictor_node_lr_5E-5__2\n"
     ]
    }
   ],
   "source": [
    "from dacapo.experiments import RunConfig\n",
    "from dacapo.experiments.starts import StartConfig\n",
    "from dacapo.store.create_store import create_config_store\n",
    "\n",
    "config_store = create_config_store()\n",
    "start_config = StartConfig(\n",
    "    \"finetuned_3d_lsdaffs_weight_ratio_0.50_plasmodesmata_pseudorandom_training_centers_maxshift_18_more_annotations_unet_default_v2_no_dataset_predictor_node_lr_5E-5__1\",\n",
    "    \"140000\",\n",
    ")\n",
    "iterations = 200000\n",
    "# make validation interval huge so don't have to deal with validation until after the fact\n",
    "validation_interval = 5000\n",
    "repetitions = 3\n",
    "for i in range(repetitions):\n",
    "    run_config = RunConfig(\n",
    "        name=(\"_\").join(\n",
    "            [\n",
    "                \"scratch\" if start_config is None else \"finetuned\",\n",
    "                task_config.name,\n",
    "                combined_datasplit_config.name,\n",
    "                architecture_config.name,\n",
    "                trainer_config.name,\n",
    "            ]\n",
    "        )\n",
    "        + f\"__{i}\",\n",
    "        task_config=task_config,\n",
    "        datasplit_config=combined_datasplit_config,\n",
    "        architecture_config=architecture_config,\n",
    "        trainer_config=trainer_config,\n",
    "        num_iterations=iterations,\n",
    "        validation_interval=validation_interval,\n",
    "        repetition=i,\n",
    "        start_config=start_config,\n",
    "    )\n",
    "    config_store.store_run_config(run_config)\n",
    "    # \"dacapo run -r {run_config.name}\"\n",
    "    print(\n",
    "        f\"visualize run: python /groups/scicompsoft/home/ackermand/Programming/ml_experiments/scripts/visualize_pipeline.py visualize-pipeline -r {run_config.name}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finetuned_3d_lsdaffs_weight_ratio_0.50_combined_plasmodesmata_pseudorandom_training_centers_unet_default_v2_no_dataset_predictor_node_lr_5E-5__2\n"
     ]
    }
   ],
   "source": [
    "print(run_config.name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from funlib.persistence import open_ds, prepare_ds\n",
    "from funlib.geometry import Roi, Coordinate\n",
    "from scipy.ndimage import binary_dilation, distance_transform_edt\n",
    "import numpy as np\n",
    "\n",
    "for iterations in range(1, 4):\n",
    "    ds = open_ds(\n",
    "        f\"/nrs/cellmap/ackermand/cellmap/leaf-gall/{dataset}.n5\",\n",
    "        \"plasmodesmata_column_cells\",\n",
    "    )\n",
    "    voxel_size = ds.voxel_size\n",
    "    data = ds.to_ndarray() > 0\n",
    "    ds = open_ds(\n",
    "        f\"/nrs/cellmap/ackermand/cellmap/leaf-gall/{dataset}.n5\",\n",
    "        \"plasmodesmata_column_target_cells\",\n",
    "    )\n",
    "    data += ds.to_ndarray() > 0\n",
    "    data = 1 - (data > 0)\n",
    "    data = binary_dilation(data, iterations=iterations)\n",
    "\n",
    "    output_ds = prepare_ds(\n",
    "        \"/nrs/cellmap/ackermand/cellmap/leaf-gall/prediction_masks.zarr\",\n",
    "        f\"dilation_iterations_{iterations}_{dataset}\",\n",
    "        total_roi=ds.roi,\n",
    "        voxel_size=voxel_size,\n",
    "        dtype=np.uint8,\n",
    "        write_size=Coordinate(np.array([64, 64, 64]) * 256),\n",
    "        delete=True,\n",
    "        # force_exact_write_size=True\n",
    "    )\n",
    "    output_ds[ds.roi] = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "plasmodesmata_dacapo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
